{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pnet_prostate_paper'...\n",
      "remote: Enumerating objects: 758, done.\u001b[K\n",
      "remote: Counting objects: 100% (758/758), done.\u001b[K\n",
      "remote: Compressing objects: 100% (469/469), done.\u001b[K\n",
      "remote: Total 758 (delta 438), reused 568 (delta 259), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (758/758), 5.18 MiB | 8.84 MiB/s, done.\n",
      "Resolving deltas: 100% (438/438), done.\n"
     ]
    }
   ],
   "source": [
    "#This Jupyter notebook was run locally using Bash kernel\n",
    "#Clone the github\n",
    "git clone https://github.com/marakeby/pnet_prostate_paper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory to pnet_prostate_paper\n",
    "cd pnet_prostate_paper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Ran pip subprocess with arguments:\n",
      "['/opt/anaconda3/envs/pnet_env/bin/python', '-m', 'pip', 'install', '-U', '-r', '/Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting adjusttext==0.7.3 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 1))\n",
      "Collecting lifelines==0.19.5 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 2))\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/f4/408183aee57b9625805b02441e761fedf32c29559e4be15823afee375de5/lifelines-0.19.5-py2.py3-none-any.whl\n",
      "Collecting matplotlib==2.2.4 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/3e/d6/4c949597c4186599cc8be08cd11b1e83fe7966676aeee3868bf3e581d852/matplotlib-2.2.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting psutil==5.8.0 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/7f/a2559a514bdeb2a33e4bf3dc3d2bb17d5acded718893869a82536130cfb3/psutil-5.8.0-cp27-cp27m-macosx_10_9_x86_64.whl\n",
      "Requirement already up-to-date: networkx==2.2 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 5)) (2.2)\n",
      "Collecting pyvis==0.1.7.0 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "Collecting requests==2.23.0 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 7))\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Collecting rope==0.18.0 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 8))\n",
      "Collecting seaborn==0.9.1 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 9))\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/86/43b8c9138ef4c2a1c492fee92792c83c13799d0e2061ff810d3826d06cd1/seaborn-0.9.1-py2.py3-none-any.whl\n",
      "Collecting toml==0.10.2 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 10))\n",
      "  Using cached https://files.pythonhosted.org/packages/44/6f/7120676b6d73228c96e17f1f794d8ab046fc910d781c8d151120c3f1569e/toml-0.10.2-py2.py3-none-any.whl\n",
      "Collecting upsetplot==0.4.0 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 11))\n",
      "Collecting urllib3==1.25.8 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 12))\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl\n",
      "Collecting xlrd==0.9.0 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 13))\n",
      "Collecting decorator==4.3.2 (from -r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 14))\n",
      "  Using cached https://files.pythonhosted.org/packages/f1/cd/7c8240007e9716b14679bc217a1baefa4432aa30394f7e2ec40a52b1a708/decorator-4.3.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from adjusttext==0.7.3->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 1)) (1.16.6)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.18 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from lifelines==0.19.5->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 2)) (0.23.4)\n",
      "Collecting autograd>=1.2 (from lifelines==0.19.5->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 2))\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from lifelines==0.19.5->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 2)) (1.1.0)\n",
      "Collecting bottleneck>=1.0 (from lifelines==0.19.5->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 2))\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: backports.functools-lru-cache in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (1.6.4)\n",
      "Requirement already satisfied, skipping upgrade: subprocess32 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (3.5.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (2021.3)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (0.10.0)\n",
      "Collecting ipython>=5.3.0 (from pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/2c/2849a2b37024a01a847c87d81825c0489eb22ffc6416cac009bf281ea838/ipython-5.10.0-py2-none-any.whl\n",
      "Collecting jinja2>=2.9.6 (from pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/c2/1eece8c95ddbc9b1aeb64f5783a9e07a286de42191b7204d67b7496ddf35/Jinja2-2.11.3-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests==2.23.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 7))\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests==2.23.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 7))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from requests==2.23.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 7)) (2020.6.20)\n",
      "Collecting future>=0.15.2 (from autograd>=1.2->lifelines==0.19.5->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 2))\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from kiwisolver>=1.0.1->matplotlib==2.2.4->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 3)) (44.0.0.post20200106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prompt-toolkit<2.0.0,>=1.0.4 (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/d2/2f099b5cd62dab819ce7a9f1431c09a9032fbfbb6474f442722e88935376/prompt_toolkit-1.0.18-py2-none-any.whl\n",
      "Collecting backports.shutil-get-terminal-size; python_version == \"2.7\" (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/cd/1750d6c35fe86d35f8562091737907f234b78fdffab42b29c72b1dd861f4/backports.shutil_get_terminal_size-1.0.0-py2.py3-none-any.whl\n",
      "Collecting appnope; sys_platform == \"darwin\" (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/e4/fa/0c6c9786aa6927d12d100d322588e125e6ed466ab0a3d2d509ea18aeb56d/appnope-0.1.2-py2.py3-none-any.whl\n",
      "Collecting pathlib2; python_version == \"2.7\" or python_version == \"3.3\" (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/76/67/dc02c72177ec79f0176e5bf9921e9c1745a381ed556afb3b3ecc2bb8ba2e/pathlib2-2.3.6-py2.py3-none-any.whl\n",
      "Collecting pexpect; sys_platform != \"win32\" (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/39/7b/88dbb785881c28a102619d46423cb853b46dbccc70d3ac362d99773a78ce/pexpect-4.8.0-py2.py3-none-any.whl\n",
      "Collecting pygments<2.6 (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/be/39/32da3184734730c0e4d3fa3b2b5872104668ad6dc1b5a73d8e477e5fe967/Pygments-2.5.2-py2.py3-none-any.whl\n",
      "Collecting traitlets>=4.2 (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/ab/872a23e29cec3cf2594af7e857f18b687ad21039c1f9b922fac5b9b142d5/traitlets-4.3.3-py2.py3-none-any.whl\n",
      "Collecting simplegeneric>0.8 (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "Collecting pickleshare (from ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl\n",
      "Collecting MarkupSafe>=0.23 (from jinja2>=2.9.6->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/d2/0ccd2c0e2cd93b35e765d9b3205cd6602e6b202b522fc7997531353715b3/MarkupSafe-1.1.1-cp27-cp27m-macosx_10_6_intel.whl\n",
      "Collecting wcwidth (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/59/7c/e39aca596badaf1b78e8f547c807b04dae603a433d3e7a7e04d67f2ef3e5/wcwidth-0.2.5-py2.py3-none-any.whl\n",
      "Collecting scandir; python_version < \"3.5\" (from pathlib2; python_version == \"2.7\" or python_version == \"3.3\"->ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "Collecting ptyprocess>=0.5 (from pexpect; sys_platform != \"win32\"->ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/22/a6/858897256d0deac81a172289110f31629fc4cee19b6f01283303e18c8db3/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "Collecting ipython-genutils (from traitlets>=4.2->ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: enum34; python_version == \"2.7\" in /opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages (from traitlets>=4.2->ipython>=5.3.0->pyvis==0.1.7.0->-r /Users/jongha523/pnet_prostate_paper/condaenv.70qvokrc.requirements.txt (line 6)) (1.1.6)\n",
      "Installing collected packages: matplotlib, adjusttext, future, autograd, bottleneck, lifelines, psutil, wcwidth, prompt-toolkit, decorator, backports.shutil-get-terminal-size, appnope, scandir, pathlib2, ptyprocess, pexpect, pygments, ipython-genutils, traitlets, simplegeneric, pickleshare, ipython, MarkupSafe, jinja2, pyvis, idna, chardet, urllib3, requests, rope, seaborn, toml, upsetplot, xlrd\n",
      "  Found existing installation: matplotlib 2.2.3\n",
      "    Uninstalling matplotlib-2.2.3:\n",
      "      Successfully uninstalled matplotlib-2.2.3\n",
      "  Found existing installation: decorator 5.1.0\n",
      "    Uninstalling decorator-5.1.0:\n",
      "      Successfully uninstalled decorator-5.1.0\n",
      "Successfully installed MarkupSafe-1.1.1 adjusttext-0.7.3 appnope-0.1.2 autograd-1.3 backports.shutil-get-terminal-size-1.0.0 bottleneck-1.3.2 chardet-3.0.4 decorator-4.3.2 future-0.18.2 idna-2.10 ipython-5.10.0 ipython-genutils-0.2.0 jinja2-2.11.3 lifelines-0.19.5 matplotlib-2.2.4 pathlib2-2.3.6 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-1.0.18 psutil-5.8.0 ptyprocess-0.7.0 pygments-2.5.2 pyvis-0.1.7.0 requests-2.23.0 rope-0.18.0 scandir-1.10.0 seaborn-0.9.1 simplegeneric-0.8.1 toml-0.10.2 traitlets-4.3.3 upsetplot-0.4.0 urllib3-1.25.8 wcwidth-0.2.5 xlrd-0.9.0\n",
      "\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate pnet_env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create P-NET environment using environment01.yml. Runs in python 2.7.\n",
    "conda env create --name pnet_env --file=environment01.yml python==2.7 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#Activate the environment\n",
    "source activate pnet_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pnet_env) (pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#Add the current diretory to PYTHONPATH\n",
    "export PYTHONPATH=~/pnet_prostate_paper:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/52/ff/912fe03a623a70bcf297d466013a0b4f4c68c3b60f86bf226682d061fc09/pandas-0.24.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/e3/d9f046b5d1c94a3aeab15f1f867aa414f8ee9d196fae6865f1d6a0ee1a0b/pytz-2021.3-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.12.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/09/96/84cf406fe7d589f3dba9fc0f737e65985a3526c6d8c783f02d4b5a10825d/numpy-1.16.6-cp27-cp27m-macosx_10_9_x86_64.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.5.0->pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Installing collected packages: six, python-dateutil, pytz, numpy, pandas\n",
      "  Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Found existing installation: pytz 2021.3\n",
      "    Uninstalling pytz-2021.3:\n",
      "      Successfully uninstalled pytz-2021.3\n",
      "  Found existing installation: numpy 1.16.6\n",
      "    Uninstalling numpy-1.16.6:\n",
      "      Successfully uninstalled numpy-1.16.6\n",
      "  Found existing installation: pandas 0.23.4\n",
      "    Uninstalling pandas-0.23.4:\n",
      "      Successfully uninstalled pandas-0.23.4\n",
      "Successfully installed numpy-1.16.6 pandas-0.24.2 python-dateutil-2.8.2 pytz-2021.3 six-1.16.0\n",
      "(pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "pip install --upgrade pandas --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "(pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda install -c anaconda python.app -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the parameter file using vim editor and change number of epochs from 300 to 500\n",
    "\n",
    "vim train/params/P1000/pnet/onsplit_average_reg_10_tanh_large.py\n",
    "\n",
    "#After making changes exit file with esc :wq command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pnet_env) (pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#Change directory to train\n",
    "cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pnet_env) Using TensorFlow backend.\n",
      "setting logs\n",
      "random seed 234\n",
      "/Users/jongha523/pnet_prostate_paper/train/params/P1000/./pnet/onsplit_average_reg_10_tanh_large_testing.py\n",
      "/Users/jongha523/pnet_prostate_paper/train/params/P1000/./pnet/onsplit_average_reg_10_tanh_large_testing.py:1: RuntimeWarning: Parent module '/Users/jongha523/pnet_prostate_paper/train/params/P1000/' not found while handling absolute import\n",
      "  from model.builders.prostate_models import build_pnet2\n",
      "{'params': {'save_train': True, 'eval_dataset': 'test'}, 'type': 'one_split'}\n",
      "[{'params': {'drop_AR': False, 'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'combine_type': 'union', 'training_split': 0, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True}, 'type': 'prostate_paper', 'id': 'ALL'}]\n",
      "data_params {'params': {'drop_AR': False, 'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'combine_type': 'union', 'training_split': 0, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True}, 'type': 'prostate_paper', 'id': 'ALL'}\n",
      "loading data....\n",
      "loading mut_important\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_final_analysis_set_cross_important_only.csv,\n",
      "(1011, 14378)\n",
      "loading response from response_paper.csv\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1011 samples, 8319 variables, 1011 responses \n",
      "8319\n",
      "mut_binary = True\n",
      "loading cnv_del\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "loading cnv_amp\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "loading from memory cached_data\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "After combining, loaded data 1011 samples, 27687 variables, 1011 responses \n",
      "predicting\n",
      "x_train (807, 27687) y_train (807, 1) \n",
      "x_test (204, 27687) y_test (204, 1) \n",
      "preprocessing....\n",
      "preprocessing....\n",
      "{'type': None}\n",
      "Pre-processing: None\n",
      "class_weight auto\n",
      "fitting\n",
      "{'type': 'nn', 'params': {'model_params': {'shuffle_genes': False, 'dropout_testing': False, 'kernel_initializer': 'lecun_uniform', 'n_hidden_layers': 5, 'dropout': [0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 'attention': False, 'w_reg_outcomes': [0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 'loss_weights': [2, 7, 20, 54, 148, 400], 'w_reg': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001], 'add_unk_genes': False, 'activation': 'tanh', 'optimizer': 'Adam', 'use_bias': True, 'data_params': {'type': 'prostate_paper', 'params': {'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True, 'drop_AR': False, 'combine_type': 'union', 'training_split': 0}, 'id': 'ALL'}}, 'fitting_params': {'early_stop': False, 'shuffle': True, 'verbose': 2, 'samples_per_epoch': 10, 'reduce_lr': False, 'save_gradient': False, 'reduce_lr_after_nepochs': {'epochs_drop': 50, 'drop': 0.25}, 'batch_size': 50, 'max_f1': True, 'epoch': 500, 'monitor': 'val_o6_f1', 'save_name': 'pnet', 'select_best_model': False, 'n_outputs': 6, 'lr': 0.001, 'prediction_output': 'average', 'debug': False, 'class_weight': 'auto'}, 'feature_importance': 'deepexplain_deeplift', 'build_fn': <function build_pnet2 at 0x7fa1061a91b8>}, 'id': 'P-net'}\n",
      "{'type': 'prostate_paper', 'params': {'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True, 'drop_AR': False, 'combine_type': 'union', 'training_split': 0}, 'id': 'ALL'}\n",
      "n_hidden_layers 5\n",
      "loading mut_important\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_final_analysis_set_cross_important_only.csv,\n",
      "loading from memory cached_data\n",
      "(1011, 14378)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1011 samples, 8319 variables, 1011 responses \n",
      "8319\n",
      "mut_binary = True\n",
      "loading cnv_del\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "loading from memory cached_data\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "loading cnv_amp\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "loading from memory cached_data\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "After combining, loaded data 1011 samples, 27687 variables, 1011 responses \n",
      "(1011, 27687)\n",
      "(1011, 1)\n",
      "(1011,)\n",
      "(27687,)\n",
      "x shape (1011, 27687) , y shape (1011, 1) info (1011,) genes (27687,)\n",
      "x shape (1011, 27687) , y shape (1011, 1) info (1011,) genes (27687,)\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer <keras.regularizers.L1L2 object at 0x7fa0ae1b9350> <keras.initializers.VarianceScaling object at 0x7fa0ae1b9650> <keras.regularizers.L1L2 object at 0x7fa0ae1b9350>\n",
      "input dimensions (None, 27687)\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:145: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear0\")`\n",
      "  decision_outcome = Dense(1, activation='linear', name='o_linear{}'.format(0), W_regularizer=reg_l(w_reg_outcome0))(\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:162: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear1\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome1 / 2.))(outcome)\n",
      "layer # 0\n",
      "pathways 1387\n",
      "genes 9275\n",
      "filtered_map (9229, 0)\n",
      "filtered_map (9229, 0)\n",
      "filtered_map (9229, 0)\n",
      "layer 0 , # of edges  15651.0\n",
      "layer # 1\n",
      "pathways 1066\n",
      "genes 1399\n",
      "filtered_map (1387, 0)\n",
      "filtered_map (1387, 0)\n",
      "filtered_map (1387, 0)\n",
      "layer 1 , # of edges  1396.0\n",
      "layer # 2\n",
      "pathways 447\n",
      "genes 1068\n",
      "filtered_map (1066, 0)\n",
      "filtered_map (1066, 0)\n",
      "filtered_map (1066, 0)\n",
      "layer 2 , # of edges  1070.0\n",
      "layer # 3\n",
      "pathways 147\n",
      "genes 448\n",
      "filtered_map (447, 0)\n",
      "filtered_map (447, 0)\n",
      "filtered_map (447, 0)\n",
      "layer 3 , # of edges  447.0\n",
      "layer # 4\n",
      "pathways 26\n",
      "genes 147\n",
      "filtered_map (147, 0)\n",
      "filtered_map (147, 0)\n",
      "filtered_map (147, 0)\n",
      "layer 4 , # of edges  148.0\n",
      "layer # 5\n",
      "pathways 1\n",
      "genes 26\n",
      "filtered_map (26, 0)\n",
      "filtered_map (26, 0)\n",
      "filtered_map (26, 0)\n",
      "layer 5 , # of edges  26.0\n",
      "original dropout [0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "dropout [1, 2, 3, 4, 5] [0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1] [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n",
      "n_genes, n_pathways 9229 1387 \n",
      "layer 0, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear2\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "n_genes, n_pathways 1387 1066 \n",
      "layer 1, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear3\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "n_genes, n_pathways 1066 447 \n",
      "layer 2, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear4\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_genes, n_pathways 447 147 \n",
      "layer 3, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear5\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "n_genes, n_pathways 147 26 \n",
      "layer 4, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear6\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "Compiling...\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/prostate_models.py:171: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  model = Model(input=[ins], output=outcome)\n",
      "loss_weights [2, 7, 20, 54, 148, 400]\n",
      "done compiling\n",
      "  - 0 inputs (None, 27687)\n",
      "  - 1 h0 (None, 9229)\n",
      "  - 2 dropout_0 (None, 9229)\n",
      "  - 3 h1 (None, 1387)\n",
      "  - 4 dropout_1 (None, 1387)\n",
      "  - 5 h2 (None, 1066)\n",
      "  - 6 dropout_2 (None, 1066)\n",
      "  - 7 h3 (None, 447)\n",
      "  - 8 dropout_3 (None, 447)\n",
      "  - 9 h4 (None, 147)\n",
      "  - 10 dropout_4 (None, 147)\n",
      "  - 11 h5 (None, 26)\n",
      "  - 12 o_linear1 (None, 1)\n",
      "  - 13 o_linear2 (None, 1)\n",
      "  - 14 o_linear3 (None, 1)\n",
      "  - 15 o_linear4 (None, 1)\n",
      "  - 16 o_linear5 (None, 1)\n",
      "  - 17 o_linear6 (None, 1)\n",
      "  - 18 o1 (None, 1)\n",
      "  - 19 o2 (None, 1)\n",
      "  - 20 o3 (None, 1)\n",
      "  - 21 o4 (None, 1)\n",
      "  - 22 o5 (None, 1)\n",
      "  - 23 o6 (None, 1)\n",
      "[<keras.engine.input_layer.InputLayer object at 0x7fa105c15410>, <model.layers_custom.Diagonal object at 0x7fa0ae1b9e10>, <keras.layers.core.Dropout object at 0x7fa0b4177ad0>, <model.layers_custom.SparseTF object at 0x7fa0f2bae350>, <keras.layers.core.Dropout object at 0x7fa0d17cad10>, <model.layers_custom.SparseTF object at 0x7fa0d17ca810>, <keras.layers.core.Dropout object at 0x7fa03993ce90>, <model.layers_custom.SparseTF object at 0x7fa03993ccd0>, <keras.layers.core.Dropout object at 0x7fa0752d2d50>, <model.layers_custom.SparseTF object at 0x7fa0752d2b10>, <keras.layers.core.Dropout object at 0x7fa0cad62b90>, <model.layers_custom.SparseTF object at 0x7fa0cad62950>, <keras.layers.core.Dense object at 0x7fa0b4177d10>, <keras.layers.core.Dense object at 0x7fa0ae19a2d0>, <keras.layers.core.Dense object at 0x7fa0ebe3df90>, <keras.layers.core.Dense object at 0x7fa0752c0f10>, <keras.layers.core.Dense object at 0x7fa0d59fab50>, <keras.layers.core.Dense object at 0x7fa0cad47990>, <keras.layers.core.Activation object at 0x7fa0b4177290>, <keras.layers.core.Activation object at 0x7fa0f2bae150>, <keras.layers.core.Activation object at 0x7fa03993c650>, <keras.layers.core.Activation object at 0x7fa0752d24d0>, <keras.layers.core.Activation object at 0x7fa0cad62310>, <keras.layers.core.Activation object at 0x7fa0f2ba7e10>]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 27687)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h0 (Diagonal)                   (None, 9229)         36916       inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_0 (Dropout)             (None, 9229)         0           h0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h1 (SparseTF)                   (None, 1387)         17038       dropout_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1387)         0           h1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h2 (SparseTF)                   (None, 1066)         2462        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1066)         0           h2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h3 (SparseTF)                   (None, 447)          1517        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 447)          0           h3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h4 (SparseTF)                   (None, 147)          594         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 147)          0           h4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h5 (SparseTF)                   (None, 26)           174         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o_linear1 (Dense)               (None, 1)            9230        h0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear2 (Dense)               (None, 1)            1388        h1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear3 (Dense)               (None, 1)            1067        h2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear4 (Dense)               (None, 1)            448         h3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear5 (Dense)               (None, 1)            148         h4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear6 (Dense)               (None, 1)            27          h5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o1 (Activation)                 (None, 1)            0           o_linear1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o2 (Activation)                 (None, 1)            0           o_linear2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o3 (Activation)                 (None, 1)            0           o_linear3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o4 (Activation)                 (None, 1)            0           o_linear4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o5 (Activation)                 (None, 1)            0           o_linear5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o6 (Activation)                 (None, 1)            0           o_linear6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 71,009\n",
      "Trainable params: 71,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "# of trainable params of the model is 71009\n",
      "start fitting\n",
      "class_weight {0: 0.7458410351201479, 1: 1.5169172932330828}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 807 samples, validate on 102 samples\n",
      "Epoch 1/500\n",
      "2021-12-24 11:53:45.801070: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-24 11:53:45.804148: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 6s - loss: 424.1426 - o1_loss: 0.6426 - o2_loss: 0.6527 - o3_loss: 0.6590 - o4_loss: 0.6693 - o5_loss: 0.6771 - o6_loss: 0.6707 - o1_f1: 0.0124 - o2_f1: 0.0310 - o3_f1: 0.0242 - o4_f1: 0.0248 - o5_f1: 0.0207 - o6_f1: 0.0197 - val_loss: 408.3828 - val_o1_loss: 0.6247 - val_o2_loss: 0.6293 - val_o3_loss: 0.6296 - val_o4_loss: 0.6400 - val_o5_loss: 0.6552 - val_o6_loss: 0.6454 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 2/500\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 403.8134 - o1_loss: 0.6211 - o2_loss: 0.6363 - o3_loss: 0.6365 - o4_loss: 0.6354 - o5_loss: 0.6439 - o6_loss: 0.6383 - o1_f1: 0.0000e+00 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.9626 - val_o1_loss: 0.6159 - val_o2_loss: 0.6279 - val_o3_loss: 0.6298 - val_o4_loss: 0.6299 - val_o5_loss: 0.6311 - val_o6_loss: 0.6297 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 3/500\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.7788 - o1_loss: 0.6097 - o2_loss: 0.6330 - o3_loss: 0.6354 - o4_loss: 0.6352 - o5_loss: 0.6345 - o6_loss: 0.6345 - o1_f1: 0.0000e+00 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.8054 - val_o1_loss: 0.6096 - val_o2_loss: 0.6268 - val_o3_loss: 0.6292 - val_o4_loss: 0.6295 - val_o5_loss: 0.6300 - val_o6_loss: 0.6299 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.6059 - o1_loss: 0.5995 - o2_loss: 0.6297 - o3_loss: 0.6336 - o4_loss: 0.6341 - o5_loss: 0.6346 - o6_loss: 0.6344 - o1_f1: 0.0398 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.4983 - val_o1_loss: 0.6031 - val_o2_loss: 0.6258 - val_o3_loss: 0.6292 - val_o4_loss: 0.6297 - val_o5_loss: 0.6294 - val_o6_loss: 0.6295 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 5/500\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.7480 - o1_loss: 0.5905 - o2_loss: 0.6291 - o3_loss: 0.6346 - o4_loss: 0.6348 - o5_loss: 0.6347 - o6_loss: 0.6347 - o1_f1: 0.0488 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.6396 - val_o1_loss: 0.5984 - val_o2_loss: 0.6234 - val_o3_loss: 0.6288 - val_o4_loss: 0.6295 - val_o5_loss: 0.6298 - val_o6_loss: 0.6298 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 6/500\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.2523 - o1_loss: 0.5796 - o2_loss: 0.6252 - o3_loss: 0.6334 - o4_loss: 0.6340 - o5_loss: 0.6340 - o6_loss: 0.6340 - o1_f1: 0.0839 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.3657 - val_o1_loss: 0.5912 - val_o2_loss: 0.6207 - val_o3_loss: 0.6285 - val_o4_loss: 0.6293 - val_o5_loss: 0.6294 - val_o6_loss: 0.6294 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 7/500\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.0024 - o1_loss: 0.5729 - o2_loss: 0.6225 - o3_loss: 0.6331 - o4_loss: 0.6337 - o5_loss: 0.6337 - o6_loss: 0.6337 - o1_f1: 0.1853 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.8373 - val_o1_loss: 0.5794 - val_o2_loss: 0.6187 - val_o3_loss: 0.6302 - val_o4_loss: 0.6307 - val_o5_loss: 0.6301 - val_o6_loss: 0.6302 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 8/500\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.3385 - o1_loss: 0.5580 - o2_loss: 0.6169 - o3_loss: 0.6329 - o4_loss: 0.6344 - o5_loss: 0.6343 - o6_loss: 0.6344 - o1_f1: 0.1623 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.6392 - val_o1_loss: 0.5727 - val_o2_loss: 0.6113 - val_o3_loss: 0.6277 - val_o4_loss: 0.6296 - val_o5_loss: 0.6301 - val_o6_loss: 0.6301 - val_o1_f1: 0.1816 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 9/500\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.3594 - o1_loss: 0.5501 - o2_loss: 0.6113 - o3_loss: 0.6324 - o4_loss: 0.6344 - o5_loss: 0.6345 - o6_loss: 0.6345 - o1_f1: 0.2906 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.1988 - val_o1_loss: 0.5682 - val_o2_loss: 0.6040 - val_o3_loss: 0.6265 - val_o4_loss: 0.6290 - val_o5_loss: 0.6295 - val_o6_loss: 0.6295 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 10/500\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 399.9214 - o1_loss: 0.5429 - o2_loss: 0.6029 - o3_loss: 0.6315 - o4_loss: 0.6340 - o5_loss: 0.6338 - o6_loss: 0.6339 - o1_f1: 0.2697 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 396.9762 - val_o1_loss: 0.5599 - val_o2_loss: 0.5949 - val_o3_loss: 0.6251 - val_o4_loss: 0.6288 - val_o5_loss: 0.6292 - val_o6_loss: 0.6293 - val_o1_f1: 0.3680 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 400.2767 - o1_loss: 0.5341 - o2_loss: 0.5913 - o3_loss: 0.6295 - o4_loss: 0.6343 - o5_loss: 0.6346 - o6_loss: 0.6348 - o1_f1: 0.2544 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 396.8174 - val_o1_loss: 0.5538 - val_o2_loss: 0.5839 - val_o3_loss: 0.6229 - val_o4_loss: 0.6283 - val_o5_loss: 0.6292 - val_o6_loss: 0.6293 - val_o1_f1: 0.3779 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 399.4135 - o1_loss: 0.5170 - o2_loss: 0.5757 - o3_loss: 0.6255 - o4_loss: 0.6326 - o5_loss: 0.6336 - o6_loss: 0.6338 - o1_f1: 0.4115 - o2_f1: 0.0138 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 396.4459 - val_o1_loss: 0.5413 - val_o2_loss: 0.5687 - val_o3_loss: 0.6196 - val_o4_loss: 0.6278 - val_o5_loss: 0.6288 - val_o6_loss: 0.6290 - val_o1_f1: 0.3011 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 399.5766 - o1_loss: 0.5097 - o2_loss: 0.5625 - o3_loss: 0.6237 - o4_loss: 0.6334 - o5_loss: 0.6340 - o6_loss: 0.6342 - o1_f1: 0.3176 - o2_f1: 0.0223 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 396.1564 - val_o1_loss: 0.5499 - val_o2_loss: 0.5538 - val_o3_loss: 0.6145 - val_o4_loss: 0.6269 - val_o5_loss: 0.6286 - val_o6_loss: 0.6289 - val_o1_f1: 0.5017 - val_o2_f1: 0.1952 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/500\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 399.7313 - o1_loss: 0.5030 - o2_loss: 0.5487 - o3_loss: 0.6198 - o4_loss: 0.6336 - o5_loss: 0.6345 - o6_loss: 0.6349 - o1_f1: 0.5617 - o2_f1: 0.4831 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 395.9960 - val_o1_loss: 0.5396 - val_o2_loss: 0.5338 - val_o3_loss: 0.6084 - val_o4_loss: 0.6264 - val_o5_loss: 0.6287 - val_o6_loss: 0.6292 - val_o1_f1: 0.1816 - val_o2_f1: 0.1952 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 397.7612 - o1_loss: 0.5000 - o2_loss: 0.5241 - o3_loss: 0.6063 - o4_loss: 0.6284 - o5_loss: 0.6321 - o6_loss: 0.6326 - o1_f1: 0.3921 - o2_f1: 0.1561 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 394.8267 - val_o1_loss: 0.5265 - val_o2_loss: 0.5155 - val_o3_loss: 0.5981 - val_o4_loss: 0.6230 - val_o5_loss: 0.6273 - val_o6_loss: 0.6281 - val_o1_f1: 0.5174 - val_o2_f1: 0.3531 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 16/500\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 396.9573 - o1_loss: 0.4783 - o2_loss: 0.4984 - o3_loss: 0.5943 - o4_loss: 0.6257 - o5_loss: 0.6314 - o6_loss: 0.6323 - o1_f1: 0.5671 - o2_f1: 0.5424 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 393.7704 - val_o1_loss: 0.5135 - val_o2_loss: 0.4977 - val_o3_loss: 0.5845 - val_o4_loss: 0.6188 - val_o5_loss: 0.6262 - val_o6_loss: 0.6275 - val_o1_f1: 0.5178 - val_o2_f1: 0.5716 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 395.5994 - o1_loss: 0.4691 - o2_loss: 0.4755 - o3_loss: 0.5783 - o4_loss: 0.6205 - o5_loss: 0.6299 - o6_loss: 0.6313 - o1_f1: 0.4880 - o2_f1: 0.5263 - o3_f1: 0.0089 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 392.2011 - val_o1_loss: 0.5116 - val_o2_loss: 0.4761 - val_o3_loss: 0.5666 - val_o4_loss: 0.6120 - val_o5_loss: 0.6241 - val_o6_loss: 0.6264 - val_o1_f1: 0.5252 - val_o2_f1: 0.5716 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 18/500\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 394.2567 - o1_loss: 0.4630 - o2_loss: 0.4601 - o3_loss: 0.5605 - o4_loss: 0.6138 - o5_loss: 0.6280 - o6_loss: 0.6306 - o1_f1: 0.5916 - o2_f1: 0.6316 - o3_f1: 0.1161 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 390.0054 - val_o1_loss: 0.5033 - val_o2_loss: 0.4604 - val_o3_loss: 0.5457 - val_o4_loss: 0.6020 - val_o5_loss: 0.6207 - val_o6_loss: 0.6248 - val_o1_f1: 0.4105 - val_o2_f1: 0.5322 - val_o3_f1: 0.0377 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 19/500\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 391.1256 - o1_loss: 0.4536 - o2_loss: 0.4386 - o3_loss: 0.5352 - o4_loss: 0.6012 - o5_loss: 0.6232 - o6_loss: 0.6279 - o1_f1: 0.5891 - o2_f1: 0.6665 - o3_f1: 0.3278 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 386.7944 - val_o1_loss: 0.4927 - val_o2_loss: 0.4420 - val_o3_loss: 0.5221 - val_o4_loss: 0.5881 - val_o5_loss: 0.6151 - val_o6_loss: 0.6222 - val_o1_f1: 0.5415 - val_o2_f1: 0.6895 - val_o3_f1: 0.5086 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 388.2750 - o1_loss: 0.4479 - o2_loss: 0.4306 - o3_loss: 0.5127 - o4_loss: 0.5870 - o5_loss: 0.6177 - o6_loss: 0.6259 - o1_f1: 0.5283 - o2_f1: 0.6096 - o3_f1: 0.3151 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 383.1252 - val_o1_loss: 0.5182 - val_o2_loss: 0.4798 - val_o3_loss: 0.5122 - val_o4_loss: 0.5721 - val_o5_loss: 0.6066 - val_o6_loss: 0.6179 - val_o1_f1: 0.5570 - val_o2_f1: 0.6674 - val_o3_f1: 0.6691 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 21/500\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 382.6730 - o1_loss: 0.4477 - o2_loss: 0.4305 - o3_loss: 0.4923 - o4_loss: 0.5674 - o5_loss: 0.6066 - o6_loss: 0.6196 - o1_f1: 0.6017 - o2_f1: 0.6814 - o3_f1: 0.6084 - o4_f1: 0.0257 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 376.2121 - val_o1_loss: 0.4790 - val_o2_loss: 0.4177 - val_o3_loss: 0.4753 - val_o4_loss: 0.5482 - val_o5_loss: 0.5939 - val_o6_loss: 0.6116 - val_o1_f1: 0.5396 - val_o2_f1: 0.6429 - val_o3_f1: 0.5740 - val_o4_f1: 0.0377 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 374.9323 - o1_loss: 0.4228 - o2_loss: 0.3934 - o3_loss: 0.4576 - o4_loss: 0.5410 - o5_loss: 0.5920 - o6_loss: 0.6116 - o1_f1: 0.6016 - o2_f1: 0.6930 - o3_f1: 0.5754 - o4_f1: 0.1172 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 369.0042 - val_o1_loss: 0.4974 - val_o2_loss: 0.4362 - val_o3_loss: 0.4665 - val_o4_loss: 0.5269 - val_o5_loss: 0.5782 - val_o6_loss: 0.6022 - val_o1_f1: 0.5922 - val_o2_f1: 0.6674 - val_o3_f1: 0.6560 - val_o4_f1: 0.5086 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 23/500\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 365.2469 - o1_loss: 0.4137 - o2_loss: 0.3874 - o3_loss: 0.4347 - o4_loss: 0.5126 - o5_loss: 0.5723 - o6_loss: 0.5997 - o1_f1: 0.6984 - o2_f1: 0.7221 - o3_f1: 0.6924 - o4_f1: 0.5361 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 358.2975 - val_o1_loss: 0.4865 - val_o2_loss: 0.4323 - val_o3_loss: 0.4566 - val_o4_loss: 0.5004 - val_o5_loss: 0.5558 - val_o6_loss: 0.5877 - val_o1_f1: 0.5166 - val_o2_f1: 0.6644 - val_o3_f1: 0.6160 - val_o4_f1: 0.3813 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 24/500\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 353.8378 - o1_loss: 0.4202 - o2_loss: 0.3907 - o3_loss: 0.4265 - o4_loss: 0.4879 - o5_loss: 0.5498 - o6_loss: 0.5830 - o1_f1: 0.5888 - o2_f1: 0.6587 - o3_f1: 0.6069 - o4_f1: 0.4369 - o5_f1: 0.0822 - o6_f1: 0.0000e+00 - val_loss: 346.5823 - val_o1_loss: 0.4919 - val_o2_loss: 0.4325 - val_o3_loss: 0.4453 - val_o4_loss: 0.4797 - val_o5_loss: 0.5336 - val_o6_loss: 0.5699 - val_o1_f1: 0.6402 - val_o2_f1: 0.6555 - val_o3_f1: 0.6814 - val_o4_f1: 0.7199 - val_o5_f1: 0.4076 - val_o6_f1: 0.0000e+00\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 337.9052 - o1_loss: 0.4060 - o2_loss: 0.3671 - o3_loss: 0.3985 - o4_loss: 0.4565 - o5_loss: 0.5215 - o6_loss: 0.5597 - o1_f1: 0.6663 - o2_f1: 0.7518 - o3_f1: 0.7095 - o4_f1: 0.6500 - o5_f1: 0.3407 - o6_f1: 0.0000e+00 - val_loss: 329.1039 - val_o1_loss: 0.4544 - val_o2_loss: 0.3759 - val_o3_loss: 0.4040 - val_o4_loss: 0.4440 - val_o5_loss: 0.5036 - val_o6_loss: 0.5452 - val_o1_f1: 0.5863 - val_o2_f1: 0.6584 - val_o3_f1: 0.6093 - val_o4_f1: 0.6941 - val_o5_f1: 0.4839 - val_o6_f1: 0.0000e+00\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 320.6711 - o1_loss: 0.3959 - o2_loss: 0.3470 - o3_loss: 0.3751 - o4_loss: 0.4267 - o5_loss: 0.4922 - o6_loss: 0.5328 - o1_f1: 0.6902 - o2_f1: 0.7455 - o3_f1: 0.7239 - o4_f1: 0.6604 - o5_f1: 0.5163 - o6_f1: 0.2096 - val_loss: 313.2809 - val_o1_loss: 0.4476 - val_o2_loss: 0.3651 - val_o3_loss: 0.3878 - val_o4_loss: 0.4200 - val_o5_loss: 0.4774 - val_o6_loss: 0.5195 - val_o1_f1: 0.5719 - val_o2_f1: 0.7181 - val_o3_f1: 0.6825 - val_o4_f1: 0.6429 - val_o5_f1: 0.7115 - val_o6_f1: 0.3992\n",
      "Epoch 27/500\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 301.9877 - o1_loss: 0.3836 - o2_loss: 0.3329 - o3_loss: 0.3561 - o4_loss: 0.3987 - o5_loss: 0.4620 - o6_loss: 0.5022 - o1_f1: 0.6895 - o2_f1: 0.7633 - o3_f1: 0.7413 - o4_f1: 0.7348 - o5_f1: 0.6417 - o6_f1: 0.5022 - val_loss: 298.2684 - val_o1_loss: 0.4427 - val_o2_loss: 0.3607 - val_o3_loss: 0.3804 - val_o4_loss: 0.4025 - val_o5_loss: 0.4536 - val_o6_loss: 0.4934 - val_o1_f1: 0.5719 - val_o2_f1: 0.7223 - val_o3_f1: 0.6834 - val_o4_f1: 0.7136 - val_o5_f1: 0.6644 - val_o6_f1: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 285.7741 - o1_loss: 0.3790 - o2_loss: 0.3297 - o3_loss: 0.3490 - o4_loss: 0.3804 - o5_loss: 0.4367 - o6_loss: 0.4737 - o1_f1: 0.6860 - o2_f1: 0.7503 - o3_f1: 0.7403 - o4_f1: 0.7204 - o5_f1: 0.6778 - o6_f1: 0.6086 - val_loss: 286.6080 - val_o1_loss: 0.4427 - val_o2_loss: 0.3639 - val_o3_loss: 0.3814 - val_o4_loss: 0.3940 - val_o5_loss: 0.4361 - val_o6_loss: 0.4716 - val_o1_f1: 0.5799 - val_o2_f1: 0.6739 - val_o3_f1: 0.7094 - val_o4_f1: 0.6964 - val_o5_f1: 0.7051 - val_o6_f1: 0.6799\n",
      "Epoch 29/500\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 266.5868 - o1_loss: 0.3651 - o2_loss: 0.3118 - o3_loss: 0.3288 - o4_loss: 0.3557 - o5_loss: 0.4083 - o6_loss: 0.4408 - o1_f1: 0.7005 - o2_f1: 0.7752 - o3_f1: 0.7562 - o4_f1: 0.7480 - o5_f1: 0.7165 - o6_f1: 0.7078 - val_loss: 272.6396 - val_o1_loss: 0.4334 - val_o2_loss: 0.3490 - val_o3_loss: 0.3699 - val_o4_loss: 0.3797 - val_o5_loss: 0.4155 - val_o6_loss: 0.4469 - val_o1_f1: 0.5818 - val_o2_f1: 0.7008 - val_o3_f1: 0.6397 - val_o4_f1: 0.6732 - val_o5_f1: 0.6983 - val_o6_f1: 0.6941\n",
      "Epoch 30/500\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 256.2678 - o1_loss: 0.3667 - o2_loss: 0.3153 - o3_loss: 0.3314 - o4_loss: 0.3505 - o5_loss: 0.3935 - o6_loss: 0.4209 - o1_f1: 0.7214 - o2_f1: 0.7812 - o3_f1: 0.7689 - o4_f1: 0.7624 - o5_f1: 0.7254 - o6_f1: 0.7060 - val_loss: 261.8059 - val_o1_loss: 0.4266 - val_o2_loss: 0.3405 - val_o3_loss: 0.3600 - val_o4_loss: 0.3690 - val_o5_loss: 0.4010 - val_o6_loss: 0.4272 - val_o1_f1: 0.5794 - val_o2_f1: 0.6821 - val_o3_f1: 0.6545 - val_o4_f1: 0.6545 - val_o5_f1: 0.6799 - val_o6_f1: 0.7280\n",
      "Epoch 31/500\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 242.9793 - o1_loss: 0.3595 - o2_loss: 0.3053 - o3_loss: 0.3193 - o4_loss: 0.3355 - o5_loss: 0.3741 - o6_loss: 0.3975 - o1_f1: 0.7345 - o2_f1: 0.7663 - o3_f1: 0.7581 - o4_f1: 0.7501 - o5_f1: 0.7332 - o6_f1: 0.7237 - val_loss: 255.6274 - val_o1_loss: 0.4260 - val_o2_loss: 0.3426 - val_o3_loss: 0.3637 - val_o4_loss: 0.3687 - val_o5_loss: 0.3920 - val_o6_loss: 0.4148 - val_o1_f1: 0.5818 - val_o2_f1: 0.7181 - val_o3_f1: 0.6674 - val_o4_f1: 0.6674 - val_o5_f1: 0.6895 - val_o6_f1: 0.6983\n",
      "Epoch 32/500\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 233.4822 - o1_loss: 0.3532 - o2_loss: 0.3021 - o3_loss: 0.3162 - o4_loss: 0.3295 - o5_loss: 0.3610 - o6_loss: 0.3796 - o1_f1: 0.7385 - o2_f1: 0.7939 - o3_f1: 0.7698 - o4_f1: 0.7664 - o5_f1: 0.7395 - o6_f1: 0.7507 - val_loss: 247.0967 - val_o1_loss: 0.4193 - val_o2_loss: 0.3317 - val_o3_loss: 0.3486 - val_o4_loss: 0.3573 - val_o5_loss: 0.3817 - val_o6_loss: 0.3996 - val_o1_f1: 0.5719 - val_o2_f1: 0.6950 - val_o3_f1: 0.6786 - val_o4_f1: 0.6786 - val_o5_f1: 0.6382 - val_o6_f1: 0.6234\n",
      "Epoch 33/500\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 219.5113 - o1_loss: 0.3457 - o2_loss: 0.2863 - o3_loss: 0.2968 - o4_loss: 0.3096 - o5_loss: 0.3407 - o6_loss: 0.3560 - o1_f1: 0.7694 - o2_f1: 0.8028 - o3_f1: 0.7976 - o4_f1: 0.7879 - o5_f1: 0.7734 - o6_f1: 0.7718 - val_loss: 243.2363 - val_o1_loss: 0.4215 - val_o2_loss: 0.3317 - val_o3_loss: 0.3472 - val_o4_loss: 0.3552 - val_o5_loss: 0.3766 - val_o6_loss: 0.3921 - val_o1_f1: 0.5952 - val_o2_f1: 0.6697 - val_o3_f1: 0.7219 - val_o4_f1: 0.7219 - val_o5_f1: 0.7219 - val_o6_f1: 0.6658\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 209.1313 - o1_loss: 0.3402 - o2_loss: 0.2762 - o3_loss: 0.2850 - o4_loss: 0.2969 - o5_loss: 0.3254 - o6_loss: 0.3381 - o1_f1: 0.7786 - o2_f1: 0.8050 - o3_f1: 0.7909 - o4_f1: 0.7875 - o5_f1: 0.7720 - o6_f1: 0.7676 - val_loss: 237.1924 - val_o1_loss: 0.4165 - val_o2_loss: 0.3283 - val_o3_loss: 0.3424 - val_o4_loss: 0.3498 - val_o5_loss: 0.3680 - val_o6_loss: 0.3811 - val_o1_f1: 0.6038 - val_o2_f1: 0.6697 - val_o3_f1: 0.7219 - val_o4_f1: 0.7219 - val_o5_f1: 0.7219 - val_o6_f1: 0.6786\n",
      "Epoch 35/500\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 201.5918 - o1_loss: 0.3342 - o2_loss: 0.2704 - o3_loss: 0.2788 - o4_loss: 0.2887 - o5_loss: 0.3144 - o6_loss: 0.3247 - o1_f1: 0.7941 - o2_f1: 0.8020 - o3_f1: 0.8010 - o4_f1: 0.7971 - o5_f1: 0.7887 - o6_f1: 0.7824 - val_loss: 231.8545 - val_o1_loss: 0.4095 - val_o2_loss: 0.3231 - val_o3_loss: 0.3361 - val_o4_loss: 0.3438 - val_o5_loss: 0.3605 - val_o6_loss: 0.3716 - val_o1_f1: 0.6046 - val_o2_f1: 0.6786 - val_o3_f1: 0.6786 - val_o4_f1: 0.6786 - val_o5_f1: 0.6786 - val_o6_f1: 0.6786\n",
      "Epoch 36/500\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 197.1563 - o1_loss: 0.3317 - o2_loss: 0.2692 - o3_loss: 0.2785 - o4_loss: 0.2866 - o5_loss: 0.3072 - o6_loss: 0.3165 - o1_f1: 0.7708 - o2_f1: 0.8133 - o3_f1: 0.8094 - o4_f1: 0.8031 - o5_f1: 0.7875 - o6_f1: 0.7920 - val_loss: 228.5721 - val_o1_loss: 0.4063 - val_o2_loss: 0.3191 - val_o3_loss: 0.3331 - val_o4_loss: 0.3407 - val_o5_loss: 0.3550 - val_o6_loss: 0.3660 - val_o1_f1: 0.5882 - val_o2_f1: 0.7044 - val_o3_f1: 0.7044 - val_o4_f1: 0.6914 - val_o5_f1: 0.6658 - val_o6_f1: 0.6779\n",
      "Epoch 37/500\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 190.0146 - o1_loss: 0.3294 - o2_loss: 0.2624 - o3_loss: 0.2690 - o4_loss: 0.2768 - o5_loss: 0.2963 - o6_loss: 0.3045 - o1_f1: 0.7667 - o2_f1: 0.8034 - o3_f1: 0.8039 - o4_f1: 0.7997 - o5_f1: 0.7906 - o6_f1: 0.8043 - val_loss: 227.5120 - val_o1_loss: 0.4061 - val_o2_loss: 0.3194 - val_o3_loss: 0.3308 - val_o4_loss: 0.3395 - val_o5_loss: 0.3544 - val_o6_loss: 0.3638 - val_o1_f1: 0.6186 - val_o2_f1: 0.6697 - val_o3_f1: 0.6786 - val_o4_f1: 0.7219 - val_o5_f1: 0.7219 - val_o6_f1: 0.6610\n",
      "Epoch 38/500\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 188.2346 - o1_loss: 0.3276 - o2_loss: 0.2605 - o3_loss: 0.2676 - o4_loss: 0.2754 - o5_loss: 0.2932 - o6_loss: 0.3014 - o1_f1: 0.7776 - o2_f1: 0.8281 - o3_f1: 0.8222 - o4_f1: 0.8190 - o5_f1: 0.8052 - o6_f1: 0.8068 - val_loss: 225.5814 - val_o1_loss: 0.4032 - val_o2_loss: 0.3188 - val_o3_loss: 0.3291 - val_o4_loss: 0.3375 - val_o5_loss: 0.3515 - val_o6_loss: 0.3603 - val_o1_f1: 0.6327 - val_o2_f1: 0.6697 - val_o3_f1: 0.7219 - val_o4_f1: 0.7219 - val_o5_f1: 0.7219 - val_o6_f1: 0.6610\n",
      "Epoch 39/500\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 174.8369 - o1_loss: 0.3172 - o2_loss: 0.2457 - o3_loss: 0.2495 - o4_loss: 0.2555 - o5_loss: 0.2747 - o6_loss: 0.2786 - o1_f1: 0.8029 - o2_f1: 0.8480 - o3_f1: 0.8433 - o4_f1: 0.8413 - o5_f1: 0.8250 - o6_f1: 0.8217 - val_loss: 221.8752 - val_o1_loss: 0.3997 - val_o2_loss: 0.3144 - val_o3_loss: 0.3256 - val_o4_loss: 0.3333 - val_o5_loss: 0.3455 - val_o6_loss: 0.3540 - val_o1_f1: 0.6069 - val_o2_f1: 0.7044 - val_o3_f1: 0.7044 - val_o4_f1: 0.6914 - val_o5_f1: 0.6821 - val_o6_f1: 0.6914\n",
      "Epoch 40/500\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 171.4536 - o1_loss: 0.3149 - o2_loss: 0.2425 - o3_loss: 0.2459 - o4_loss: 0.2514 - o5_loss: 0.2691 - o6_loss: 0.2729 - o1_f1: 0.8002 - o2_f1: 0.8412 - o3_f1: 0.8468 - o4_f1: 0.8381 - o5_f1: 0.8409 - o6_f1: 0.8351 - val_loss: 224.1599 - val_o1_loss: 0.3993 - val_o2_loss: 0.3178 - val_o3_loss: 0.3313 - val_o4_loss: 0.3393 - val_o5_loss: 0.3477 - val_o6_loss: 0.3576 - val_o1_f1: 0.5981 - val_o2_f1: 0.7181 - val_o3_f1: 0.6965 - val_o4_f1: 0.7101 - val_o5_f1: 0.6914 - val_o6_f1: 0.7101\n",
      "Epoch 41/500\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 169.1467 - o1_loss: 0.3118 - o2_loss: 0.2407 - o3_loss: 0.2443 - o4_loss: 0.2491 - o5_loss: 0.2638 - o6_loss: 0.2694 - o1_f1: 0.7789 - o2_f1: 0.8200 - o3_f1: 0.8145 - o4_f1: 0.8139 - o5_f1: 0.8057 - o6_f1: 0.8077 - val_loss: 224.1157 - val_o1_loss: 0.3973 - val_o2_loss: 0.3162 - val_o3_loss: 0.3241 - val_o4_loss: 0.3340 - val_o5_loss: 0.3483 - val_o6_loss: 0.3583 - val_o1_f1: 0.6821 - val_o2_f1: 0.6610 - val_o3_f1: 0.7129 - val_o4_f1: 0.7219 - val_o5_f1: 0.7129 - val_o6_f1: 0.6883\n",
      "Epoch 42/500\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 157.5090 - o1_loss: 0.3064 - o2_loss: 0.2279 - o3_loss: 0.2290 - o4_loss: 0.2324 - o5_loss: 0.2476 - o6_loss: 0.2495 - o1_f1: 0.8032 - o2_f1: 0.8485 - o3_f1: 0.8430 - o4_f1: 0.8440 - o5_f1: 0.8405 - o6_f1: 0.8412 - val_loss: 236.3912 - val_o1_loss: 0.4067 - val_o2_loss: 0.3323 - val_o3_loss: 0.3428 - val_o4_loss: 0.3539 - val_o5_loss: 0.3623 - val_o6_loss: 0.3798 - val_o1_f1: 0.6483 - val_o2_f1: 0.6739 - val_o3_f1: 0.6739 - val_o4_f1: 0.6528 - val_o5_f1: 0.6610 - val_o6_f1: 0.6610\n",
      "Epoch 43/500\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 148.1569 - o1_loss: 0.3007 - o2_loss: 0.2170 - o3_loss: 0.2156 - o4_loss: 0.2177 - o5_loss: 0.2334 - o6_loss: 0.2341 - o1_f1: 0.8075 - o2_f1: 0.8412 - o3_f1: 0.8315 - o4_f1: 0.8386 - o5_f1: 0.8423 - o6_f1: 0.8372 - val_loss: 220.8807 - val_o1_loss: 0.3909 - val_o2_loss: 0.3139 - val_o3_loss: 0.3201 - val_o4_loss: 0.3299 - val_o5_loss: 0.3435 - val_o6_loss: 0.3526 - val_o1_f1: 0.6625 - val_o2_f1: 0.6774 - val_o3_f1: 0.7309 - val_o4_f1: 0.7219 - val_o5_f1: 0.7129 - val_o6_f1: 0.6466\n",
      "Epoch 44/500\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 144.8307 - o1_loss: 0.2990 - o2_loss: 0.2154 - o3_loss: 0.2135 - o4_loss: 0.2144 - o5_loss: 0.2288 - o6_loss: 0.2280 - o1_f1: 0.7954 - o2_f1: 0.8556 - o3_f1: 0.8550 - o4_f1: 0.8626 - o5_f1: 0.8508 - o6_f1: 0.8555 - val_loss: 227.5274 - val_o1_loss: 0.3906 - val_o2_loss: 0.3188 - val_o3_loss: 0.3257 - val_o4_loss: 0.3377 - val_o5_loss: 0.3522 - val_o6_loss: 0.3645 - val_o1_f1: 0.6821 - val_o2_f1: 0.7043 - val_o3_f1: 0.7043 - val_o4_f1: 0.6883 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 45/500\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 136.4278 - o1_loss: 0.2946 - o2_loss: 0.2064 - o3_loss: 0.2028 - o4_loss: 0.2025 - o5_loss: 0.2159 - o6_loss: 0.2140 - o1_f1: 0.8176 - o2_f1: 0.8606 - o3_f1: 0.8621 - o4_f1: 0.8646 - o5_f1: 0.8559 - o6_f1: 0.8601 - val_loss: 226.1736 - val_o1_loss: 0.3922 - val_o2_loss: 0.3175 - val_o3_loss: 0.3241 - val_o4_loss: 0.3357 - val_o5_loss: 0.3495 - val_o6_loss: 0.3624 - val_o1_f1: 0.6732 - val_o2_f1: 0.7043 - val_o3_f1: 0.7043 - val_o4_f1: 0.6883 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 46/500\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 135.8974 - o1_loss: 0.2933 - o2_loss: 0.2052 - o3_loss: 0.2023 - o4_loss: 0.2022 - o5_loss: 0.2140 - o6_loss: 0.2134 - o1_f1: 0.8475 - o2_f1: 0.8871 - o3_f1: 0.8839 - o4_f1: 0.8947 - o5_f1: 0.8848 - o6_f1: 0.8822 - val_loss: 217.8169 - val_o1_loss: 0.3863 - val_o2_loss: 0.3096 - val_o3_loss: 0.3154 - val_o4_loss: 0.3242 - val_o5_loss: 0.3374 - val_o6_loss: 0.3480 - val_o1_f1: 0.6821 - val_o2_f1: 0.6860 - val_o3_f1: 0.6950 - val_o4_f1: 0.6950 - val_o5_f1: 0.6697 - val_o6_f1: 0.6610\n",
      "Epoch 47/500\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 134.5184 - o1_loss: 0.2897 - o2_loss: 0.2019 - o3_loss: 0.1996 - o4_loss: 0.2006 - o5_loss: 0.2111 - o6_loss: 0.2113 - o1_f1: 0.8110 - o2_f1: 0.8584 - o3_f1: 0.8595 - o4_f1: 0.8652 - o5_f1: 0.8624 - o6_f1: 0.8713 - val_loss: 223.6807 - val_o1_loss: 0.3862 - val_o2_loss: 0.3158 - val_o3_loss: 0.3207 - val_o4_loss: 0.3311 - val_o5_loss: 0.3456 - val_o6_loss: 0.3582 - val_o1_f1: 0.6821 - val_o2_f1: 0.7043 - val_o3_f1: 0.7043 - val_o4_f1: 0.7043 - val_o5_f1: 0.7043 - val_o6_f1: 0.6739\n",
      "Epoch 48/500\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 120.8655 - o1_loss: 0.2860 - o2_loss: 0.1902 - o3_loss: 0.1833 - o4_loss: 0.1802 - o5_loss: 0.1917 - o6_loss: 0.1880 - o1_f1: 0.8370 - o2_f1: 0.8945 - o3_f1: 0.8918 - o4_f1: 0.8891 - o5_f1: 0.8916 - o6_f1: 0.8959 - val_loss: 221.4315 - val_o1_loss: 0.3832 - val_o2_loss: 0.3117 - val_o3_loss: 0.3162 - val_o4_loss: 0.3270 - val_o5_loss: 0.3426 - val_o6_loss: 0.3545 - val_o1_f1: 0.6821 - val_o2_f1: 0.6860 - val_o3_f1: 0.7309 - val_o4_f1: 0.7309 - val_o5_f1: 0.7043 - val_o6_f1: 0.6739\n",
      "Epoch 49/500\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 1s - loss: 115.9726 - o1_loss: 0.2823 - o2_loss: 0.1852 - o3_loss: 0.1775 - o4_loss: 0.1735 - o5_loss: 0.1839 - o6_loss: 0.1799 - o1_f1: 0.8393 - o2_f1: 0.8989 - o3_f1: 0.9032 - o4_f1: 0.9070 - o5_f1: 0.9087 - o6_f1: 0.9050 - val_loss: 219.1854 - val_o1_loss: 0.3797 - val_o2_loss: 0.3081 - val_o3_loss: 0.3133 - val_o4_loss: 0.3241 - val_o5_loss: 0.3390 - val_o6_loss: 0.3507 - val_o1_f1: 0.6686 - val_o2_f1: 0.6821 - val_o3_f1: 0.6950 - val_o4_f1: 0.7044 - val_o5_f1: 0.7129 - val_o6_f1: 0.7043\n",
      "Epoch 50/500\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 111.4443 - o1_loss: 0.2802 - o2_loss: 0.1807 - o3_loss: 0.1720 - o4_loss: 0.1673 - o5_loss: 0.1773 - o6_loss: 0.1722 - o1_f1: 0.8469 - o2_f1: 0.9002 - o3_f1: 0.9139 - o4_f1: 0.9179 - o5_f1: 0.9131 - o6_f1: 0.9124 - val_loss: 223.6485 - val_o1_loss: 0.3811 - val_o2_loss: 0.3120 - val_o3_loss: 0.3174 - val_o4_loss: 0.3296 - val_o5_loss: 0.3445 - val_o6_loss: 0.3588 - val_o1_f1: 0.6821 - val_o2_f1: 0.7309 - val_o3_f1: 0.7223 - val_o4_f1: 0.7043 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 51/500\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 111.8177 - o1_loss: 0.2798 - o2_loss: 0.1809 - o3_loss: 0.1727 - o4_loss: 0.1681 - o5_loss: 0.1779 - o6_loss: 0.1727 - o1_f1: 0.8453 - o2_f1: 0.9076 - o3_f1: 0.9128 - o4_f1: 0.9172 - o5_f1: 0.9201 - o6_f1: 0.9192 - val_loss: 218.8207 - val_o1_loss: 0.3791 - val_o2_loss: 0.3074 - val_o3_loss: 0.3127 - val_o4_loss: 0.3236 - val_o5_loss: 0.3384 - val_o6_loss: 0.3501 - val_o1_f1: 0.6686 - val_o2_f1: 0.6821 - val_o3_f1: 0.6950 - val_o4_f1: 0.7044 - val_o5_f1: 0.7309 - val_o6_f1: 0.6610\n",
      "Epoch 52/500\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 110.6307 - o1_loss: 0.2793 - o2_loss: 0.1796 - o3_loss: 0.1709 - o4_loss: 0.1660 - o5_loss: 0.1754 - o6_loss: 0.1711 - o1_f1: 0.8401 - o2_f1: 0.9013 - o3_f1: 0.9025 - o4_f1: 0.9100 - o5_f1: 0.9141 - o6_f1: 0.9176 - val_loss: 223.3016 - val_o1_loss: 0.3803 - val_o2_loss: 0.3107 - val_o3_loss: 0.3155 - val_o4_loss: 0.3276 - val_o5_loss: 0.3437 - val_o6_loss: 0.3586 - val_o1_f1: 0.6821 - val_o2_f1: 0.6860 - val_o3_f1: 0.7399 - val_o4_f1: 0.7309 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 53/500\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 109.5090 - o1_loss: 0.2793 - o2_loss: 0.1791 - o3_loss: 0.1701 - o4_loss: 0.1649 - o5_loss: 0.1737 - o6_loss: 0.1690 - o1_f1: 0.8397 - o2_f1: 0.8921 - o3_f1: 0.8975 - o4_f1: 0.9038 - o5_f1: 0.9074 - o6_f1: 0.9134 - val_loss: 223.1452 - val_o1_loss: 0.3791 - val_o2_loss: 0.3104 - val_o3_loss: 0.3152 - val_o4_loss: 0.3273 - val_o5_loss: 0.3432 - val_o6_loss: 0.3584 - val_o1_f1: 0.6821 - val_o2_f1: 0.6860 - val_o3_f1: 0.7399 - val_o4_f1: 0.7309 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 54/500\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 108.3536 - o1_loss: 0.2782 - o2_loss: 0.1774 - o3_loss: 0.1683 - o4_loss: 0.1629 - o5_loss: 0.1723 - o6_loss: 0.1670 - o1_f1: 0.8535 - o2_f1: 0.9173 - o3_f1: 0.9149 - o4_f1: 0.9201 - o5_f1: 0.9172 - o6_f1: 0.9149 - val_loss: 222.8162 - val_o1_loss: 0.3791 - val_o2_loss: 0.3100 - val_o3_loss: 0.3147 - val_o4_loss: 0.3267 - val_o5_loss: 0.3429 - val_o6_loss: 0.3578 - val_o1_f1: 0.6821 - val_o2_f1: 0.6860 - val_o3_f1: 0.7399 - val_o4_f1: 0.7309 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 55/500\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 105.9078 - o1_loss: 0.2772 - o2_loss: 0.1750 - o3_loss: 0.1652 - o4_loss: 0.1594 - o5_loss: 0.1683 - o6_loss: 0.1630 - o1_f1: 0.8512 - o2_f1: 0.9052 - o3_f1: 0.9095 - o4_f1: 0.9181 - o5_f1: 0.9153 - o6_f1: 0.9141 - val_loss: 222.5515 - val_o1_loss: 0.3787 - val_o2_loss: 0.3097 - val_o3_loss: 0.3143 - val_o4_loss: 0.3264 - val_o5_loss: 0.3425 - val_o6_loss: 0.3573 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7399 - val_o4_f1: 0.7309 - val_o5_f1: 0.6883 - val_o6_f1: 0.6883\n",
      "Epoch 56/500\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 105.6620 - o1_loss: 0.2773 - o2_loss: 0.1751 - o3_loss: 0.1653 - o4_loss: 0.1594 - o5_loss: 0.1680 - o6_loss: 0.1625 - o1_f1: 0.8539 - o2_f1: 0.9046 - o3_f1: 0.9033 - o4_f1: 0.9106 - o5_f1: 0.9145 - o6_f1: 0.9169 - val_loss: 220.6855 - val_o1_loss: 0.3775 - val_o2_loss: 0.3083 - val_o3_loss: 0.3130 - val_o4_loss: 0.3246 - val_o5_loss: 0.3402 - val_o6_loss: 0.3538 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7399 - val_o4_f1: 0.7399 - val_o5_f1: 0.7309 - val_o6_f1: 0.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 103.1815 - o1_loss: 0.2759 - o2_loss: 0.1722 - o3_loss: 0.1619 - o4_loss: 0.1555 - o5_loss: 0.1642 - o6_loss: 0.1585 - o1_f1: 0.8589 - o2_f1: 0.9030 - o3_f1: 0.9126 - o4_f1: 0.9199 - o5_f1: 0.9215 - o6_f1: 0.9197 - val_loss: 224.3347 - val_o1_loss: 0.3784 - val_o2_loss: 0.3112 - val_o3_loss: 0.3158 - val_o4_loss: 0.3282 - val_o5_loss: 0.3442 - val_o6_loss: 0.3607 - val_o1_f1: 0.6821 - val_o2_f1: 0.7309 - val_o3_f1: 0.7309 - val_o4_f1: 0.7309 - val_o5_f1: 0.6883 - val_o6_f1: 0.6739\n",
      "Epoch 58/500\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 103.2901 - o1_loss: 0.2760 - o2_loss: 0.1723 - o3_loss: 0.1620 - o4_loss: 0.1558 - o5_loss: 0.1643 - o6_loss: 0.1586 - o1_f1: 0.8431 - o2_f1: 0.9075 - o3_f1: 0.9121 - o4_f1: 0.9109 - o5_f1: 0.9139 - o6_f1: 0.9155 - val_loss: 222.3220 - val_o1_loss: 0.3773 - val_o2_loss: 0.3097 - val_o3_loss: 0.3143 - val_o4_loss: 0.3260 - val_o5_loss: 0.3415 - val_o6_loss: 0.3571 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7399 - val_o4_f1: 0.7309 - val_o5_f1: 0.6969 - val_o6_f1: 0.6883\n",
      "Epoch 59/500\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 102.5911 - o1_loss: 0.2753 - o2_loss: 0.1715 - o3_loss: 0.1613 - o4_loss: 0.1549 - o5_loss: 0.1632 - o6_loss: 0.1574 - o1_f1: 0.8510 - o2_f1: 0.9088 - o3_f1: 0.9160 - o4_f1: 0.9174 - o5_f1: 0.9078 - o6_f1: 0.9165 - val_loss: 220.6734 - val_o1_loss: 0.3763 - val_o2_loss: 0.3082 - val_o3_loss: 0.3130 - val_o4_loss: 0.3245 - val_o5_loss: 0.3398 - val_o6_loss: 0.3539 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.6821 - val_o4_f1: 0.7044 - val_o5_f1: 0.7309 - val_o6_f1: 0.7043\n",
      "Epoch 60/500\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 100.3796 - o1_loss: 0.2742 - o2_loss: 0.1693 - o3_loss: 0.1585 - o4_loss: 0.1517 - o5_loss: 0.1598 - o6_loss: 0.1538 - o1_f1: 0.8486 - o2_f1: 0.9103 - o3_f1: 0.9204 - o4_f1: 0.9227 - o5_f1: 0.9205 - o6_f1: 0.9248 - val_loss: 226.3325 - val_o1_loss: 0.3776 - val_o2_loss: 0.3128 - val_o3_loss: 0.3176 - val_o4_loss: 0.3304 - val_o5_loss: 0.3465 - val_o6_loss: 0.3644 - val_o1_f1: 0.6821 - val_o2_f1: 0.7309 - val_o3_f1: 0.7309 - val_o4_f1: 0.7345 - val_o5_f1: 0.6883 - val_o6_f1: 0.6732\n",
      "Epoch 61/500\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 99.9080 - o1_loss: 0.2740 - o2_loss: 0.1689 - o3_loss: 0.1580 - o4_loss: 0.1511 - o5_loss: 0.1592 - o6_loss: 0.1529 - o1_f1: 0.8528 - o2_f1: 0.9219 - o3_f1: 0.9232 - o4_f1: 0.9268 - o5_f1: 0.9216 - o6_f1: 0.9284 - val_loss: 221.3592 - val_o1_loss: 0.3759 - val_o2_loss: 0.3084 - val_o3_loss: 0.3131 - val_o4_loss: 0.3248 - val_o5_loss: 0.3406 - val_o6_loss: 0.3552 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7309 - val_o6_f1: 0.7043\n",
      "Epoch 62/500\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 99.2585 - o1_loss: 0.2733 - o2_loss: 0.1678 - o3_loss: 0.1570 - o4_loss: 0.1502 - o5_loss: 0.1577 - o6_loss: 0.1520 - o1_f1: 0.8454 - o2_f1: 0.9017 - o3_f1: 0.9103 - o4_f1: 0.9156 - o5_f1: 0.9149 - o6_f1: 0.9175 - val_loss: 222.7509 - val_o1_loss: 0.3758 - val_o2_loss: 0.3091 - val_o3_loss: 0.3137 - val_o4_loss: 0.3259 - val_o5_loss: 0.3421 - val_o6_loss: 0.3579 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7399 - val_o4_f1: 0.7399 - val_o5_f1: 0.7129 - val_o6_f1: 0.7043\n",
      "Epoch 63/500\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 98.0761 - o1_loss: 0.2732 - o2_loss: 0.1668 - o3_loss: 0.1556 - o4_loss: 0.1484 - o5_loss: 0.1560 - o6_loss: 0.1499 - o1_f1: 0.8477 - o2_f1: 0.9073 - o3_f1: 0.9216 - o4_f1: 0.9273 - o5_f1: 0.9207 - o6_f1: 0.9231 - val_loss: 226.3352 - val_o1_loss: 0.3763 - val_o2_loss: 0.3117 - val_o3_loss: 0.3167 - val_o4_loss: 0.3298 - val_o5_loss: 0.3464 - val_o6_loss: 0.3646 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7309 - val_o4_f1: 0.7345 - val_o5_f1: 0.6883 - val_o6_f1: 0.6861\n",
      "Epoch 64/500\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 98.6599 - o1_loss: 0.2725 - o2_loss: 0.1669 - o3_loss: 0.1561 - o4_loss: 0.1491 - o5_loss: 0.1568 - o6_loss: 0.1510 - o1_f1: 0.8648 - o2_f1: 0.9347 - o3_f1: 0.9367 - o4_f1: 0.9342 - o5_f1: 0.9338 - o6_f1: 0.9348 - val_loss: 221.9441 - val_o1_loss: 0.3750 - val_o2_loss: 0.3084 - val_o3_loss: 0.3130 - val_o4_loss: 0.3252 - val_o5_loss: 0.3412 - val_o6_loss: 0.3564 - val_o1_f1: 0.6686 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7309 - val_o6_f1: 0.7043\n",
      "Epoch 65/500\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 97.9717 - o1_loss: 0.2725 - o2_loss: 0.1659 - o3_loss: 0.1551 - o4_loss: 0.1485 - o5_loss: 0.1552 - o6_loss: 0.1500 - o1_f1: 0.8432 - o2_f1: 0.9009 - o3_f1: 0.9076 - o4_f1: 0.9172 - o5_f1: 0.9162 - o6_f1: 0.9200 - val_loss: 226.0912 - val_o1_loss: 0.3758 - val_o2_loss: 0.3117 - val_o3_loss: 0.3163 - val_o4_loss: 0.3293 - val_o5_loss: 0.3458 - val_o6_loss: 0.3642 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7309 - val_o4_f1: 0.7345 - val_o5_f1: 0.6883 - val_o6_f1: 0.6861\n",
      "Epoch 66/500\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 95.7329 - o1_loss: 0.2712 - o2_loss: 0.1641 - o3_loss: 0.1526 - o4_loss: 0.1450 - o5_loss: 0.1524 - o6_loss: 0.1461 - o1_f1: 0.8607 - o2_f1: 0.9330 - o3_f1: 0.9407 - o4_f1: 0.9333 - o5_f1: 0.9329 - o6_f1: 0.9340 - val_loss: 223.4181 - val_o1_loss: 0.3748 - val_o2_loss: 0.3094 - val_o3_loss: 0.3140 - val_o4_loss: 0.3265 - val_o5_loss: 0.3426 - val_o6_loss: 0.3592 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7129 - val_o6_f1: 0.6883\n",
      "Epoch 67/500\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 94.3908 - o1_loss: 0.2713 - o2_loss: 0.1625 - o3_loss: 0.1507 - o4_loss: 0.1432 - o5_loss: 0.1500 - o6_loss: 0.1439 - o1_f1: 0.8419 - o2_f1: 0.9045 - o3_f1: 0.9209 - o4_f1: 0.9252 - o5_f1: 0.9212 - o6_f1: 0.9226 - val_loss: 225.8609 - val_o1_loss: 0.3746 - val_o2_loss: 0.3112 - val_o3_loss: 0.3158 - val_o4_loss: 0.3289 - val_o5_loss: 0.3454 - val_o6_loss: 0.3638 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7309 - val_o4_f1: 0.7432 - val_o5_f1: 0.6883 - val_o6_f1: 0.7004\n",
      "Epoch 68/500\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 94.4808 - o1_loss: 0.2708 - o2_loss: 0.1628 - o3_loss: 0.1511 - o4_loss: 0.1433 - o5_loss: 0.1504 - o6_loss: 0.1439 - o1_f1: 0.8646 - o2_f1: 0.9323 - o3_f1: 0.9313 - o4_f1: 0.9353 - o5_f1: 0.9289 - o6_f1: 0.9295 - val_loss: 223.7237 - val_o1_loss: 0.3746 - val_o2_loss: 0.3096 - val_o3_loss: 0.3140 - val_o4_loss: 0.3266 - val_o5_loss: 0.3430 - val_o6_loss: 0.3598 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7129 - val_o6_f1: 0.7043\n",
      "Epoch 69/500\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 92.7094 - o1_loss: 0.2699 - o2_loss: 0.1607 - o3_loss: 0.1486 - o4_loss: 0.1408 - o5_loss: 0.1473 - o6_loss: 0.1411 - o1_f1: 0.8603 - o2_f1: 0.9169 - o3_f1: 0.9233 - o4_f1: 0.9345 - o5_f1: 0.9321 - o6_f1: 0.9311 - val_loss: 223.8037 - val_o1_loss: 0.3738 - val_o2_loss: 0.3093 - val_o3_loss: 0.3138 - val_o4_loss: 0.3266 - val_o5_loss: 0.3431 - val_o6_loss: 0.3599 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7129 - val_o6_f1: 0.7043\n",
      "Epoch 70/500\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 91.8136 - o1_loss: 0.2696 - o2_loss: 0.1600 - o3_loss: 0.1477 - o4_loss: 0.1396 - o5_loss: 0.1460 - o6_loss: 0.1396 - o1_f1: 0.8394 - o2_f1: 0.9094 - o3_f1: 0.9207 - o4_f1: 0.9262 - o5_f1: 0.9254 - o6_f1: 0.9303 - val_loss: 224.9912 - val_o1_loss: 0.3729 - val_o2_loss: 0.3098 - val_o3_loss: 0.3144 - val_o4_loss: 0.3276 - val_o5_loss: 0.3443 - val_o6_loss: 0.3623 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7043 - val_o6_f1: 0.7004\n",
      "Epoch 71/500\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.00025.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 90.5071 - o1_loss: 0.2687 - o2_loss: 0.1585 - o3_loss: 0.1459 - o4_loss: 0.1376 - o5_loss: 0.1441 - o6_loss: 0.1374 - o1_f1: 0.8503 - o2_f1: 0.9154 - o3_f1: 0.9268 - o4_f1: 0.9362 - o5_f1: 0.9300 - o6_f1: 0.9348 - val_loss: 223.7450 - val_o1_loss: 0.3727 - val_o2_loss: 0.3090 - val_o3_loss: 0.3136 - val_o4_loss: 0.3264 - val_o5_loss: 0.3428 - val_o6_loss: 0.3599 - val_o1_f1: 0.6686 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7129 - val_o6_f1: 0.7165\n",
      "Epoch 72/500\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 89.5609 - o1_loss: 0.2683 - o2_loss: 0.1574 - o3_loss: 0.1446 - o4_loss: 0.1362 - o5_loss: 0.1426 - o6_loss: 0.1358 - o1_f1: 0.8550 - o2_f1: 0.9228 - o3_f1: 0.9322 - o4_f1: 0.9384 - o5_f1: 0.9364 - o6_f1: 0.9374 - val_loss: 224.5848 - val_o1_loss: 0.3727 - val_o2_loss: 0.3098 - val_o3_loss: 0.3143 - val_o4_loss: 0.3272 - val_o5_loss: 0.3434 - val_o6_loss: 0.3616 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7043 - val_o6_f1: 0.7004\n",
      "Epoch 73/500\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 89.1033 - o1_loss: 0.2681 - o2_loss: 0.1570 - o3_loss: 0.1442 - o4_loss: 0.1356 - o5_loss: 0.1419 - o6_loss: 0.1350 - o1_f1: 0.8650 - o2_f1: 0.9332 - o3_f1: 0.9418 - o4_f1: 0.9471 - o5_f1: 0.9365 - o6_f1: 0.9367 - val_loss: 222.4401 - val_o1_loss: 0.3720 - val_o2_loss: 0.3084 - val_o3_loss: 0.3131 - val_o4_loss: 0.3256 - val_o5_loss: 0.3412 - val_o6_loss: 0.3574 - val_o1_f1: 0.6686 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7129 - val_o6_f1: 0.7129\n",
      "Epoch 74/500\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 87.9479 - o1_loss: 0.2673 - o2_loss: 0.1556 - o3_loss: 0.1425 - o4_loss: 0.1339 - o5_loss: 0.1400 - o6_loss: 0.1332 - o1_f1: 0.8582 - o2_f1: 0.9243 - o3_f1: 0.9354 - o4_f1: 0.9410 - o5_f1: 0.9368 - o6_f1: 0.9418 - val_loss: 225.4410 - val_o1_loss: 0.3723 - val_o2_loss: 0.3101 - val_o3_loss: 0.3147 - val_o4_loss: 0.3280 - val_o5_loss: 0.3443 - val_o6_loss: 0.3632 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7181 - val_o4_f1: 0.7342 - val_o5_f1: 0.7043 - val_o6_f1: 0.7004\n",
      "Epoch 75/500\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 87.1440 - o1_loss: 0.2670 - o2_loss: 0.1550 - o3_loss: 0.1417 - o4_loss: 0.1328 - o5_loss: 0.1388 - o6_loss: 0.1318 - o1_f1: 0.8592 - o2_f1: 0.9342 - o3_f1: 0.9372 - o4_f1: 0.9454 - o5_f1: 0.9343 - o6_f1: 0.9369 - val_loss: 225.5068 - val_o1_loss: 0.3721 - val_o2_loss: 0.3101 - val_o3_loss: 0.3146 - val_o4_loss: 0.3281 - val_o5_loss: 0.3445 - val_o6_loss: 0.3633 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7342 - val_o5_f1: 0.7043 - val_o6_f1: 0.7004\n",
      "Epoch 76/500\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 88.0997 - o1_loss: 0.2672 - o2_loss: 0.1554 - o3_loss: 0.1427 - o4_loss: 0.1342 - o5_loss: 0.1397 - o6_loss: 0.1336 - o1_f1: 0.8539 - o2_f1: 0.9209 - o3_f1: 0.9217 - o4_f1: 0.9329 - o5_f1: 0.9300 - o6_f1: 0.9351 - val_loss: 228.4560 - val_o1_loss: 0.3713 - val_o2_loss: 0.3115 - val_o3_loss: 0.3165 - val_o4_loss: 0.3310 - val_o5_loss: 0.3478 - val_o6_loss: 0.3689 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7309 - val_o4_f1: 0.7165 - val_o5_f1: 0.6883 - val_o6_f1: 0.6861\n",
      "Epoch 77/500\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 86.5319 - o1_loss: 0.2662 - o2_loss: 0.1540 - o3_loss: 0.1407 - o4_loss: 0.1319 - o5_loss: 0.1377 - o6_loss: 0.1308 - o1_f1: 0.8592 - o2_f1: 0.9402 - o3_f1: 0.9486 - o4_f1: 0.9522 - o5_f1: 0.9416 - o6_f1: 0.9438 - val_loss: 228.8228 - val_o1_loss: 0.3715 - val_o2_loss: 0.3119 - val_o3_loss: 0.3170 - val_o4_loss: 0.3315 - val_o5_loss: 0.3481 - val_o6_loss: 0.3696 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7309 - val_o4_f1: 0.7165 - val_o5_f1: 0.6883 - val_o6_f1: 0.6732\n",
      "Epoch 78/500\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 85.7451 - o1_loss: 0.2659 - o2_loss: 0.1530 - o3_loss: 0.1397 - o4_loss: 0.1308 - o5_loss: 0.1364 - o6_loss: 0.1295 - o1_f1: 0.8656 - o2_f1: 0.9344 - o3_f1: 0.9378 - o4_f1: 0.9459 - o5_f1: 0.9468 - o6_f1: 0.9412 - val_loss: 223.6018 - val_o1_loss: 0.3711 - val_o2_loss: 0.3087 - val_o3_loss: 0.3134 - val_o4_loss: 0.3265 - val_o5_loss: 0.3423 - val_o6_loss: 0.3596 - val_o1_f1: 0.6821 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7399 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 79/500\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 84.0868 - o1_loss: 0.2651 - o2_loss: 0.1513 - o3_loss: 0.1375 - o4_loss: 0.1282 - o5_loss: 0.1338 - o6_loss: 0.1268 - o1_f1: 0.8643 - o2_f1: 0.9341 - o3_f1: 0.9462 - o4_f1: 0.9501 - o5_f1: 0.9462 - o6_f1: 0.9465 - val_loss: 226.8816 - val_o1_loss: 0.3713 - val_o2_loss: 0.3106 - val_o3_loss: 0.3155 - val_o4_loss: 0.3293 - val_o5_loss: 0.3458 - val_o6_loss: 0.3660 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7181 - val_o4_f1: 0.7342 - val_o5_f1: 0.7043 - val_o6_f1: 0.7004\n",
      "Epoch 80/500\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 83.2302 - o1_loss: 0.2647 - o2_loss: 0.1506 - o3_loss: 0.1366 - o4_loss: 0.1272 - o5_loss: 0.1325 - o6_loss: 0.1253 - o1_f1: 0.8588 - o2_f1: 0.9378 - o3_f1: 0.9398 - o4_f1: 0.9470 - o5_f1: 0.9429 - o6_f1: 0.9472 - val_loss: 224.9328 - val_o1_loss: 0.3701 - val_o2_loss: 0.3092 - val_o3_loss: 0.3141 - val_o4_loss: 0.3275 - val_o5_loss: 0.3436 - val_o6_loss: 0.3623 - val_o1_f1: 0.6686 - val_o2_f1: 0.6732 - val_o3_f1: 0.7270 - val_o4_f1: 0.7219 - val_o5_f1: 0.7129 - val_o6_f1: 0.7251\n",
      "Epoch 81/500\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 82.5848 - o1_loss: 0.2644 - o2_loss: 0.1499 - o3_loss: 0.1358 - o4_loss: 0.1262 - o5_loss: 0.1315 - o6_loss: 0.1243 - o1_f1: 0.8640 - o2_f1: 0.9362 - o3_f1: 0.9489 - o4_f1: 0.9516 - o5_f1: 0.9490 - o6_f1: 0.9476 - val_loss: 227.4628 - val_o1_loss: 0.3703 - val_o2_loss: 0.3106 - val_o3_loss: 0.3155 - val_o4_loss: 0.3298 - val_o5_loss: 0.3466 - val_o6_loss: 0.3671 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7181 - val_o4_f1: 0.7342 - val_o5_f1: 0.7043 - val_o6_f1: 0.7004\n",
      "Epoch 82/500\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 82.2311 - o1_loss: 0.2640 - o2_loss: 0.1493 - o3_loss: 0.1352 - o4_loss: 0.1259 - o5_loss: 0.1307 - o6_loss: 0.1237 - o1_f1: 0.8583 - o2_f1: 0.9313 - o3_f1: 0.9441 - o4_f1: 0.9503 - o5_f1: 0.9461 - o6_f1: 0.9510 - val_loss: 230.7937 - val_o1_loss: 0.3704 - val_o2_loss: 0.3128 - val_o3_loss: 0.3182 - val_o4_loss: 0.3333 - val_o5_loss: 0.3503 - val_o6_loss: 0.3733 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.7309 - val_o4_f1: 0.7165 - val_o5_f1: 0.6861 - val_o6_f1: 0.6732\n",
      "Epoch 83/500\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 81.7759 - o1_loss: 0.2635 - o2_loss: 0.1488 - o3_loss: 0.1347 - o4_loss: 0.1251 - o5_loss: 0.1301 - o6_loss: 0.1230 - o1_f1: 0.8645 - o2_f1: 0.9362 - o3_f1: 0.9516 - o4_f1: 0.9519 - o5_f1: 0.9442 - o6_f1: 0.9424 - val_loss: 224.3878 - val_o1_loss: 0.3695 - val_o2_loss: 0.3087 - val_o3_loss: 0.3137 - val_o4_loss: 0.3272 - val_o5_loss: 0.3431 - val_o6_loss: 0.3611 - val_o1_f1: 0.6821 - val_o2_f1: 0.6919 - val_o3_f1: 0.7270 - val_o4_f1: 0.7219 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 84/500\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 80.2490 - o1_loss: 0.2629 - o2_loss: 0.1471 - o3_loss: 0.1325 - o4_loss: 0.1228 - o5_loss: 0.1276 - o6_loss: 0.1205 - o1_f1: 0.8599 - o2_f1: 0.9367 - o3_f1: 0.9416 - o4_f1: 0.9500 - o5_f1: 0.9443 - o6_f1: 0.9447 - val_loss: 228.4474 - val_o1_loss: 0.3700 - val_o2_loss: 0.3111 - val_o3_loss: 0.3162 - val_o4_loss: 0.3307 - val_o5_loss: 0.3473 - val_o6_loss: 0.3690 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7181 - val_o4_f1: 0.7251 - val_o5_f1: 0.7043 - val_o6_f1: 0.6861\n",
      "Epoch 85/500\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 79.3335 - o1_loss: 0.2626 - o2_loss: 0.1463 - o3_loss: 0.1315 - o4_loss: 0.1217 - o5_loss: 0.1263 - o6_loss: 0.1189 - o1_f1: 0.8677 - o2_f1: 0.9427 - o3_f1: 0.9469 - o4_f1: 0.9531 - o5_f1: 0.9495 - o6_f1: 0.9499 - val_loss: 225.3815 - val_o1_loss: 0.3687 - val_o2_loss: 0.3092 - val_o3_loss: 0.3142 - val_o4_loss: 0.3279 - val_o5_loss: 0.3439 - val_o6_loss: 0.3631 - val_o1_f1: 0.6686 - val_o2_f1: 0.6919 - val_o3_f1: 0.7270 - val_o4_f1: 0.7342 - val_o5_f1: 0.7129 - val_o6_f1: 0.7251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 79.2012 - o1_loss: 0.2622 - o2_loss: 0.1462 - o3_loss: 0.1314 - o4_loss: 0.1214 - o5_loss: 0.1261 - o6_loss: 0.1187 - o1_f1: 0.8741 - o2_f1: 0.9383 - o3_f1: 0.9494 - o4_f1: 0.9512 - o5_f1: 0.9480 - o6_f1: 0.9468 - val_loss: 225.8876 - val_o1_loss: 0.3687 - val_o2_loss: 0.3095 - val_o3_loss: 0.3143 - val_o4_loss: 0.3281 - val_o5_loss: 0.3443 - val_o6_loss: 0.3642 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7342 - val_o5_f1: 0.7129 - val_o6_f1: 0.7251\n",
      "Epoch 87/500\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 78.2856 - o1_loss: 0.2620 - o2_loss: 0.1450 - o3_loss: 0.1300 - o4_loss: 0.1202 - o5_loss: 0.1244 - o6_loss: 0.1172 - o1_f1: 0.8594 - o2_f1: 0.9383 - o3_f1: 0.9462 - o4_f1: 0.9491 - o5_f1: 0.9516 - o6_f1: 0.9487 - val_loss: 230.0289 - val_o1_loss: 0.3690 - val_o2_loss: 0.3119 - val_o3_loss: 0.3171 - val_o4_loss: 0.3319 - val_o5_loss: 0.3491 - val_o6_loss: 0.3720 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.7181 - val_o4_f1: 0.7091 - val_o5_f1: 0.7004 - val_o6_f1: 0.6861\n",
      "Epoch 88/500\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 77.2059 - o1_loss: 0.2611 - o2_loss: 0.1438 - o3_loss: 0.1288 - o4_loss: 0.1185 - o5_loss: 0.1233 - o6_loss: 0.1152 - o1_f1: 0.8680 - o2_f1: 0.9404 - o3_f1: 0.9561 - o4_f1: 0.9581 - o5_f1: 0.9581 - o6_f1: 0.9600 - val_loss: 223.3241 - val_o1_loss: 0.3674 - val_o2_loss: 0.3082 - val_o3_loss: 0.3134 - val_o4_loss: 0.3269 - val_o5_loss: 0.3416 - val_o6_loss: 0.3590 - val_o1_f1: 0.6686 - val_o2_f1: 0.7008 - val_o3_f1: 0.7270 - val_o4_f1: 0.7270 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 89/500\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 77.8835 - o1_loss: 0.2613 - o2_loss: 0.1440 - o3_loss: 0.1294 - o4_loss: 0.1200 - o5_loss: 0.1232 - o6_loss: 0.1167 - o1_f1: 0.8521 - o2_f1: 0.9250 - o3_f1: 0.9393 - o4_f1: 0.9448 - o5_f1: 0.9421 - o6_f1: 0.9462 - val_loss: 231.5879 - val_o1_loss: 0.3685 - val_o2_loss: 0.3129 - val_o3_loss: 0.3185 - val_o4_loss: 0.3339 - val_o5_loss: 0.3508 - val_o6_loss: 0.3749 - val_o1_f1: 0.6821 - val_o2_f1: 0.6841 - val_o3_f1: 0.7001 - val_o4_f1: 0.7004 - val_o5_f1: 0.6861 - val_o6_f1: 0.6861\n",
      "Epoch 90/500\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 78.2848 - o1_loss: 0.2614 - o2_loss: 0.1448 - o3_loss: 0.1304 - o4_loss: 0.1203 - o5_loss: 0.1245 - o6_loss: 0.1171 - o1_f1: 0.8673 - o2_f1: 0.9423 - o3_f1: 0.9529 - o4_f1: 0.9552 - o5_f1: 0.9491 - o6_f1: 0.9549 - val_loss: 223.5897 - val_o1_loss: 0.3670 - val_o2_loss: 0.3082 - val_o3_loss: 0.3139 - val_o4_loss: 0.3280 - val_o5_loss: 0.3424 - val_o6_loss: 0.3591 - val_o1_f1: 0.6686 - val_o2_f1: 0.7008 - val_o3_f1: 0.7008 - val_o4_f1: 0.6914 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 91/500\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 75.6520 - o1_loss: 0.2604 - o2_loss: 0.1421 - o3_loss: 0.1267 - o4_loss: 0.1163 - o5_loss: 0.1203 - o6_loss: 0.1128 - o1_f1: 0.8685 - o2_f1: 0.9391 - o3_f1: 0.9522 - o4_f1: 0.9585 - o5_f1: 0.9495 - o6_f1: 0.9524 - val_loss: 227.9045 - val_o1_loss: 0.3680 - val_o2_loss: 0.3107 - val_o3_loss: 0.3158 - val_o4_loss: 0.3303 - val_o5_loss: 0.3461 - val_o6_loss: 0.3680 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7181 - val_o4_f1: 0.7182 - val_o5_f1: 0.7165 - val_o6_f1: 0.6861\n",
      "Epoch 92/500\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 74.3823 - o1_loss: 0.2597 - o2_loss: 0.1407 - o3_loss: 0.1250 - o4_loss: 0.1145 - o5_loss: 0.1183 - o6_loss: 0.1107 - o1_f1: 0.8538 - o2_f1: 0.9412 - o3_f1: 0.9459 - o4_f1: 0.9461 - o5_f1: 0.9437 - o6_f1: 0.9454 - val_loss: 226.1237 - val_o1_loss: 0.3667 - val_o2_loss: 0.3092 - val_o3_loss: 0.3144 - val_o4_loss: 0.3287 - val_o5_loss: 0.3442 - val_o6_loss: 0.3646 - val_o1_f1: 0.6686 - val_o2_f1: 0.7386 - val_o3_f1: 0.7270 - val_o4_f1: 0.7342 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 93/500\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 73.7687 - o1_loss: 0.2596 - o2_loss: 0.1401 - o3_loss: 0.1242 - o4_loss: 0.1136 - o5_loss: 0.1174 - o6_loss: 0.1097 - o1_f1: 0.8569 - o2_f1: 0.9418 - o3_f1: 0.9517 - o4_f1: 0.9524 - o5_f1: 0.9500 - o6_f1: 0.9477 - val_loss: 227.4177 - val_o1_loss: 0.3671 - val_o2_loss: 0.3101 - val_o3_loss: 0.3153 - val_o4_loss: 0.3298 - val_o5_loss: 0.3454 - val_o6_loss: 0.3672 - val_o1_f1: 0.6821 - val_o2_f1: 0.7386 - val_o3_f1: 0.7181 - val_o4_f1: 0.7182 - val_o5_f1: 0.7165 - val_o6_f1: 0.6948\n",
      "Epoch 94/500\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 73.9709 - o1_loss: 0.2598 - o2_loss: 0.1402 - o3_loss: 0.1243 - o4_loss: 0.1138 - o5_loss: 0.1173 - o6_loss: 0.1102 - o1_f1: 0.8599 - o2_f1: 0.9409 - o3_f1: 0.9448 - o4_f1: 0.9513 - o5_f1: 0.9458 - o6_f1: 0.9494 - val_loss: 229.9175 - val_o1_loss: 0.3666 - val_o2_loss: 0.3112 - val_o3_loss: 0.3168 - val_o4_loss: 0.3323 - val_o5_loss: 0.3486 - val_o6_loss: 0.3718 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7091 - val_o5_f1: 0.7004 - val_o6_f1: 0.6861\n",
      "Epoch 95/500\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 73.5813 - o1_loss: 0.2589 - o2_loss: 0.1397 - o3_loss: 0.1241 - o4_loss: 0.1134 - o5_loss: 0.1170 - o6_loss: 0.1094 - o1_f1: 0.8602 - o2_f1: 0.9475 - o3_f1: 0.9547 - o4_f1: 0.9607 - o5_f1: 0.9553 - o6_f1: 0.9608 - val_loss: 225.3053 - val_o1_loss: 0.3658 - val_o2_loss: 0.3084 - val_o3_loss: 0.3141 - val_o4_loss: 0.3287 - val_o5_loss: 0.3439 - val_o6_loss: 0.3626 - val_o1_f1: 0.6686 - val_o2_f1: 0.7008 - val_o3_f1: 0.7475 - val_o4_f1: 0.7090 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 96/500\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 73.2078 - o1_loss: 0.2588 - o2_loss: 0.1391 - o3_loss: 0.1233 - o4_loss: 0.1127 - o5_loss: 0.1160 - o6_loss: 0.1089 - o1_f1: 0.8674 - o2_f1: 0.9428 - o3_f1: 0.9511 - o4_f1: 0.9565 - o5_f1: 0.9534 - o6_f1: 0.9490 - val_loss: 234.5139 - val_o1_loss: 0.3679 - val_o2_loss: 0.3138 - val_o3_loss: 0.3204 - val_o4_loss: 0.3375 - val_o5_loss: 0.3541 - val_o6_loss: 0.3803 - val_o1_f1: 0.6732 - val_o2_f1: 0.6841 - val_o3_f1: 0.6969 - val_o4_f1: 0.6861 - val_o5_f1: 0.6861 - val_o6_f1: 0.6861\n",
      "Epoch 97/500\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 71.6179 - o1_loss: 0.2580 - o2_loss: 0.1374 - o3_loss: 0.1213 - o4_loss: 0.1104 - o5_loss: 0.1139 - o6_loss: 0.1061 - o1_f1: 0.8713 - o2_f1: 0.9458 - o3_f1: 0.9557 - o4_f1: 0.9559 - o5_f1: 0.9543 - o6_f1: 0.9556 - val_loss: 226.1914 - val_o1_loss: 0.3657 - val_o2_loss: 0.3089 - val_o3_loss: 0.3146 - val_o4_loss: 0.3294 - val_o5_loss: 0.3449 - val_o6_loss: 0.3643 - val_o1_f1: 0.6686 - val_o2_f1: 0.6919 - val_o3_f1: 0.7475 - val_o4_f1: 0.7219 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 98/500\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 70.9993 - o1_loss: 0.2576 - o2_loss: 0.1368 - o3_loss: 0.1205 - o4_loss: 0.1097 - o5_loss: 0.1128 - o6_loss: 0.1051 - o1_f1: 0.8703 - o2_f1: 0.9407 - o3_f1: 0.9533 - o4_f1: 0.9559 - o5_f1: 0.9540 - o6_f1: 0.9539 - val_loss: 227.3644 - val_o1_loss: 0.3657 - val_o2_loss: 0.3094 - val_o3_loss: 0.3151 - val_o4_loss: 0.3302 - val_o5_loss: 0.3459 - val_o6_loss: 0.3667 - val_o1_f1: 0.6821 - val_o2_f1: 0.7386 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 99/500\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 1s - loss: 71.1241 - o1_loss: 0.2572 - o2_loss: 0.1363 - o3_loss: 0.1201 - o4_loss: 0.1095 - o5_loss: 0.1126 - o6_loss: 0.1056 - o1_f1: 0.8525 - o2_f1: 0.9350 - o3_f1: 0.9430 - o4_f1: 0.9476 - o5_f1: 0.9425 - o6_f1: 0.9441 - val_loss: 229.5162 - val_o1_loss: 0.3661 - val_o2_loss: 0.3108 - val_o3_loss: 0.3166 - val_o4_loss: 0.3321 - val_o5_loss: 0.3481 - val_o6_loss: 0.3709 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7182 - val_o5_f1: 0.7165 - val_o6_f1: 0.6948\n",
      "Epoch 100/500\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 69.3619 - o1_loss: 0.2568 - o2_loss: 0.1351 - o3_loss: 0.1184 - o4_loss: 0.1072 - o5_loss: 0.1104 - o6_loss: 0.1024 - o1_f1: 0.8740 - o2_f1: 0.9442 - o3_f1: 0.9624 - o4_f1: 0.9594 - o5_f1: 0.9576 - o6_f1: 0.9595 - val_loss: 228.6767 - val_o1_loss: 0.3658 - val_o2_loss: 0.3103 - val_o3_loss: 0.3160 - val_o4_loss: 0.3313 - val_o5_loss: 0.3471 - val_o6_loss: 0.3693 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 101/500\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 69.2181 - o1_loss: 0.2566 - o2_loss: 0.1349 - o3_loss: 0.1181 - o4_loss: 0.1069 - o5_loss: 0.1100 - o6_loss: 0.1022 - o1_f1: 0.8703 - o2_f1: 0.9423 - o3_f1: 0.9545 - o4_f1: 0.9561 - o5_f1: 0.9506 - o6_f1: 0.9506 - val_loss: 228.0043 - val_o1_loss: 0.3653 - val_o2_loss: 0.3097 - val_o3_loss: 0.3155 - val_o4_loss: 0.3308 - val_o5_loss: 0.3465 - val_o6_loss: 0.3680 - val_o1_f1: 0.6821 - val_o2_f1: 0.7386 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7251\n",
      "Epoch 102/500\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 69.4131 - o1_loss: 0.2566 - o2_loss: 0.1351 - o3_loss: 0.1185 - o4_loss: 0.1072 - o5_loss: 0.1103 - o6_loss: 0.1025 - o1_f1: 0.8663 - o2_f1: 0.9466 - o3_f1: 0.9555 - o4_f1: 0.9512 - o5_f1: 0.9541 - o6_f1: 0.9512 - val_loss: 231.2031 - val_o1_loss: 0.3660 - val_o2_loss: 0.3116 - val_o3_loss: 0.3176 - val_o4_loss: 0.3338 - val_o5_loss: 0.3502 - val_o6_loss: 0.3741 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.6841 - val_o4_f1: 0.7091 - val_o5_f1: 0.7004 - val_o6_f1: 0.6948\n",
      "Epoch 103/500\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 69.1151 - o1_loss: 0.2567 - o2_loss: 0.1348 - o3_loss: 0.1181 - o4_loss: 0.1068 - o5_loss: 0.1098 - o6_loss: 0.1020 - o1_f1: 0.8689 - o2_f1: 0.9453 - o3_f1: 0.9566 - o4_f1: 0.9583 - o5_f1: 0.9565 - o6_f1: 0.9567 - val_loss: 228.8093 - val_o1_loss: 0.3653 - val_o2_loss: 0.3100 - val_o3_loss: 0.3159 - val_o4_loss: 0.3315 - val_o5_loss: 0.3476 - val_o6_loss: 0.3695 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 104/500\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 68.8215 - o1_loss: 0.2564 - o2_loss: 0.1344 - o3_loss: 0.1176 - o4_loss: 0.1063 - o5_loss: 0.1093 - o6_loss: 0.1016 - o1_f1: 0.8683 - o2_f1: 0.9450 - o3_f1: 0.9569 - o4_f1: 0.9593 - o5_f1: 0.9553 - o6_f1: 0.9533 - val_loss: 229.3210 - val_o1_loss: 0.3654 - val_o2_loss: 0.3103 - val_o3_loss: 0.3162 - val_o4_loss: 0.3320 - val_o5_loss: 0.3481 - val_o6_loss: 0.3705 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 105/500\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 68.5217 - o1_loss: 0.2563 - o2_loss: 0.1342 - o3_loss: 0.1173 - o4_loss: 0.1059 - o5_loss: 0.1090 - o6_loss: 0.1010 - o1_f1: 0.8719 - o2_f1: 0.9425 - o3_f1: 0.9566 - o4_f1: 0.9578 - o5_f1: 0.9559 - o6_f1: 0.9581 - val_loss: 229.8327 - val_o1_loss: 0.3655 - val_o2_loss: 0.3106 - val_o3_loss: 0.3165 - val_o4_loss: 0.3324 - val_o5_loss: 0.3487 - val_o6_loss: 0.3714 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 106/500\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 68.3496 - o1_loss: 0.2562 - o2_loss: 0.1340 - o3_loss: 0.1171 - o4_loss: 0.1057 - o5_loss: 0.1087 - o6_loss: 0.1008 - o1_f1: 0.8706 - o2_f1: 0.9443 - o3_f1: 0.9605 - o4_f1: 0.9575 - o5_f1: 0.9557 - o6_f1: 0.9574 - val_loss: 229.6115 - val_o1_loss: 0.3654 - val_o2_loss: 0.3104 - val_o3_loss: 0.3164 - val_o4_loss: 0.3323 - val_o5_loss: 0.3484 - val_o6_loss: 0.3710 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 107/500\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 68.1944 - o1_loss: 0.2562 - o2_loss: 0.1339 - o3_loss: 0.1170 - o4_loss: 0.1055 - o5_loss: 0.1085 - o6_loss: 0.1005 - o1_f1: 0.8760 - o2_f1: 0.9513 - o3_f1: 0.9586 - o4_f1: 0.9564 - o5_f1: 0.9565 - o6_f1: 0.9589 - val_loss: 232.4083 - val_o1_loss: 0.3661 - val_o2_loss: 0.3122 - val_o3_loss: 0.3185 - val_o4_loss: 0.3351 - val_o5_loss: 0.3516 - val_o6_loss: 0.3763 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.6841 - val_o4_f1: 0.7091 - val_o5_f1: 0.7004 - val_o6_f1: 0.6861\n",
      "Epoch 108/500\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 68.4303 - o1_loss: 0.2562 - o2_loss: 0.1341 - o3_loss: 0.1172 - o4_loss: 0.1058 - o5_loss: 0.1088 - o6_loss: 0.1009 - o1_f1: 0.8757 - o2_f1: 0.9486 - o3_f1: 0.9585 - o4_f1: 0.9551 - o5_f1: 0.9551 - o6_f1: 0.9569 - val_loss: 230.2308 - val_o1_loss: 0.3654 - val_o2_loss: 0.3107 - val_o3_loss: 0.3168 - val_o4_loss: 0.3328 - val_o5_loss: 0.3491 - val_o6_loss: 0.3722 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 109/500\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.8656 - o1_loss: 0.2560 - o2_loss: 0.1335 - o3_loss: 0.1165 - o4_loss: 0.1050 - o5_loss: 0.1079 - o6_loss: 0.0999 - o1_f1: 0.8761 - o2_f1: 0.9499 - o3_f1: 0.9593 - o4_f1: 0.9576 - o5_f1: 0.9556 - o6_f1: 0.9577 - val_loss: 229.8949 - val_o1_loss: 0.3653 - val_o2_loss: 0.3105 - val_o3_loss: 0.3165 - val_o4_loss: 0.3325 - val_o5_loss: 0.3487 - val_o6_loss: 0.3716 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 110/500\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 68.2753 - o1_loss: 0.2561 - o2_loss: 0.1337 - o3_loss: 0.1167 - o4_loss: 0.1055 - o5_loss: 0.1084 - o6_loss: 0.1007 - o1_f1: 0.8750 - o2_f1: 0.9458 - o3_f1: 0.9584 - o4_f1: 0.9606 - o5_f1: 0.9575 - o6_f1: 0.9587 - val_loss: 229.2851 - val_o1_loss: 0.3649 - val_o2_loss: 0.3101 - val_o3_loss: 0.3161 - val_o4_loss: 0.3320 - val_o5_loss: 0.3481 - val_o6_loss: 0.3704 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 111/500\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.8732 - o1_loss: 0.2559 - o2_loss: 0.1334 - o3_loss: 0.1164 - o4_loss: 0.1049 - o5_loss: 0.1079 - o6_loss: 0.1000 - o1_f1: 0.8710 - o2_f1: 0.9473 - o3_f1: 0.9614 - o4_f1: 0.9595 - o5_f1: 0.9602 - o6_f1: 0.9602 - val_loss: 230.8975 - val_o1_loss: 0.3652 - val_o2_loss: 0.3110 - val_o3_loss: 0.3172 - val_o4_loss: 0.3335 - val_o5_loss: 0.3499 - val_o6_loss: 0.3735 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.6841 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 112/500\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.8459 - o1_loss: 0.2557 - o2_loss: 0.1331 - o3_loss: 0.1161 - o4_loss: 0.1048 - o5_loss: 0.1077 - o6_loss: 0.1000 - o1_f1: 0.8693 - o2_f1: 0.9466 - o3_f1: 0.9617 - o4_f1: 0.9594 - o5_f1: 0.9572 - o6_f1: 0.9528 - val_loss: 228.5254 - val_o1_loss: 0.3644 - val_o2_loss: 0.3096 - val_o3_loss: 0.3157 - val_o4_loss: 0.3315 - val_o5_loss: 0.3472 - val_o6_loss: 0.3689 - val_o1_f1: 0.6821 - val_o2_f1: 0.7386 - val_o3_f1: 0.7475 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7251\n",
      "Epoch 113/500\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.3017 - o1_loss: 0.2556 - o2_loss: 0.1327 - o3_loss: 0.1155 - o4_loss: 0.1041 - o5_loss: 0.1069 - o6_loss: 0.0991 - o1_f1: 0.8617 - o2_f1: 0.9454 - o3_f1: 0.9595 - o4_f1: 0.9599 - o5_f1: 0.9582 - o6_f1: 0.9581 - val_loss: 229.5725 - val_o1_loss: 0.3645 - val_o2_loss: 0.3101 - val_o3_loss: 0.3163 - val_o4_loss: 0.3323 - val_o5_loss: 0.3483 - val_o6_loss: 0.3709 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 114/500\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.1778 - o1_loss: 0.2555 - o2_loss: 0.1326 - o3_loss: 0.1154 - o4_loss: 0.1039 - o5_loss: 0.1067 - o6_loss: 0.0989 - o1_f1: 0.8721 - o2_f1: 0.9437 - o3_f1: 0.9561 - o4_f1: 0.9556 - o5_f1: 0.9529 - o6_f1: 0.9534 - val_loss: 229.9572 - val_o1_loss: 0.3644 - val_o2_loss: 0.3102 - val_o3_loss: 0.3165 - val_o4_loss: 0.3326 - val_o5_loss: 0.3487 - val_o6_loss: 0.3717 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.2039 - o1_loss: 0.2556 - o2_loss: 0.1326 - o3_loss: 0.1155 - o4_loss: 0.1040 - o5_loss: 0.1068 - o6_loss: 0.0989 - o1_f1: 0.8666 - o2_f1: 0.9486 - o3_f1: 0.9568 - o4_f1: 0.9552 - o5_f1: 0.9561 - o6_f1: 0.9575 - val_loss: 230.9142 - val_o1_loss: 0.3646 - val_o2_loss: 0.3107 - val_o3_loss: 0.3171 - val_o4_loss: 0.3335 - val_o5_loss: 0.3499 - val_o6_loss: 0.3735 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.6841 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 116/500\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 66.8152 - o1_loss: 0.2553 - o2_loss: 0.1322 - o3_loss: 0.1149 - o4_loss: 0.1034 - o5_loss: 0.1062 - o6_loss: 0.0983 - o1_f1: 0.8693 - o2_f1: 0.9503 - o3_f1: 0.9606 - o4_f1: 0.9586 - o5_f1: 0.9569 - o6_f1: 0.9610 - val_loss: 229.5085 - val_o1_loss: 0.3642 - val_o2_loss: 0.3099 - val_o3_loss: 0.3162 - val_o4_loss: 0.3323 - val_o5_loss: 0.3483 - val_o6_loss: 0.3708 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 117/500\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 66.8581 - o1_loss: 0.2552 - o2_loss: 0.1321 - o3_loss: 0.1149 - o4_loss: 0.1034 - o5_loss: 0.1061 - o6_loss: 0.0984 - o1_f1: 0.8716 - o2_f1: 0.9473 - o3_f1: 0.9579 - o4_f1: 0.9600 - o5_f1: 0.9585 - o6_f1: 0.9583 - val_loss: 229.1864 - val_o1_loss: 0.3640 - val_o2_loss: 0.3097 - val_o3_loss: 0.3160 - val_o4_loss: 0.3321 - val_o5_loss: 0.3480 - val_o6_loss: 0.3701 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 118/500\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 66.4692 - o1_loss: 0.2552 - o2_loss: 0.1318 - o3_loss: 0.1145 - o4_loss: 0.1029 - o5_loss: 0.1056 - o6_loss: 0.0977 - o1_f1: 0.8744 - o2_f1: 0.9437 - o3_f1: 0.9581 - o4_f1: 0.9567 - o5_f1: 0.9548 - o6_f1: 0.9553 - val_loss: 230.6352 - val_o1_loss: 0.3644 - val_o2_loss: 0.3105 - val_o3_loss: 0.3169 - val_o4_loss: 0.3333 - val_o5_loss: 0.3495 - val_o6_loss: 0.3729 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.6841 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 119/500\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 67.2531 - o1_loss: 0.2554 - o2_loss: 0.1325 - o3_loss: 0.1155 - o4_loss: 0.1040 - o5_loss: 0.1068 - o6_loss: 0.0990 - o1_f1: 0.8731 - o2_f1: 0.9523 - o3_f1: 0.9607 - o4_f1: 0.9607 - o5_f1: 0.9582 - o6_f1: 0.9607 - val_loss: 230.8641 - val_o1_loss: 0.3643 - val_o2_loss: 0.3106 - val_o3_loss: 0.3170 - val_o4_loss: 0.3335 - val_o5_loss: 0.3497 - val_o6_loss: 0.3734 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.6841 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 120/500\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 66.1646 - o1_loss: 0.2549 - o2_loss: 0.1313 - o3_loss: 0.1139 - o4_loss: 0.1024 - o5_loss: 0.1050 - o6_loss: 0.0972 - o1_f1: 0.8712 - o2_f1: 0.9479 - o3_f1: 0.9577 - o4_f1: 0.9598 - o5_f1: 0.9584 - o6_f1: 0.9578 - val_loss: 228.1480 - val_o1_loss: 0.3636 - val_o2_loss: 0.3092 - val_o3_loss: 0.3156 - val_o4_loss: 0.3315 - val_o5_loss: 0.3469 - val_o6_loss: 0.3680 - val_o1_f1: 0.6686 - val_o2_f1: 0.6919 - val_o3_f1: 0.7475 - val_o4_f1: 0.7059 - val_o5_f1: 0.7219 - val_o6_f1: 0.7251\n",
      "Epoch 121/500\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 66.4493 - o1_loss: 0.2550 - o2_loss: 0.1315 - o3_loss: 0.1142 - o4_loss: 0.1028 - o5_loss: 0.1054 - o6_loss: 0.0977 - o1_f1: 0.8519 - o2_f1: 0.9400 - o3_f1: 0.9526 - o4_f1: 0.9537 - o5_f1: 0.9522 - o6_f1: 0.9503 - val_loss: 229.1971 - val_o1_loss: 0.3636 - val_o2_loss: 0.3096 - val_o3_loss: 0.3160 - val_o4_loss: 0.3321 - val_o5_loss: 0.3478 - val_o6_loss: 0.3702 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 122/500\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 65.9911 - o1_loss: 0.2548 - o2_loss: 0.1312 - o3_loss: 0.1138 - o4_loss: 0.1022 - o5_loss: 0.1048 - o6_loss: 0.0969 - o1_f1: 0.8694 - o2_f1: 0.9452 - o3_f1: 0.9618 - o4_f1: 0.9599 - o5_f1: 0.9580 - o6_f1: 0.9577 - val_loss: 230.0270 - val_o1_loss: 0.3637 - val_o2_loss: 0.3100 - val_o3_loss: 0.3165 - val_o4_loss: 0.3328 - val_o5_loss: 0.3487 - val_o6_loss: 0.3718 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 123/500\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 65.9862 - o1_loss: 0.2548 - o2_loss: 0.1312 - o3_loss: 0.1138 - o4_loss: 0.1022 - o5_loss: 0.1048 - o6_loss: 0.0969 - o1_f1: 0.8741 - o2_f1: 0.9523 - o3_f1: 0.9616 - o4_f1: 0.9600 - o5_f1: 0.9606 - o6_f1: 0.9626 - val_loss: 230.9649 - val_o1_loss: 0.3638 - val_o2_loss: 0.3104 - val_o3_loss: 0.3170 - val_o4_loss: 0.3336 - val_o5_loss: 0.3498 - val_o6_loss: 0.3736 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.6841 - val_o4_f1: 0.7182 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 124/500\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 66.1189 - o1_loss: 0.2548 - o2_loss: 0.1314 - o3_loss: 0.1141 - o4_loss: 0.1024 - o5_loss: 0.1050 - o6_loss: 0.0971 - o1_f1: 0.8741 - o2_f1: 0.9517 - o3_f1: 0.9590 - o4_f1: 0.9590 - o5_f1: 0.9559 - o6_f1: 0.9577 - val_loss: 230.9997 - val_o1_loss: 0.3640 - val_o2_loss: 0.3104 - val_o3_loss: 0.3170 - val_o4_loss: 0.3336 - val_o5_loss: 0.3499 - val_o6_loss: 0.3736 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.6948\n",
      "Epoch 125/500\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 65.5082 - o1_loss: 0.2546 - o2_loss: 0.1307 - o3_loss: 0.1132 - o4_loss: 0.1015 - o5_loss: 0.1040 - o6_loss: 0.0961 - o1_f1: 0.8676 - o2_f1: 0.9488 - o3_f1: 0.9556 - o4_f1: 0.9540 - o5_f1: 0.9523 - o6_f1: 0.9539 - val_loss: 230.1839 - val_o1_loss: 0.3636 - val_o2_loss: 0.3099 - val_o3_loss: 0.3165 - val_o4_loss: 0.3329 - val_o5_loss: 0.3490 - val_o6_loss: 0.3721 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 126/500\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 65.4100 - o1_loss: 0.2545 - o2_loss: 0.1305 - o3_loss: 0.1130 - o4_loss: 0.1013 - o5_loss: 0.1039 - o6_loss: 0.0960 - o1_f1: 0.8664 - o2_f1: 0.9495 - o3_f1: 0.9591 - o4_f1: 0.9568 - o5_f1: 0.9548 - o6_f1: 0.9577 - val_loss: 230.6640 - val_o1_loss: 0.3636 - val_o2_loss: 0.3103 - val_o3_loss: 0.3169 - val_o4_loss: 0.3333 - val_o5_loss: 0.3494 - val_o6_loss: 0.3730 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 127/500\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 65.3278 - o1_loss: 0.2545 - o2_loss: 0.1304 - o3_loss: 0.1129 - o4_loss: 0.1012 - o5_loss: 0.1037 - o6_loss: 0.0958 - o1_f1: 0.8696 - o2_f1: 0.9543 - o3_f1: 0.9635 - o4_f1: 0.9614 - o5_f1: 0.9591 - o6_f1: 0.9591 - val_loss: 229.1699 - val_o1_loss: 0.3632 - val_o2_loss: 0.3095 - val_o3_loss: 0.3161 - val_o4_loss: 0.3321 - val_o5_loss: 0.3477 - val_o6_loss: 0.3701 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7251\n",
      "Epoch 128/500\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 65.1610 - o1_loss: 0.2543 - o2_loss: 0.1302 - o3_loss: 0.1126 - o4_loss: 0.1009 - o5_loss: 0.1034 - o6_loss: 0.0956 - o1_f1: 0.8669 - o2_f1: 0.9485 - o3_f1: 0.9578 - o4_f1: 0.9558 - o5_f1: 0.9562 - o6_f1: 0.9558 - val_loss: 230.3833 - val_o1_loss: 0.3634 - val_o2_loss: 0.3101 - val_o3_loss: 0.3167 - val_o4_loss: 0.3331 - val_o5_loss: 0.3490 - val_o6_loss: 0.3725 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 129/500\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 6.25e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 65.1622 - o1_loss: 0.2544 - o2_loss: 0.1302 - o3_loss: 0.1126 - o4_loss: 0.1009 - o5_loss: 0.1034 - o6_loss: 0.0956 - o1_f1: 0.8676 - o2_f1: 0.9474 - o3_f1: 0.9593 - o4_f1: 0.9578 - o5_f1: 0.9565 - o6_f1: 0.9560 - val_loss: 230.2081 - val_o1_loss: 0.3631 - val_o2_loss: 0.3099 - val_o3_loss: 0.3165 - val_o4_loss: 0.3329 - val_o5_loss: 0.3489 - val_o6_loss: 0.3721 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 130/500\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 64.9432 - o1_loss: 0.2543 - o2_loss: 0.1300 - o3_loss: 0.1124 - o4_loss: 0.1006 - o5_loss: 0.1031 - o6_loss: 0.0952 - o1_f1: 0.8723 - o2_f1: 0.9538 - o3_f1: 0.9618 - o4_f1: 0.9600 - o5_f1: 0.9601 - o6_f1: 0.9602 - val_loss: 231.0050 - val_o1_loss: 0.3633 - val_o2_loss: 0.3103 - val_o3_loss: 0.3170 - val_o4_loss: 0.3337 - val_o5_loss: 0.3498 - val_o6_loss: 0.3737 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 131/500\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 64.6967 - o1_loss: 0.2541 - o2_loss: 0.1297 - o3_loss: 0.1120 - o4_loss: 0.1003 - o5_loss: 0.1026 - o6_loss: 0.0948 - o1_f1: 0.8690 - o2_f1: 0.9539 - o3_f1: 0.9616 - o4_f1: 0.9596 - o5_f1: 0.9579 - o6_f1: 0.9624 - val_loss: 229.7904 - val_o1_loss: 0.3629 - val_o2_loss: 0.3096 - val_o3_loss: 0.3163 - val_o4_loss: 0.3327 - val_o5_loss: 0.3485 - val_o6_loss: 0.3713 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 132/500\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 64.6464 - o1_loss: 0.2541 - o2_loss: 0.1296 - o3_loss: 0.1119 - o4_loss: 0.1002 - o5_loss: 0.1026 - o6_loss: 0.0947 - o1_f1: 0.8647 - o2_f1: 0.9485 - o3_f1: 0.9598 - o4_f1: 0.9580 - o5_f1: 0.9581 - o6_f1: 0.9607 - val_loss: 230.8774 - val_o1_loss: 0.3632 - val_o2_loss: 0.3102 - val_o3_loss: 0.3170 - val_o4_loss: 0.3336 - val_o5_loss: 0.3495 - val_o6_loss: 0.3735 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 133/500\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 64.3575 - o1_loss: 0.2540 - o2_loss: 0.1293 - o3_loss: 0.1116 - o4_loss: 0.0998 - o5_loss: 0.1022 - o6_loss: 0.0942 - o1_f1: 0.8710 - o2_f1: 0.9535 - o3_f1: 0.9591 - o4_f1: 0.9575 - o5_f1: 0.9577 - o6_f1: 0.9594 - val_loss: 229.7010 - val_o1_loss: 0.3630 - val_o2_loss: 0.3096 - val_o3_loss: 0.3164 - val_o4_loss: 0.3327 - val_o5_loss: 0.3482 - val_o6_loss: 0.3712 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 134/500\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 64.3318 - o1_loss: 0.2540 - o2_loss: 0.1292 - o3_loss: 0.1115 - o4_loss: 0.0998 - o5_loss: 0.1020 - o6_loss: 0.0942 - o1_f1: 0.8631 - o2_f1: 0.9403 - o3_f1: 0.9531 - o4_f1: 0.9515 - o5_f1: 0.9496 - o6_f1: 0.9516 - val_loss: 228.8159 - val_o1_loss: 0.3628 - val_o2_loss: 0.3092 - val_o3_loss: 0.3160 - val_o4_loss: 0.3320 - val_o5_loss: 0.3473 - val_o6_loss: 0.3694 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7251\n",
      "Epoch 135/500\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 64.8535 - o1_loss: 0.2539 - o2_loss: 0.1294 - o3_loss: 0.1119 - o4_loss: 0.1003 - o5_loss: 0.1026 - o6_loss: 0.0952 - o1_f1: 0.8643 - o2_f1: 0.9486 - o3_f1: 0.9583 - o4_f1: 0.9597 - o5_f1: 0.9560 - o6_f1: 0.9582 - val_loss: 228.9003 - val_o1_loss: 0.3625 - val_o2_loss: 0.3092 - val_o3_loss: 0.3160 - val_o4_loss: 0.3322 - val_o5_loss: 0.3475 - val_o6_loss: 0.3695 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7251\n",
      "Epoch 136/500\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.9843 - o1_loss: 0.2537 - o2_loss: 0.1288 - o3_loss: 0.1110 - o4_loss: 0.0992 - o5_loss: 0.1015 - o6_loss: 0.0936 - o1_f1: 0.8659 - o2_f1: 0.9521 - o3_f1: 0.9603 - o4_f1: 0.9582 - o5_f1: 0.9576 - o6_f1: 0.9600 - val_loss: 231.2825 - val_o1_loss: 0.3628 - val_o2_loss: 0.3103 - val_o3_loss: 0.3172 - val_o4_loss: 0.3340 - val_o5_loss: 0.3500 - val_o6_loss: 0.3742 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 137/500\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.8929 - o1_loss: 0.2536 - o2_loss: 0.1288 - o3_loss: 0.1110 - o4_loss: 0.0991 - o5_loss: 0.1014 - o6_loss: 0.0934 - o1_f1: 0.8721 - o2_f1: 0.9540 - o3_f1: 0.9607 - o4_f1: 0.9622 - o5_f1: 0.9603 - o6_f1: 0.9618 - val_loss: 231.2890 - val_o1_loss: 0.3627 - val_o2_loss: 0.3102 - val_o3_loss: 0.3171 - val_o4_loss: 0.3340 - val_o5_loss: 0.3500 - val_o6_loss: 0.3742 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 138/500\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.6650 - o1_loss: 0.2536 - o2_loss: 0.1285 - o3_loss: 0.1106 - o4_loss: 0.0988 - o5_loss: 0.1010 - o6_loss: 0.0931 - o1_f1: 0.8623 - o2_f1: 0.9485 - o3_f1: 0.9573 - o4_f1: 0.9554 - o5_f1: 0.9569 - o6_f1: 0.9547 - val_loss: 229.6327 - val_o1_loss: 0.3624 - val_o2_loss: 0.3094 - val_o3_loss: 0.3163 - val_o4_loss: 0.3327 - val_o5_loss: 0.3481 - val_o6_loss: 0.3710 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7270 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 139/500\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.6899 - o1_loss: 0.2535 - o2_loss: 0.1285 - o3_loss: 0.1106 - o4_loss: 0.0988 - o5_loss: 0.1010 - o6_loss: 0.0932 - o1_f1: 0.8629 - o2_f1: 0.9417 - o3_f1: 0.9520 - o4_f1: 0.9497 - o5_f1: 0.9479 - o6_f1: 0.9479 - val_loss: 230.1461 - val_o1_loss: 0.3625 - val_o2_loss: 0.3096 - val_o3_loss: 0.3166 - val_o4_loss: 0.3332 - val_o5_loss: 0.3488 - val_o6_loss: 0.3720 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 140/500\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.5281 - o1_loss: 0.2535 - o2_loss: 0.1283 - o3_loss: 0.1104 - o4_loss: 0.0986 - o5_loss: 0.1007 - o6_loss: 0.0929 - o1_f1: 0.8632 - o2_f1: 0.9513 - o3_f1: 0.9603 - o4_f1: 0.9578 - o5_f1: 0.9555 - o6_f1: 0.9577 - val_loss: 230.6203 - val_o1_loss: 0.3623 - val_o2_loss: 0.3098 - val_o3_loss: 0.3168 - val_o4_loss: 0.3335 - val_o5_loss: 0.3493 - val_o6_loss: 0.3729 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 141/500\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.3404 - o1_loss: 0.2534 - o2_loss: 0.1281 - o3_loss: 0.1102 - o4_loss: 0.0983 - o5_loss: 0.1004 - o6_loss: 0.0926 - o1_f1: 0.8666 - o2_f1: 0.9519 - o3_f1: 0.9608 - o4_f1: 0.9591 - o5_f1: 0.9571 - o6_f1: 0.9588 - val_loss: 231.0937 - val_o1_loss: 0.3624 - val_o2_loss: 0.3100 - val_o3_loss: 0.3171 - val_o4_loss: 0.3339 - val_o5_loss: 0.3498 - val_o6_loss: 0.3738 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 142/500\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.2246 - o1_loss: 0.2533 - o2_loss: 0.1280 - o3_loss: 0.1101 - o4_loss: 0.0981 - o5_loss: 0.1003 - o6_loss: 0.0924 - o1_f1: 0.8639 - o2_f1: 0.9521 - o3_f1: 0.9582 - o4_f1: 0.9603 - o5_f1: 0.9599 - o6_f1: 0.9580 - val_loss: 231.3033 - val_o1_loss: 0.3625 - val_o2_loss: 0.3101 - val_o3_loss: 0.3171 - val_o4_loss: 0.3341 - val_o5_loss: 0.3499 - val_o6_loss: 0.3743 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 143/500\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.2168 - o1_loss: 0.2532 - o2_loss: 0.1279 - o3_loss: 0.1100 - o4_loss: 0.0981 - o5_loss: 0.1002 - o6_loss: 0.0924 - o1_f1: 0.8637 - o2_f1: 0.9508 - o3_f1: 0.9589 - o4_f1: 0.9569 - o5_f1: 0.9571 - o6_f1: 0.9592 - val_loss: 231.1140 - val_o1_loss: 0.3625 - val_o2_loss: 0.3100 - val_o3_loss: 0.3170 - val_o4_loss: 0.3339 - val_o5_loss: 0.3497 - val_o6_loss: 0.3739 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/500\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 63.6036 - o1_loss: 0.2533 - o2_loss: 0.1282 - o3_loss: 0.1105 - o4_loss: 0.0987 - o5_loss: 0.1009 - o6_loss: 0.0930 - o1_f1: 0.8806 - o2_f1: 0.9557 - o3_f1: 0.9607 - o4_f1: 0.9658 - o5_f1: 0.9601 - o6_f1: 0.9646 - val_loss: 234.1213 - val_o1_loss: 0.3631 - val_o2_loss: 0.3117 - val_o3_loss: 0.3191 - val_o4_loss: 0.3368 - val_o5_loss: 0.3530 - val_o6_loss: 0.3797 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.6841 - val_o4_f1: 0.7091 - val_o5_f1: 0.7004 - val_o6_f1: 0.6948\n",
      "Epoch 145/500\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 62.8612 - o1_loss: 0.2531 - o2_loss: 0.1276 - o3_loss: 0.1097 - o4_loss: 0.0977 - o5_loss: 0.0997 - o6_loss: 0.0917 - o1_f1: 0.8733 - o2_f1: 0.9573 - o3_f1: 0.9630 - o4_f1: 0.9651 - o5_f1: 0.9627 - o6_f1: 0.9647 - val_loss: 230.8641 - val_o1_loss: 0.3624 - val_o2_loss: 0.3099 - val_o3_loss: 0.3169 - val_o4_loss: 0.3337 - val_o5_loss: 0.3493 - val_o6_loss: 0.3734 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 146/500\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 62.9836 - o1_loss: 0.2531 - o2_loss: 0.1276 - o3_loss: 0.1096 - o4_loss: 0.0978 - o5_loss: 0.0998 - o6_loss: 0.0920 - o1_f1: 0.8645 - o2_f1: 0.9511 - o3_f1: 0.9605 - o4_f1: 0.9578 - o5_f1: 0.9581 - o6_f1: 0.9584 - val_loss: 229.9985 - val_o1_loss: 0.3621 - val_o2_loss: 0.3094 - val_o3_loss: 0.3165 - val_o4_loss: 0.3331 - val_o5_loss: 0.3485 - val_o6_loss: 0.3717 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 147/500\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 62.5463 - o1_loss: 0.2528 - o2_loss: 0.1271 - o3_loss: 0.1090 - o4_loss: 0.0971 - o5_loss: 0.0991 - o6_loss: 0.0913 - o1_f1: 0.8621 - o2_f1: 0.9504 - o3_f1: 0.9580 - o4_f1: 0.9560 - o5_f1: 0.9554 - o6_f1: 0.9554 - val_loss: 230.9233 - val_o1_loss: 0.3622 - val_o2_loss: 0.3099 - val_o3_loss: 0.3170 - val_o4_loss: 0.3338 - val_o5_loss: 0.3494 - val_o6_loss: 0.3735 - val_o1_f1: 0.6686 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 148/500\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 62.6565 - o1_loss: 0.2529 - o2_loss: 0.1272 - o3_loss: 0.1092 - o4_loss: 0.0973 - o5_loss: 0.0994 - o6_loss: 0.0914 - o1_f1: 0.8784 - o2_f1: 0.9525 - o3_f1: 0.9588 - o4_f1: 0.9630 - o5_f1: 0.9606 - o6_f1: 0.9625 - val_loss: 233.1317 - val_o1_loss: 0.3627 - val_o2_loss: 0.3110 - val_o3_loss: 0.3184 - val_o4_loss: 0.3358 - val_o5_loss: 0.3519 - val_o6_loss: 0.3778 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.7001 - val_o4_f1: 0.7091 - val_o5_f1: 0.7091 - val_o6_f1: 0.6948\n",
      "Epoch 149/500\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 1s - loss: 62.5462 - o1_loss: 0.2528 - o2_loss: 0.1272 - o3_loss: 0.1091 - o4_loss: 0.0972 - o5_loss: 0.0991 - o6_loss: 0.0913 - o1_f1: 0.8724 - o2_f1: 0.9529 - o3_f1: 0.9608 - o4_f1: 0.9608 - o5_f1: 0.9586 - o6_f1: 0.9609 - val_loss: 229.9083 - val_o1_loss: 0.3620 - val_o2_loss: 0.3094 - val_o3_loss: 0.3165 - val_o4_loss: 0.3331 - val_o5_loss: 0.3484 - val_o6_loss: 0.3715 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 150/500\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 62.1589 - o1_loss: 0.2526 - o2_loss: 0.1267 - o3_loss: 0.1085 - o4_loss: 0.0966 - o5_loss: 0.0985 - o6_loss: 0.0906 - o1_f1: 0.8702 - o2_f1: 0.9516 - o3_f1: 0.9599 - o4_f1: 0.9579 - o5_f1: 0.9609 - o6_f1: 0.9587 - val_loss: 230.8345 - val_o1_loss: 0.3621 - val_o2_loss: 0.3097 - val_o3_loss: 0.3169 - val_o4_loss: 0.3338 - val_o5_loss: 0.3494 - val_o6_loss: 0.3733 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 151/500\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 62.0814 - o1_loss: 0.2526 - o2_loss: 0.1266 - o3_loss: 0.1085 - o4_loss: 0.0965 - o5_loss: 0.0984 - o6_loss: 0.0905 - o1_f1: 0.8722 - o2_f1: 0.9554 - o3_f1: 0.9607 - o4_f1: 0.9609 - o5_f1: 0.9617 - o6_f1: 0.9608 - val_loss: 231.2731 - val_o1_loss: 0.3622 - val_o2_loss: 0.3099 - val_o3_loss: 0.3172 - val_o4_loss: 0.3341 - val_o5_loss: 0.3499 - val_o6_loss: 0.3741 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 152/500\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 62.0426 - o1_loss: 0.2526 - o2_loss: 0.1266 - o3_loss: 0.1084 - o4_loss: 0.0964 - o5_loss: 0.0984 - o6_loss: 0.0904 - o1_f1: 0.8703 - o2_f1: 0.9551 - o3_f1: 0.9595 - o4_f1: 0.9616 - o5_f1: 0.9592 - o6_f1: 0.9604 - val_loss: 231.8206 - val_o1_loss: 0.3623 - val_o2_loss: 0.3102 - val_o3_loss: 0.3175 - val_o4_loss: 0.3346 - val_o5_loss: 0.3505 - val_o6_loss: 0.3752 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 153/500\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 62.0088 - o1_loss: 0.2526 - o2_loss: 0.1266 - o3_loss: 0.1084 - o4_loss: 0.0964 - o5_loss: 0.0983 - o6_loss: 0.0904 - o1_f1: 0.8738 - o2_f1: 0.9565 - o3_f1: 0.9606 - o4_f1: 0.9643 - o5_f1: 0.9612 - o6_f1: 0.9614 - val_loss: 231.8932 - val_o1_loss: 0.3623 - val_o2_loss: 0.3102 - val_o3_loss: 0.3175 - val_o4_loss: 0.3347 - val_o5_loss: 0.3506 - val_o6_loss: 0.3753 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 154/500\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.9792 - o1_loss: 0.2526 - o2_loss: 0.1265 - o3_loss: 0.1084 - o4_loss: 0.0963 - o5_loss: 0.0983 - o6_loss: 0.0903 - o1_f1: 0.8793 - o2_f1: 0.9563 - o3_f1: 0.9597 - o4_f1: 0.9610 - o5_f1: 0.9588 - o6_f1: 0.9626 - val_loss: 231.6610 - val_o1_loss: 0.3622 - val_o2_loss: 0.3101 - val_o3_loss: 0.3174 - val_o4_loss: 0.3345 - val_o5_loss: 0.3504 - val_o6_loss: 0.3749 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 155/500\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 61.9140 - o1_loss: 0.2525 - o2_loss: 0.1264 - o3_loss: 0.1083 - o4_loss: 0.0962 - o5_loss: 0.0982 - o6_loss: 0.0902 - o1_f1: 0.8737 - o2_f1: 0.9565 - o3_f1: 0.9610 - o4_f1: 0.9628 - o5_f1: 0.9614 - o6_f1: 0.9615 - val_loss: 231.4781 - val_o1_loss: 0.3621 - val_o2_loss: 0.3100 - val_o3_loss: 0.3173 - val_o4_loss: 0.3343 - val_o5_loss: 0.3502 - val_o6_loss: 0.3745 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 156/500\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 61.8774 - o1_loss: 0.2525 - o2_loss: 0.1264 - o3_loss: 0.1082 - o4_loss: 0.0962 - o5_loss: 0.0981 - o6_loss: 0.0902 - o1_f1: 0.8746 - o2_f1: 0.9555 - o3_f1: 0.9600 - o4_f1: 0.9600 - o5_f1: 0.9604 - o6_f1: 0.9606 - val_loss: 231.3785 - val_o1_loss: 0.3621 - val_o2_loss: 0.3099 - val_o3_loss: 0.3172 - val_o4_loss: 0.3343 - val_o5_loss: 0.3501 - val_o6_loss: 0.3743 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 157/500\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 61.8527 - o1_loss: 0.2525 - o2_loss: 0.1264 - o3_loss: 0.1082 - o4_loss: 0.0961 - o5_loss: 0.0980 - o6_loss: 0.0901 - o1_f1: 0.8705 - o2_f1: 0.9561 - o3_f1: 0.9599 - o4_f1: 0.9585 - o5_f1: 0.9581 - o6_f1: 0.9602 - val_loss: 231.4604 - val_o1_loss: 0.3621 - val_o2_loss: 0.3100 - val_o3_loss: 0.3173 - val_o4_loss: 0.3343 - val_o5_loss: 0.3501 - val_o6_loss: 0.3745 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 61.8169 - o1_loss: 0.2524 - o2_loss: 0.1263 - o3_loss: 0.1081 - o4_loss: 0.0961 - o5_loss: 0.0980 - o6_loss: 0.0901 - o1_f1: 0.8722 - o2_f1: 0.9543 - o3_f1: 0.9584 - o4_f1: 0.9590 - o5_f1: 0.9591 - o6_f1: 0.9578 - val_loss: 231.5234 - val_o1_loss: 0.3621 - val_o2_loss: 0.3100 - val_o3_loss: 0.3173 - val_o4_loss: 0.3344 - val_o5_loss: 0.3502 - val_o6_loss: 0.3746 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 159/500\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 61.8225 - o1_loss: 0.2525 - o2_loss: 0.1264 - o3_loss: 0.1082 - o4_loss: 0.0961 - o5_loss: 0.0980 - o6_loss: 0.0901 - o1_f1: 0.8827 - o2_f1: 0.9582 - o3_f1: 0.9618 - o4_f1: 0.9643 - o5_f1: 0.9616 - o6_f1: 0.9655 - val_loss: 232.1869 - val_o1_loss: 0.3622 - val_o2_loss: 0.3103 - val_o3_loss: 0.3177 - val_o4_loss: 0.3350 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 160/500\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.7839 - o1_loss: 0.2524 - o2_loss: 0.1263 - o3_loss: 0.1081 - o4_loss: 0.0960 - o5_loss: 0.0980 - o6_loss: 0.0900 - o1_f1: 0.8721 - o2_f1: 0.9475 - o3_f1: 0.9525 - o4_f1: 0.9554 - o5_f1: 0.9546 - o6_f1: 0.9585 - val_loss: 232.0570 - val_o1_loss: 0.3622 - val_o2_loss: 0.3103 - val_o3_loss: 0.3176 - val_o4_loss: 0.3348 - val_o5_loss: 0.3508 - val_o6_loss: 0.3757 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 161/500\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.7584 - o1_loss: 0.2524 - o2_loss: 0.1262 - o3_loss: 0.1081 - o4_loss: 0.0960 - o5_loss: 0.0979 - o6_loss: 0.0900 - o1_f1: 0.8673 - o2_f1: 0.9534 - o3_f1: 0.9574 - o4_f1: 0.9569 - o5_f1: 0.9570 - o6_f1: 0.9586 - val_loss: 231.2511 - val_o1_loss: 0.3619 - val_o2_loss: 0.3098 - val_o3_loss: 0.3171 - val_o4_loss: 0.3342 - val_o5_loss: 0.3499 - val_o6_loss: 0.3741 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 162/500\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.7455 - o1_loss: 0.2524 - o2_loss: 0.1262 - o3_loss: 0.1080 - o4_loss: 0.0960 - o5_loss: 0.0979 - o6_loss: 0.0900 - o1_f1: 0.8783 - o2_f1: 0.9588 - o3_f1: 0.9629 - o4_f1: 0.9651 - o5_f1: 0.9619 - o6_f1: 0.9620 - val_loss: 231.5777 - val_o1_loss: 0.3619 - val_o2_loss: 0.3100 - val_o3_loss: 0.3173 - val_o4_loss: 0.3344 - val_o5_loss: 0.3503 - val_o6_loss: 0.3747 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 163/500\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.6550 - o1_loss: 0.2524 - o2_loss: 0.1261 - o3_loss: 0.1079 - o4_loss: 0.0958 - o5_loss: 0.0977 - o6_loss: 0.0898 - o1_f1: 0.8746 - o2_f1: 0.9590 - o3_f1: 0.9634 - o4_f1: 0.9646 - o5_f1: 0.9623 - o6_f1: 0.9659 - val_loss: 231.7994 - val_o1_loss: 0.3620 - val_o2_loss: 0.3101 - val_o3_loss: 0.3174 - val_o4_loss: 0.3346 - val_o5_loss: 0.3505 - val_o6_loss: 0.3752 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 164/500\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.6843 - o1_loss: 0.2524 - o2_loss: 0.1262 - o3_loss: 0.1079 - o4_loss: 0.0959 - o5_loss: 0.0978 - o6_loss: 0.0899 - o1_f1: 0.8732 - o2_f1: 0.9561 - o3_f1: 0.9592 - o4_f1: 0.9592 - o5_f1: 0.9594 - o6_f1: 0.9595 - val_loss: 231.6400 - val_o1_loss: 0.3619 - val_o2_loss: 0.3100 - val_o3_loss: 0.3173 - val_o4_loss: 0.3345 - val_o5_loss: 0.3503 - val_o6_loss: 0.3748 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 165/500\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.6026 - o1_loss: 0.2523 - o2_loss: 0.1261 - o3_loss: 0.1079 - o4_loss: 0.0958 - o5_loss: 0.0976 - o6_loss: 0.0897 - o1_f1: 0.8697 - o2_f1: 0.9574 - o3_f1: 0.9608 - o4_f1: 0.9623 - o5_f1: 0.9596 - o6_f1: 0.9637 - val_loss: 231.8810 - val_o1_loss: 0.3619 - val_o2_loss: 0.3101 - val_o3_loss: 0.3175 - val_o4_loss: 0.3347 - val_o5_loss: 0.3506 - val_o6_loss: 0.3753 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 166/500\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.5621 - o1_loss: 0.2523 - o2_loss: 0.1260 - o3_loss: 0.1078 - o4_loss: 0.0957 - o5_loss: 0.0976 - o6_loss: 0.0896 - o1_f1: 0.8763 - o2_f1: 0.9569 - o3_f1: 0.9601 - o4_f1: 0.9619 - o5_f1: 0.9616 - o6_f1: 0.9632 - val_loss: 232.3225 - val_o1_loss: 0.3620 - val_o2_loss: 0.3104 - val_o3_loss: 0.3178 - val_o4_loss: 0.3351 - val_o5_loss: 0.3510 - val_o6_loss: 0.3762 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 167/500\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.5440 - o1_loss: 0.2523 - o2_loss: 0.1260 - o3_loss: 0.1078 - o4_loss: 0.0957 - o5_loss: 0.0976 - o6_loss: 0.0896 - o1_f1: 0.8757 - o2_f1: 0.9582 - o3_f1: 0.9619 - o4_f1: 0.9636 - o5_f1: 0.9633 - o6_f1: 0.9658 - val_loss: 232.1702 - val_o1_loss: 0.3620 - val_o2_loss: 0.3103 - val_o3_loss: 0.3177 - val_o4_loss: 0.3350 - val_o5_loss: 0.3508 - val_o6_loss: 0.3759 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 168/500\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.4887 - o1_loss: 0.2523 - o2_loss: 0.1260 - o3_loss: 0.1077 - o4_loss: 0.0956 - o5_loss: 0.0975 - o6_loss: 0.0895 - o1_f1: 0.8731 - o2_f1: 0.9539 - o3_f1: 0.9586 - o4_f1: 0.9606 - o5_f1: 0.9606 - o6_f1: 0.9631 - val_loss: 231.6676 - val_o1_loss: 0.3618 - val_o2_loss: 0.3100 - val_o3_loss: 0.3174 - val_o4_loss: 0.3345 - val_o5_loss: 0.3503 - val_o6_loss: 0.3749 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 169/500\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.4481 - o1_loss: 0.2522 - o2_loss: 0.1259 - o3_loss: 0.1076 - o4_loss: 0.0955 - o5_loss: 0.0974 - o6_loss: 0.0895 - o1_f1: 0.8668 - o2_f1: 0.9554 - o3_f1: 0.9595 - o4_f1: 0.9611 - o5_f1: 0.9580 - o6_f1: 0.9608 - val_loss: 231.6931 - val_o1_loss: 0.3618 - val_o2_loss: 0.3100 - val_o3_loss: 0.3174 - val_o4_loss: 0.3346 - val_o5_loss: 0.3503 - val_o6_loss: 0.3750 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 170/500\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.4193 - o1_loss: 0.2522 - o2_loss: 0.1259 - o3_loss: 0.1076 - o4_loss: 0.0955 - o5_loss: 0.0974 - o6_loss: 0.0894 - o1_f1: 0.8640 - o2_f1: 0.9495 - o3_f1: 0.9528 - o4_f1: 0.9546 - o5_f1: 0.9539 - o6_f1: 0.9578 - val_loss: 231.8361 - val_o1_loss: 0.3619 - val_o2_loss: 0.3101 - val_o3_loss: 0.3175 - val_o4_loss: 0.3347 - val_o5_loss: 0.3505 - val_o6_loss: 0.3752 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 171/500\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.3430 - o1_loss: 0.2522 - o2_loss: 0.1258 - o3_loss: 0.1075 - o4_loss: 0.0954 - o5_loss: 0.0972 - o6_loss: 0.0893 - o1_f1: 0.8797 - o2_f1: 0.9577 - o3_f1: 0.9621 - o4_f1: 0.9646 - o5_f1: 0.9633 - o6_f1: 0.9667 - val_loss: 231.3449 - val_o1_loss: 0.3618 - val_o2_loss: 0.3099 - val_o3_loss: 0.3173 - val_o4_loss: 0.3343 - val_o5_loss: 0.3499 - val_o6_loss: 0.3743 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.3869 - o1_loss: 0.2522 - o2_loss: 0.1258 - o3_loss: 0.1075 - o4_loss: 0.0954 - o5_loss: 0.0972 - o6_loss: 0.0894 - o1_f1: 0.8784 - o2_f1: 0.9559 - o3_f1: 0.9618 - o4_f1: 0.9616 - o5_f1: 0.9614 - o6_f1: 0.9598 - val_loss: 230.7787 - val_o1_loss: 0.3617 - val_o2_loss: 0.3096 - val_o3_loss: 0.3170 - val_o4_loss: 0.3339 - val_o5_loss: 0.3493 - val_o6_loss: 0.3732 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 173/500\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.3642 - o1_loss: 0.2522 - o2_loss: 0.1257 - o3_loss: 0.1075 - o4_loss: 0.0954 - o5_loss: 0.0972 - o6_loss: 0.0893 - o1_f1: 0.8718 - o2_f1: 0.9554 - o3_f1: 0.9615 - o4_f1: 0.9617 - o5_f1: 0.9614 - o6_f1: 0.9592 - val_loss: 230.8764 - val_o1_loss: 0.3616 - val_o2_loss: 0.3096 - val_o3_loss: 0.3170 - val_o4_loss: 0.3340 - val_o5_loss: 0.3494 - val_o6_loss: 0.3733 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 174/500\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.3172 - o1_loss: 0.2522 - o2_loss: 0.1257 - o3_loss: 0.1074 - o4_loss: 0.0953 - o5_loss: 0.0971 - o6_loss: 0.0893 - o1_f1: 0.8767 - o2_f1: 0.9551 - o3_f1: 0.9594 - o4_f1: 0.9594 - o5_f1: 0.9591 - o6_f1: 0.9606 - val_loss: 231.0659 - val_o1_loss: 0.3616 - val_o2_loss: 0.3097 - val_o3_loss: 0.3171 - val_o4_loss: 0.3341 - val_o5_loss: 0.3496 - val_o6_loss: 0.3737 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 175/500\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.2789 - o1_loss: 0.2521 - o2_loss: 0.1257 - o3_loss: 0.1074 - o4_loss: 0.0953 - o5_loss: 0.0971 - o6_loss: 0.0892 - o1_f1: 0.8700 - o2_f1: 0.9563 - o3_f1: 0.9607 - o4_f1: 0.9603 - o5_f1: 0.9609 - o6_f1: 0.9617 - val_loss: 231.4775 - val_o1_loss: 0.3617 - val_o2_loss: 0.3099 - val_o3_loss: 0.3173 - val_o4_loss: 0.3344 - val_o5_loss: 0.3501 - val_o6_loss: 0.3745 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 176/500\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.2497 - o1_loss: 0.2521 - o2_loss: 0.1256 - o3_loss: 0.1073 - o4_loss: 0.0952 - o5_loss: 0.0970 - o6_loss: 0.0891 - o1_f1: 0.8710 - o2_f1: 0.9533 - o3_f1: 0.9573 - o4_f1: 0.9589 - o5_f1: 0.9600 - o6_f1: 0.9572 - val_loss: 231.2341 - val_o1_loss: 0.3616 - val_o2_loss: 0.3098 - val_o3_loss: 0.3172 - val_o4_loss: 0.3343 - val_o5_loss: 0.3498 - val_o6_loss: 0.3740 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 177/500\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.1745 - o1_loss: 0.2521 - o2_loss: 0.1256 - o3_loss: 0.1072 - o4_loss: 0.0951 - o5_loss: 0.0969 - o6_loss: 0.0890 - o1_f1: 0.8734 - o2_f1: 0.9553 - o3_f1: 0.9595 - o4_f1: 0.9597 - o5_f1: 0.9605 - o6_f1: 0.9608 - val_loss: 231.5759 - val_o1_loss: 0.3617 - val_o2_loss: 0.3100 - val_o3_loss: 0.3174 - val_o4_loss: 0.3345 - val_o5_loss: 0.3502 - val_o6_loss: 0.3747 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 178/500\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.2179 - o1_loss: 0.2521 - o2_loss: 0.1256 - o3_loss: 0.1073 - o4_loss: 0.0952 - o5_loss: 0.0970 - o6_loss: 0.0891 - o1_f1: 0.8663 - o2_f1: 0.9557 - o3_f1: 0.9605 - o4_f1: 0.9612 - o5_f1: 0.9613 - o6_f1: 0.9626 - val_loss: 231.5151 - val_o1_loss: 0.3617 - val_o2_loss: 0.3099 - val_o3_loss: 0.3173 - val_o4_loss: 0.3345 - val_o5_loss: 0.3501 - val_o6_loss: 0.3746 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 179/500\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.1377 - o1_loss: 0.2520 - o2_loss: 0.1255 - o3_loss: 0.1072 - o4_loss: 0.0951 - o5_loss: 0.0969 - o6_loss: 0.0890 - o1_f1: 0.8685 - o2_f1: 0.9535 - o3_f1: 0.9573 - o4_f1: 0.9596 - o5_f1: 0.9581 - o6_f1: 0.9625 - val_loss: 231.6647 - val_o1_loss: 0.3617 - val_o2_loss: 0.3100 - val_o3_loss: 0.3174 - val_o4_loss: 0.3346 - val_o5_loss: 0.3503 - val_o6_loss: 0.3749 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 180/500\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.0841 - o1_loss: 0.2520 - o2_loss: 0.1255 - o3_loss: 0.1072 - o4_loss: 0.0950 - o5_loss: 0.0968 - o6_loss: 0.0889 - o1_f1: 0.8731 - o2_f1: 0.9515 - o3_f1: 0.9558 - o4_f1: 0.9577 - o5_f1: 0.9561 - o6_f1: 0.9605 - val_loss: 232.0288 - val_o1_loss: 0.3618 - val_o2_loss: 0.3102 - val_o3_loss: 0.3176 - val_o4_loss: 0.3349 - val_o5_loss: 0.3506 - val_o6_loss: 0.3756 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 181/500\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.0873 - o1_loss: 0.2520 - o2_loss: 0.1255 - o3_loss: 0.1071 - o4_loss: 0.0950 - o5_loss: 0.0968 - o6_loss: 0.0889 - o1_f1: 0.8788 - o2_f1: 0.9592 - o3_f1: 0.9642 - o4_f1: 0.9658 - o5_f1: 0.9631 - o6_f1: 0.9667 - val_loss: 232.0257 - val_o1_loss: 0.3618 - val_o2_loss: 0.3102 - val_o3_loss: 0.3176 - val_o4_loss: 0.3349 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 182/500\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 61.0381 - o1_loss: 0.2520 - o2_loss: 0.1254 - o3_loss: 0.1071 - o4_loss: 0.0949 - o5_loss: 0.0967 - o6_loss: 0.0888 - o1_f1: 0.8808 - o2_f1: 0.9561 - o3_f1: 0.9600 - o4_f1: 0.9620 - o5_f1: 0.9623 - o6_f1: 0.9644 - val_loss: 232.2141 - val_o1_loss: 0.3619 - val_o2_loss: 0.3103 - val_o3_loss: 0.3178 - val_o4_loss: 0.3351 - val_o5_loss: 0.3508 - val_o6_loss: 0.3760 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 183/500\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.9432 - o1_loss: 0.2519 - o2_loss: 0.1253 - o3_loss: 0.1069 - o4_loss: 0.0948 - o5_loss: 0.0966 - o6_loss: 0.0886 - o1_f1: 0.8742 - o2_f1: 0.9554 - o3_f1: 0.9597 - o4_f1: 0.9616 - o5_f1: 0.9594 - o6_f1: 0.9627 - val_loss: 231.6002 - val_o1_loss: 0.3617 - val_o2_loss: 0.3100 - val_o3_loss: 0.3174 - val_o4_loss: 0.3346 - val_o5_loss: 0.3501 - val_o6_loss: 0.3748 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 184/500\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.9603 - o1_loss: 0.2520 - o2_loss: 0.1253 - o3_loss: 0.1069 - o4_loss: 0.0948 - o5_loss: 0.0966 - o6_loss: 0.0887 - o1_f1: 0.8717 - o2_f1: 0.9546 - o3_f1: 0.9589 - o4_f1: 0.9616 - o5_f1: 0.9592 - o6_f1: 0.9583 - val_loss: 231.3281 - val_o1_loss: 0.3617 - val_o2_loss: 0.3098 - val_o3_loss: 0.3173 - val_o4_loss: 0.3344 - val_o5_loss: 0.3498 - val_o6_loss: 0.3742 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 185/500\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.9264 - o1_loss: 0.2519 - o2_loss: 0.1252 - o3_loss: 0.1069 - o4_loss: 0.0947 - o5_loss: 0.0965 - o6_loss: 0.0886 - o1_f1: 0.8725 - o2_f1: 0.9564 - o3_f1: 0.9599 - o4_f1: 0.9628 - o5_f1: 0.9621 - o6_f1: 0.9607 - val_loss: 231.2761 - val_o1_loss: 0.3616 - val_o2_loss: 0.3098 - val_o3_loss: 0.3173 - val_o4_loss: 0.3343 - val_o5_loss: 0.3498 - val_o6_loss: 0.3741 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 186/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.9104 - o1_loss: 0.2519 - o2_loss: 0.1252 - o3_loss: 0.1068 - o4_loss: 0.0947 - o5_loss: 0.0965 - o6_loss: 0.0886 - o1_f1: 0.8741 - o2_f1: 0.9536 - o3_f1: 0.9582 - o4_f1: 0.9583 - o5_f1: 0.9583 - o6_f1: 0.9589 - val_loss: 231.1663 - val_o1_loss: 0.3616 - val_o2_loss: 0.3098 - val_o3_loss: 0.3172 - val_o4_loss: 0.3343 - val_o5_loss: 0.3497 - val_o6_loss: 0.3739 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 187/500\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.8972 - o1_loss: 0.2519 - o2_loss: 0.1252 - o3_loss: 0.1068 - o4_loss: 0.0947 - o5_loss: 0.0964 - o6_loss: 0.0886 - o1_f1: 0.8721 - o2_f1: 0.9572 - o3_f1: 0.9604 - o4_f1: 0.9601 - o5_f1: 0.9601 - o6_f1: 0.9604 - val_loss: 231.1012 - val_o1_loss: 0.3615 - val_o2_loss: 0.3097 - val_o3_loss: 0.3172 - val_o4_loss: 0.3342 - val_o5_loss: 0.3496 - val_o6_loss: 0.3738 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 188/500\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.8184 - o1_loss: 0.2519 - o2_loss: 0.1251 - o3_loss: 0.1067 - o4_loss: 0.0946 - o5_loss: 0.0963 - o6_loss: 0.0884 - o1_f1: 0.8701 - o2_f1: 0.9563 - o3_f1: 0.9604 - o4_f1: 0.9605 - o5_f1: 0.9607 - o6_f1: 0.9600 - val_loss: 231.4545 - val_o1_loss: 0.3616 - val_o2_loss: 0.3099 - val_o3_loss: 0.3173 - val_o4_loss: 0.3345 - val_o5_loss: 0.3500 - val_o6_loss: 0.3745 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 189/500\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.7941 - o1_loss: 0.2519 - o2_loss: 0.1251 - o3_loss: 0.1067 - o4_loss: 0.0946 - o5_loss: 0.0963 - o6_loss: 0.0884 - o1_f1: 0.8719 - o2_f1: 0.9574 - o3_f1: 0.9617 - o4_f1: 0.9633 - o5_f1: 0.9609 - o6_f1: 0.9635 - val_loss: 231.8180 - val_o1_loss: 0.3616 - val_o2_loss: 0.3100 - val_o3_loss: 0.3175 - val_o4_loss: 0.3348 - val_o5_loss: 0.3504 - val_o6_loss: 0.3752 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 190/500\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.7793 - o1_loss: 0.2518 - o2_loss: 0.1251 - o3_loss: 0.1067 - o4_loss: 0.0945 - o5_loss: 0.0963 - o6_loss: 0.0884 - o1_f1: 0.8674 - o2_f1: 0.9475 - o3_f1: 0.9516 - o4_f1: 0.9536 - o5_f1: 0.9539 - o6_f1: 0.9555 - val_loss: 232.2316 - val_o1_loss: 0.3616 - val_o2_loss: 0.3102 - val_o3_loss: 0.3178 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3760 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 191/500\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.7286 - o1_loss: 0.2518 - o2_loss: 0.1250 - o3_loss: 0.1066 - o4_loss: 0.0945 - o5_loss: 0.0962 - o6_loss: 0.0883 - o1_f1: 0.8805 - o2_f1: 0.9579 - o3_f1: 0.9628 - o4_f1: 0.9642 - o5_f1: 0.9621 - o6_f1: 0.9662 - val_loss: 231.8607 - val_o1_loss: 0.3614 - val_o2_loss: 0.3100 - val_o3_loss: 0.3175 - val_o4_loss: 0.3349 - val_o5_loss: 0.3505 - val_o6_loss: 0.3752 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 192/500\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.7477 - o1_loss: 0.2519 - o2_loss: 0.1250 - o3_loss: 0.1067 - o4_loss: 0.0945 - o5_loss: 0.0962 - o6_loss: 0.0883 - o1_f1: 0.8727 - o2_f1: 0.9573 - o3_f1: 0.9608 - o4_f1: 0.9628 - o5_f1: 0.9631 - o6_f1: 0.9649 - val_loss: 232.7655 - val_o1_loss: 0.3617 - val_o2_loss: 0.3105 - val_o3_loss: 0.3181 - val_o4_loss: 0.3356 - val_o5_loss: 0.3515 - val_o6_loss: 0.3770 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 193/500\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.6310 - o1_loss: 0.2518 - o2_loss: 0.1249 - o3_loss: 0.1065 - o4_loss: 0.0943 - o5_loss: 0.0961 - o6_loss: 0.0881 - o1_f1: 0.8720 - o2_f1: 0.9535 - o3_f1: 0.9572 - o4_f1: 0.9599 - o5_f1: 0.9591 - o6_f1: 0.9620 - val_loss: 232.1535 - val_o1_loss: 0.3615 - val_o2_loss: 0.3102 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3508 - val_o6_loss: 0.3758 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 194/500\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.6334 - o1_loss: 0.2518 - o2_loss: 0.1249 - o3_loss: 0.1065 - o4_loss: 0.0943 - o5_loss: 0.0960 - o6_loss: 0.0881 - o1_f1: 0.8764 - o2_f1: 0.9577 - o3_f1: 0.9616 - o4_f1: 0.9635 - o5_f1: 0.9616 - o6_f1: 0.9660 - val_loss: 231.6692 - val_o1_loss: 0.3614 - val_o2_loss: 0.3099 - val_o3_loss: 0.3175 - val_o4_loss: 0.3347 - val_o5_loss: 0.3503 - val_o6_loss: 0.3749 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 195/500\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.6041 - o1_loss: 0.2517 - o2_loss: 0.1248 - o3_loss: 0.1064 - o4_loss: 0.0943 - o5_loss: 0.0960 - o6_loss: 0.0881 - o1_f1: 0.8720 - o2_f1: 0.9544 - o3_f1: 0.9584 - o4_f1: 0.9601 - o5_f1: 0.9574 - o6_f1: 0.9633 - val_loss: 231.6193 - val_o1_loss: 0.3614 - val_o2_loss: 0.3099 - val_o3_loss: 0.3174 - val_o4_loss: 0.3347 - val_o5_loss: 0.3502 - val_o6_loss: 0.3748 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 196/500\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.5792 - o1_loss: 0.2517 - o2_loss: 0.1248 - o3_loss: 0.1064 - o4_loss: 0.0942 - o5_loss: 0.0959 - o6_loss: 0.0881 - o1_f1: 0.8713 - o2_f1: 0.9536 - o3_f1: 0.9579 - o4_f1: 0.9570 - o5_f1: 0.9568 - o6_f1: 0.9588 - val_loss: 231.1774 - val_o1_loss: 0.3613 - val_o2_loss: 0.3097 - val_o3_loss: 0.3172 - val_o4_loss: 0.3343 - val_o5_loss: 0.3498 - val_o6_loss: 0.3739 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 197/500\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.5639 - o1_loss: 0.2517 - o2_loss: 0.1248 - o3_loss: 0.1064 - o4_loss: 0.0942 - o5_loss: 0.0959 - o6_loss: 0.0880 - o1_f1: 0.8757 - o2_f1: 0.9546 - o3_f1: 0.9599 - o4_f1: 0.9605 - o5_f1: 0.9605 - o6_f1: 0.9587 - val_loss: 231.1495 - val_o1_loss: 0.3613 - val_o2_loss: 0.3097 - val_o3_loss: 0.3172 - val_o4_loss: 0.3343 - val_o5_loss: 0.3497 - val_o6_loss: 0.3738 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 198/500\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.5270 - o1_loss: 0.2517 - o2_loss: 0.1247 - o3_loss: 0.1063 - o4_loss: 0.0942 - o5_loss: 0.0958 - o6_loss: 0.0880 - o1_f1: 0.8626 - o2_f1: 0.9439 - o3_f1: 0.9494 - o4_f1: 0.9499 - o5_f1: 0.9504 - o6_f1: 0.9538 - val_loss: 231.7064 - val_o1_loss: 0.3614 - val_o2_loss: 0.3099 - val_o3_loss: 0.3175 - val_o4_loss: 0.3348 - val_o5_loss: 0.3503 - val_o6_loss: 0.3749 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 199/500\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 1s - loss: 60.4918 - o1_loss: 0.2517 - o2_loss: 0.1247 - o3_loss: 0.1063 - o4_loss: 0.0941 - o5_loss: 0.0958 - o6_loss: 0.0879 - o1_f1: 0.8768 - o2_f1: 0.9532 - o3_f1: 0.9582 - o4_f1: 0.9598 - o5_f1: 0.9598 - o6_f1: 0.9617 - val_loss: 232.3967 - val_o1_loss: 0.3615 - val_o2_loss: 0.3103 - val_o3_loss: 0.3179 - val_o4_loss: 0.3353 - val_o5_loss: 0.3511 - val_o6_loss: 0.3763 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.4221 - o1_loss: 0.2517 - o2_loss: 0.1247 - o3_loss: 0.1062 - o4_loss: 0.0940 - o5_loss: 0.0957 - o6_loss: 0.0878 - o1_f1: 0.8780 - o2_f1: 0.9582 - o3_f1: 0.9614 - o4_f1: 0.9633 - o5_f1: 0.9648 - o6_f1: 0.9667 - val_loss: 232.3783 - val_o1_loss: 0.3615 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3762 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 201/500\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.4381 - o1_loss: 0.2517 - o2_loss: 0.1247 - o3_loss: 0.1063 - o4_loss: 0.0941 - o5_loss: 0.0957 - o6_loss: 0.0878 - o1_f1: 0.8704 - o2_f1: 0.9488 - o3_f1: 0.9531 - o4_f1: 0.9618 - o5_f1: 0.9618 - o6_f1: 0.9638 - val_loss: 232.6431 - val_o1_loss: 0.3616 - val_o2_loss: 0.3104 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3768 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 202/500\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.4274 - o1_loss: 0.2517 - o2_loss: 0.1247 - o3_loss: 0.1062 - o4_loss: 0.0940 - o5_loss: 0.0957 - o6_loss: 0.0878 - o1_f1: 0.8771 - o2_f1: 0.9568 - o3_f1: 0.9605 - o4_f1: 0.9627 - o5_f1: 0.9626 - o6_f1: 0.9643 - val_loss: 232.7195 - val_o1_loss: 0.3615 - val_o2_loss: 0.3104 - val_o3_loss: 0.3181 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3769 - val_o1_f1: 0.6821 - val_o2_f1: 0.7001 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 203/500\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.4126 - o1_loss: 0.2516 - o2_loss: 0.1247 - o3_loss: 0.1062 - o4_loss: 0.0940 - o5_loss: 0.0957 - o6_loss: 0.0878 - o1_f1: 0.8792 - o2_f1: 0.9563 - o3_f1: 0.9605 - o4_f1: 0.9626 - o5_f1: 0.9629 - o6_f1: 0.9647 - val_loss: 232.6737 - val_o1_loss: 0.3615 - val_o2_loss: 0.3104 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3768 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 204/500\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3943 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1062 - o4_loss: 0.0940 - o5_loss: 0.0957 - o6_loss: 0.0877 - o1_f1: 0.8750 - o2_f1: 0.9568 - o3_f1: 0.9613 - o4_f1: 0.9630 - o5_f1: 0.9634 - o6_f1: 0.9664 - val_loss: 232.5435 - val_o1_loss: 0.3615 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3766 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 205/500\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3845 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1062 - o4_loss: 0.0940 - o5_loss: 0.0956 - o6_loss: 0.0877 - o1_f1: 0.8789 - o2_f1: 0.9559 - o3_f1: 0.9609 - o4_f1: 0.9625 - o5_f1: 0.9625 - o6_f1: 0.9643 - val_loss: 232.4214 - val_o1_loss: 0.3615 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3763 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 206/500\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3698 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1062 - o4_loss: 0.0939 - o5_loss: 0.0956 - o6_loss: 0.0877 - o1_f1: 0.8662 - o2_f1: 0.9448 - o3_f1: 0.9491 - o4_f1: 0.9516 - o5_f1: 0.9515 - o6_f1: 0.9533 - val_loss: 232.3230 - val_o1_loss: 0.3615 - val_o2_loss: 0.3102 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 207/500\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3658 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1061 - o4_loss: 0.0939 - o5_loss: 0.0956 - o6_loss: 0.0877 - o1_f1: 0.8802 - o2_f1: 0.9578 - o3_f1: 0.9614 - o4_f1: 0.9633 - o5_f1: 0.9637 - o6_f1: 0.9656 - val_loss: 232.1685 - val_o1_loss: 0.3614 - val_o2_loss: 0.3101 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3508 - val_o6_loss: 0.3758 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 208/500\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3519 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1061 - o4_loss: 0.0939 - o5_loss: 0.0956 - o6_loss: 0.0877 - o1_f1: 0.8770 - o2_f1: 0.9558 - o3_f1: 0.9597 - o4_f1: 0.9621 - o5_f1: 0.9625 - o6_f1: 0.9645 - val_loss: 232.0723 - val_o1_loss: 0.3614 - val_o2_loss: 0.3101 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 209/500\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3429 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1061 - o4_loss: 0.0939 - o5_loss: 0.0956 - o6_loss: 0.0877 - o1_f1: 0.8710 - o2_f1: 0.9541 - o3_f1: 0.9583 - o4_f1: 0.9600 - o5_f1: 0.9599 - o6_f1: 0.9625 - val_loss: 232.0399 - val_o1_loss: 0.3614 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3350 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 210/500\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3421 - o1_loss: 0.2516 - o2_loss: 0.1246 - o3_loss: 0.1061 - o4_loss: 0.0939 - o5_loss: 0.0956 - o6_loss: 0.0877 - o1_f1: 0.8772 - o2_f1: 0.9513 - o3_f1: 0.9556 - o4_f1: 0.9576 - o5_f1: 0.9573 - o6_f1: 0.9589 - val_loss: 232.0458 - val_o1_loss: 0.3614 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3350 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 211/500\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3159 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1061 - o4_loss: 0.0939 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8663 - o2_f1: 0.9484 - o3_f1: 0.9524 - o4_f1: 0.9547 - o5_f1: 0.9552 - o6_f1: 0.9569 - val_loss: 231.8481 - val_o1_loss: 0.3613 - val_o2_loss: 0.3100 - val_o3_loss: 0.3176 - val_o4_loss: 0.3349 - val_o5_loss: 0.3505 - val_o6_loss: 0.3752 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 212/500\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3241 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1061 - o4_loss: 0.0939 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8751 - o2_f1: 0.9536 - o3_f1: 0.9580 - o4_f1: 0.9601 - o5_f1: 0.9575 - o6_f1: 0.9616 - val_loss: 231.7862 - val_o1_loss: 0.3613 - val_o2_loss: 0.3099 - val_o3_loss: 0.3175 - val_o4_loss: 0.3348 - val_o5_loss: 0.3504 - val_o6_loss: 0.3751 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 213/500\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3023 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8687 - o2_f1: 0.9494 - o3_f1: 0.9529 - o4_f1: 0.9548 - o5_f1: 0.9551 - o6_f1: 0.9571 - val_loss: 231.9076 - val_o1_loss: 0.3613 - val_o2_loss: 0.3100 - val_o3_loss: 0.3176 - val_o4_loss: 0.3349 - val_o5_loss: 0.3505 - val_o6_loss: 0.3753 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/500\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3073 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8674 - o2_f1: 0.9517 - o3_f1: 0.9555 - o4_f1: 0.9574 - o5_f1: 0.9579 - o6_f1: 0.9595 - val_loss: 231.9063 - val_o1_loss: 0.3613 - val_o2_loss: 0.3100 - val_o3_loss: 0.3176 - val_o4_loss: 0.3349 - val_o5_loss: 0.3505 - val_o6_loss: 0.3753 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 215/500\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2966 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8750 - o2_f1: 0.9572 - o3_f1: 0.9612 - o4_f1: 0.9628 - o5_f1: 0.9630 - o6_f1: 0.9657 - val_loss: 232.0301 - val_o1_loss: 0.3613 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3350 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 216/500\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2809 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0875 - o1_f1: 0.8796 - o2_f1: 0.9568 - o3_f1: 0.9620 - o4_f1: 0.9629 - o5_f1: 0.9624 - o6_f1: 0.9649 - val_loss: 232.3153 - val_o1_loss: 0.3614 - val_o2_loss: 0.3102 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 217/500\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.3036 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1061 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8782 - o2_f1: 0.9550 - o3_f1: 0.9590 - o4_f1: 0.9617 - o5_f1: 0.9609 - o6_f1: 0.9638 - val_loss: 232.5785 - val_o1_loss: 0.3614 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 218/500\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2854 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0876 - o1_f1: 0.8785 - o2_f1: 0.9585 - o3_f1: 0.9619 - o4_f1: 0.9642 - o5_f1: 0.9634 - o6_f1: 0.9649 - val_loss: 232.5169 - val_o1_loss: 0.3614 - val_o2_loss: 0.3103 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 219/500\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2668 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0875 - o1_f1: 0.8733 - o2_f1: 0.9497 - o3_f1: 0.9527 - o4_f1: 0.9544 - o5_f1: 0.9547 - o6_f1: 0.9567 - val_loss: 232.4775 - val_o1_loss: 0.3614 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3512 - val_o6_loss: 0.3764 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 220/500\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2760 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0955 - o6_loss: 0.0875 - o1_f1: 0.8818 - o2_f1: 0.9612 - o3_f1: 0.9647 - o4_f1: 0.9666 - o5_f1: 0.9665 - o6_f1: 0.9684 - val_loss: 232.6538 - val_o1_loss: 0.3614 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3768 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7001 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 221/500\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2502 - o1_loss: 0.2516 - o2_loss: 0.1245 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0954 - o6_loss: 0.0875 - o1_f1: 0.8797 - o2_f1: 0.9567 - o3_f1: 0.9607 - o4_f1: 0.9630 - o5_f1: 0.9630 - o6_f1: 0.9647 - val_loss: 232.5280 - val_o1_loss: 0.3614 - val_o2_loss: 0.3103 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 222/500\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2399 - o1_loss: 0.2516 - o2_loss: 0.1244 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0954 - o6_loss: 0.0875 - o1_f1: 0.8715 - o2_f1: 0.9500 - o3_f1: 0.9561 - o4_f1: 0.9596 - o5_f1: 0.9592 - o6_f1: 0.9612 - val_loss: 232.4995 - val_o1_loss: 0.3614 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 223/500\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2479 - o1_loss: 0.2516 - o2_loss: 0.1244 - o3_loss: 0.1060 - o4_loss: 0.0938 - o5_loss: 0.0954 - o6_loss: 0.0875 - o1_f1: 0.8781 - o2_f1: 0.9574 - o3_f1: 0.9620 - o4_f1: 0.9643 - o5_f1: 0.9630 - o6_f1: 0.9653 - val_loss: 232.4675 - val_o1_loss: 0.3614 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3512 - val_o6_loss: 0.3764 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 224/500\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2190 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0937 - o5_loss: 0.0954 - o6_loss: 0.0874 - o1_f1: 0.8759 - o2_f1: 0.9572 - o3_f1: 0.9608 - o4_f1: 0.9627 - o5_f1: 0.9628 - o6_f1: 0.9646 - val_loss: 232.2467 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3760 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 225/500\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2088 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0937 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8670 - o2_f1: 0.9566 - o3_f1: 0.9607 - o4_f1: 0.9624 - o5_f1: 0.9616 - o6_f1: 0.9641 - val_loss: 232.2349 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 226/500\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2027 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0937 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8698 - o2_f1: 0.9550 - o3_f1: 0.9587 - o4_f1: 0.9606 - o5_f1: 0.9596 - o6_f1: 0.9616 - val_loss: 232.1970 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3177 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 227/500\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.2055 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0937 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8759 - o2_f1: 0.9578 - o3_f1: 0.9625 - o4_f1: 0.9642 - o5_f1: 0.9636 - o6_f1: 0.9663 - val_loss: 232.0937 - val_o1_loss: 0.3613 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3508 - val_o6_loss: 0.3757 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1946 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0937 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8747 - o2_f1: 0.9563 - o3_f1: 0.9608 - o4_f1: 0.9629 - o5_f1: 0.9618 - o6_f1: 0.9639 - val_loss: 232.1925 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3177 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 229/500\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1796 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0937 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8785 - o2_f1: 0.9616 - o3_f1: 0.9644 - o4_f1: 0.9656 - o5_f1: 0.9664 - o6_f1: 0.9683 - val_loss: 232.1937 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3177 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 230/500\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1716 - o1_loss: 0.2515 - o2_loss: 0.1244 - o3_loss: 0.1059 - o4_loss: 0.0936 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8733 - o2_f1: 0.9467 - o3_f1: 0.9516 - o4_f1: 0.9532 - o5_f1: 0.9535 - o6_f1: 0.9551 - val_loss: 232.2343 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6821 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 231/500\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1578 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0953 - o6_loss: 0.0874 - o1_f1: 0.8726 - o2_f1: 0.9549 - o3_f1: 0.9595 - o4_f1: 0.9613 - o5_f1: 0.9631 - o6_f1: 0.9652 - val_loss: 232.1640 - val_o1_loss: 0.3613 - val_o2_loss: 0.3101 - val_o3_loss: 0.3177 - val_o4_loss: 0.3352 - val_o5_loss: 0.3508 - val_o6_loss: 0.3758 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 232/500\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1515 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8759 - o2_f1: 0.9577 - o3_f1: 0.9616 - o4_f1: 0.9639 - o5_f1: 0.9648 - o6_f1: 0.9663 - val_loss: 232.0532 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 233/500\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1445 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8604 - o2_f1: 0.9454 - o3_f1: 0.9500 - o4_f1: 0.9521 - o5_f1: 0.9531 - o6_f1: 0.9547 - val_loss: 232.0259 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3507 - val_o6_loss: 0.3755 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 234/500\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1380 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8730 - o2_f1: 0.9574 - o3_f1: 0.9613 - o4_f1: 0.9638 - o5_f1: 0.9636 - o6_f1: 0.9661 - val_loss: 232.0148 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3350 - val_o5_loss: 0.3507 - val_o6_loss: 0.3755 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 235/500\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1320 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8687 - o2_f1: 0.9558 - o3_f1: 0.9607 - o4_f1: 0.9629 - o5_f1: 0.9622 - o6_f1: 0.9645 - val_loss: 232.0008 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3176 - val_o4_loss: 0.3350 - val_o5_loss: 0.3507 - val_o6_loss: 0.3755 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 236/500\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1282 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8655 - o2_f1: 0.9562 - o3_f1: 0.9597 - o4_f1: 0.9616 - o5_f1: 0.9636 - o6_f1: 0.9658 - val_loss: 231.9828 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3176 - val_o4_loss: 0.3350 - val_o5_loss: 0.3506 - val_o6_loss: 0.3754 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 237/500\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1290 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0936 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8716 - o2_f1: 0.9566 - o3_f1: 0.9601 - o4_f1: 0.9618 - o5_f1: 0.9616 - o6_f1: 0.9645 - val_loss: 232.0379 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3507 - val_o6_loss: 0.3756 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 238/500\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1053 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0935 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8619 - o2_f1: 0.9497 - o3_f1: 0.9528 - o4_f1: 0.9548 - o5_f1: 0.9557 - o6_f1: 0.9574 - val_loss: 232.0004 - val_o1_loss: 0.3612 - val_o2_loss: 0.3100 - val_o3_loss: 0.3176 - val_o4_loss: 0.3350 - val_o5_loss: 0.3507 - val_o6_loss: 0.3755 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 239/500\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1053 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0935 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8723 - o2_f1: 0.9539 - o3_f1: 0.9580 - o4_f1: 0.9607 - o5_f1: 0.9613 - o6_f1: 0.9629 - val_loss: 231.9781 - val_o1_loss: 0.3611 - val_o2_loss: 0.3099 - val_o3_loss: 0.3176 - val_o4_loss: 0.3350 - val_o5_loss: 0.3506 - val_o6_loss: 0.3754 - val_o1_f1: 0.6779 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 240/500\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.1024 - o1_loss: 0.2515 - o2_loss: 0.1243 - o3_loss: 0.1058 - o4_loss: 0.0935 - o5_loss: 0.0952 - o6_loss: 0.0873 - o1_f1: 0.8708 - o2_f1: 0.9563 - o3_f1: 0.9620 - o4_f1: 0.9639 - o5_f1: 0.9648 - o6_f1: 0.9667 - val_loss: 232.3231 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 241/500\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0870 - o1_loss: 0.2515 - o2_loss: 0.1242 - o3_loss: 0.1058 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8781 - o2_f1: 0.9556 - o3_f1: 0.9602 - o4_f1: 0.9622 - o5_f1: 0.9618 - o6_f1: 0.9642 - val_loss: 232.4368 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3763 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0803 - o1_loss: 0.2515 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8808 - o2_f1: 0.9576 - o3_f1: 0.9625 - o4_f1: 0.9646 - o5_f1: 0.9642 - o6_f1: 0.9665 - val_loss: 232.3353 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 243/500\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0697 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8722 - o2_f1: 0.9558 - o3_f1: 0.9594 - o4_f1: 0.9612 - o5_f1: 0.9615 - o6_f1: 0.9640 - val_loss: 232.2527 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3509 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 244/500\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0562 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8730 - o2_f1: 0.9530 - o3_f1: 0.9567 - o4_f1: 0.9587 - o5_f1: 0.9591 - o6_f1: 0.9611 - val_loss: 232.2256 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3352 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 245/500\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0665 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8772 - o2_f1: 0.9549 - o3_f1: 0.9594 - o4_f1: 0.9608 - o5_f1: 0.9612 - o6_f1: 0.9633 - val_loss: 232.4297 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3763 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 246/500\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0393 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8680 - o2_f1: 0.9568 - o3_f1: 0.9614 - o4_f1: 0.9631 - o5_f1: 0.9616 - o6_f1: 0.9641 - val_loss: 232.3234 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 247/500\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0623 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0935 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8662 - o2_f1: 0.9546 - o3_f1: 0.9582 - o4_f1: 0.9603 - o5_f1: 0.9641 - o6_f1: 0.9659 - val_loss: 232.0884 - val_o1_loss: 0.3611 - val_o2_loss: 0.3100 - val_o3_loss: 0.3177 - val_o4_loss: 0.3351 - val_o5_loss: 0.3508 - val_o6_loss: 0.3756 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 248/500\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0352 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0934 - o5_loss: 0.0951 - o6_loss: 0.0872 - o1_f1: 0.8729 - o2_f1: 0.9513 - o3_f1: 0.9557 - o4_f1: 0.9589 - o5_f1: 0.9602 - o6_f1: 0.9625 - val_loss: 232.4292 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3763 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 249/500\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 1s - loss: 60.0154 - o1_loss: 0.2514 - o2_loss: 0.1242 - o3_loss: 0.1057 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8761 - o2_f1: 0.9564 - o3_f1: 0.9596 - o4_f1: 0.9616 - o5_f1: 0.9621 - o6_f1: 0.9641 - val_loss: 232.3455 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 250/500\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 60.0052 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8803 - o2_f1: 0.9569 - o3_f1: 0.9609 - o4_f1: 0.9634 - o5_f1: 0.9626 - o6_f1: 0.9647 - val_loss: 232.3674 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3762 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 251/500\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 60.0035 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8786 - o2_f1: 0.9547 - o3_f1: 0.9587 - o4_f1: 0.9608 - o5_f1: 0.9618 - o6_f1: 0.9633 - val_loss: 232.3665 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3762 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 252/500\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 60.0016 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8818 - o2_f1: 0.9599 - o3_f1: 0.9630 - o4_f1: 0.9659 - o5_f1: 0.9654 - o6_f1: 0.9675 - val_loss: 232.3666 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3762 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 253/500\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 60.0009 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8779 - o2_f1: 0.9560 - o3_f1: 0.9599 - o4_f1: 0.9621 - o5_f1: 0.9622 - o6_f1: 0.9645 - val_loss: 232.3325 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 254/500\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9967 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8735 - o2_f1: 0.9550 - o3_f1: 0.9596 - o4_f1: 0.9613 - o5_f1: 0.9607 - o6_f1: 0.9622 - val_loss: 232.3447 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 255/500\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 60.0018 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8699 - o2_f1: 0.9586 - o3_f1: 0.9632 - o4_f1: 0.9654 - o5_f1: 0.9629 - o6_f1: 0.9662 - val_loss: 232.2934 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/500\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9913 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8694 - o2_f1: 0.9560 - o3_f1: 0.9611 - o4_f1: 0.9627 - o5_f1: 0.9617 - o6_f1: 0.9635 - val_loss: 232.3100 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 257/500\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9908 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8675 - o2_f1: 0.9532 - o3_f1: 0.9575 - o4_f1: 0.9596 - o5_f1: 0.9602 - o6_f1: 0.9623 - val_loss: 232.3184 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 258/500\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9889 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8736 - o2_f1: 0.9586 - o3_f1: 0.9621 - o4_f1: 0.9641 - o5_f1: 0.9634 - o6_f1: 0.9664 - val_loss: 232.3076 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 259/500\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9894 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8774 - o2_f1: 0.9605 - o3_f1: 0.9642 - o4_f1: 0.9657 - o5_f1: 0.9639 - o6_f1: 0.9660 - val_loss: 232.2899 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 260/500\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9876 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8666 - o2_f1: 0.9539 - o3_f1: 0.9585 - o4_f1: 0.9607 - o5_f1: 0.9607 - o6_f1: 0.9628 - val_loss: 232.3191 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 261/500\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9840 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8732 - o2_f1: 0.9572 - o3_f1: 0.9612 - o4_f1: 0.9630 - o5_f1: 0.9638 - o6_f1: 0.9659 - val_loss: 232.2887 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 262/500\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9813 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8771 - o2_f1: 0.9580 - o3_f1: 0.9615 - o4_f1: 0.9633 - o5_f1: 0.9634 - o6_f1: 0.9655 - val_loss: 232.2702 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 263/500\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9795 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8778 - o2_f1: 0.9569 - o3_f1: 0.9611 - o4_f1: 0.9631 - o5_f1: 0.9644 - o6_f1: 0.9659 - val_loss: 232.2941 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 264/500\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9761 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8804 - o2_f1: 0.9581 - o3_f1: 0.9616 - o4_f1: 0.9633 - o5_f1: 0.9631 - o6_f1: 0.9652 - val_loss: 232.2974 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 265/500\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9739 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0871 - o1_f1: 0.8676 - o2_f1: 0.9492 - o3_f1: 0.9538 - o4_f1: 0.9555 - o5_f1: 0.9567 - o6_f1: 0.9585 - val_loss: 232.2929 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 266/500\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9708 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0870 - o1_f1: 0.8798 - o2_f1: 0.9580 - o3_f1: 0.9616 - o4_f1: 0.9640 - o5_f1: 0.9643 - o6_f1: 0.9661 - val_loss: 232.2909 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 267/500\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9700 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0934 - o5_loss: 0.0950 - o6_loss: 0.0870 - o1_f1: 0.8753 - o2_f1: 0.9566 - o3_f1: 0.9605 - o4_f1: 0.9626 - o5_f1: 0.9615 - o6_f1: 0.9638 - val_loss: 232.3049 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 268/500\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9666 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8672 - o2_f1: 0.9424 - o3_f1: 0.9467 - o4_f1: 0.9480 - o5_f1: 0.9474 - o6_f1: 0.9516 - val_loss: 232.3044 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 269/500\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9660 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8768 - o2_f1: 0.9561 - o3_f1: 0.9615 - o4_f1: 0.9638 - o5_f1: 0.9642 - o6_f1: 0.9662 - val_loss: 232.2822 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/500\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9643 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8653 - o2_f1: 0.9466 - o3_f1: 0.9508 - o4_f1: 0.9537 - o5_f1: 0.9526 - o6_f1: 0.9549 - val_loss: 232.2628 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 271/500\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9616 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8792 - o2_f1: 0.9555 - o3_f1: 0.9603 - o4_f1: 0.9619 - o5_f1: 0.9625 - o6_f1: 0.9643 - val_loss: 232.2687 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 272/500\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 59.9600 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8761 - o2_f1: 0.9565 - o3_f1: 0.9613 - o4_f1: 0.9633 - o5_f1: 0.9622 - o6_f1: 0.9642 - val_loss: 232.2601 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 273/500\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9603 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8695 - o2_f1: 0.9480 - o3_f1: 0.9547 - o4_f1: 0.9562 - o5_f1: 0.9567 - o6_f1: 0.9580 - val_loss: 232.2340 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3509 - val_o6_loss: 0.3759 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7342 - val_o6_f1: 0.7091\n",
      "Epoch 274/500\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9553 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8756 - o2_f1: 0.9569 - o3_f1: 0.9619 - o4_f1: 0.9636 - o5_f1: 0.9630 - o6_f1: 0.9654 - val_loss: 232.2796 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 275/500\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9590 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8781 - o2_f1: 0.9513 - o3_f1: 0.9568 - o4_f1: 0.9609 - o5_f1: 0.9609 - o6_f1: 0.9629 - val_loss: 232.3487 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 276/500\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9542 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8828 - o2_f1: 0.9582 - o3_f1: 0.9623 - o4_f1: 0.9645 - o5_f1: 0.9653 - o6_f1: 0.9669 - val_loss: 232.3165 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3761 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 277/500\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9487 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8722 - o2_f1: 0.9552 - o3_f1: 0.9595 - o4_f1: 0.9610 - o5_f1: 0.9623 - o6_f1: 0.9642 - val_loss: 232.2925 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 278/500\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9461 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8706 - o2_f1: 0.9556 - o3_f1: 0.9596 - o4_f1: 0.9613 - o5_f1: 0.9606 - o6_f1: 0.9631 - val_loss: 232.2833 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 279/500\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 59.9500 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8749 - o2_f1: 0.9585 - o3_f1: 0.9616 - o4_f1: 0.9636 - o5_f1: 0.9634 - o6_f1: 0.9649 - val_loss: 232.2726 - val_o1_loss: 0.3611 - val_o2_loss: 0.3101 - val_o3_loss: 0.3178 - val_o4_loss: 0.3353 - val_o5_loss: 0.3510 - val_o6_loss: 0.3760 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 280/500\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 59.9436 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8717 - o2_f1: 0.9525 - o3_f1: 0.9564 - o4_f1: 0.9582 - o5_f1: 0.9598 - o6_f1: 0.9625 - val_loss: 232.3550 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3762 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 281/500\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9422 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1056 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8758 - o2_f1: 0.9556 - o3_f1: 0.9595 - o4_f1: 0.9616 - o5_f1: 0.9613 - o6_f1: 0.9639 - val_loss: 232.3820 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3762 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 282/500\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9376 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8813 - o2_f1: 0.9572 - o3_f1: 0.9613 - o4_f1: 0.9627 - o5_f1: 0.9615 - o6_f1: 0.9647 - val_loss: 232.4283 - val_o1_loss: 0.3612 - val_o2_loss: 0.3101 - val_o3_loss: 0.3179 - val_o4_loss: 0.3354 - val_o5_loss: 0.3511 - val_o6_loss: 0.3763 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 283/500\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9384 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8701 - o2_f1: 0.9506 - o3_f1: 0.9552 - o4_f1: 0.9572 - o5_f1: 0.9576 - o6_f1: 0.9597 - val_loss: 232.4656 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3764 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 59.9335 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8766 - o2_f1: 0.9586 - o3_f1: 0.9627 - o4_f1: 0.9647 - o5_f1: 0.9646 - o6_f1: 0.9665 - val_loss: 232.4836 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3764 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 285/500\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9346 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8721 - o2_f1: 0.9563 - o3_f1: 0.9601 - o4_f1: 0.9620 - o5_f1: 0.9624 - o6_f1: 0.9645 - val_loss: 232.5088 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 286/500\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9309 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8834 - o2_f1: 0.9571 - o3_f1: 0.9614 - o4_f1: 0.9629 - o5_f1: 0.9632 - o6_f1: 0.9650 - val_loss: 232.5022 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3764 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 287/500\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9286 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8719 - o2_f1: 0.9537 - o3_f1: 0.9582 - o4_f1: 0.9601 - o5_f1: 0.9605 - o6_f1: 0.9626 - val_loss: 232.5421 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 288/500\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9279 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8809 - o2_f1: 0.9589 - o3_f1: 0.9636 - o4_f1: 0.9661 - o5_f1: 0.9665 - o6_f1: 0.9682 - val_loss: 232.5696 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 289/500\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9347 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8739 - o2_f1: 0.9562 - o3_f1: 0.9604 - o4_f1: 0.9624 - o5_f1: 0.9618 - o6_f1: 0.9645 - val_loss: 232.5264 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 290/500\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9260 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8830 - o2_f1: 0.9570 - o3_f1: 0.9604 - o4_f1: 0.9627 - o5_f1: 0.9617 - o6_f1: 0.9646 - val_loss: 232.5959 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 291/500\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9225 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8785 - o2_f1: 0.9549 - o3_f1: 0.9598 - o4_f1: 0.9615 - o5_f1: 0.9608 - o6_f1: 0.9624 - val_loss: 232.5951 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 292/500\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9218 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8714 - o2_f1: 0.9554 - o3_f1: 0.9599 - o4_f1: 0.9614 - o5_f1: 0.9610 - o6_f1: 0.9639 - val_loss: 232.6083 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 293/500\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9265 - o1_loss: 0.2514 - o2_loss: 0.1241 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8711 - o2_f1: 0.9497 - o3_f1: 0.9538 - o4_f1: 0.9558 - o5_f1: 0.9561 - o6_f1: 0.9579 - val_loss: 232.6484 - val_o1_loss: 0.3612 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 294/500\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 59.9165 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0870 - o1_f1: 0.8760 - o2_f1: 0.9554 - o3_f1: 0.9586 - o4_f1: 0.9615 - o5_f1: 0.9616 - o6_f1: 0.9637 - val_loss: 232.6338 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 295/500\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9138 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8745 - o2_f1: 0.9525 - o3_f1: 0.9558 - o4_f1: 0.9594 - o5_f1: 0.9595 - o6_f1: 0.9614 - val_loss: 232.6510 - val_o1_loss: 0.3612 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 296/500\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9120 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8789 - o2_f1: 0.9563 - o3_f1: 0.9609 - o4_f1: 0.9622 - o5_f1: 0.9619 - o6_f1: 0.9642 - val_loss: 232.6945 - val_o1_loss: 0.3612 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3357 - val_o5_loss: 0.3514 - val_o6_loss: 0.3768 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 297/500\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9131 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8767 - o2_f1: 0.9540 - o3_f1: 0.9572 - o4_f1: 0.9588 - o5_f1: 0.9596 - o6_f1: 0.9616 - val_loss: 232.6954 - val_o1_loss: 0.3612 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3357 - val_o5_loss: 0.3514 - val_o6_loss: 0.3768 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9117 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8776 - o2_f1: 0.9560 - o3_f1: 0.9602 - o4_f1: 0.9619 - o5_f1: 0.9614 - o6_f1: 0.9639 - val_loss: 232.6617 - val_o1_loss: 0.3612 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3768 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 299/500\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 1s - loss: 59.9093 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8806 - o2_f1: 0.9579 - o3_f1: 0.9615 - o4_f1: 0.9631 - o5_f1: 0.9635 - o6_f1: 0.9652 - val_loss: 232.6554 - val_o1_loss: 0.3612 - val_o2_loss: 0.3103 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 300/500\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 2s - loss: 59.9051 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8780 - o2_f1: 0.9583 - o3_f1: 0.9625 - o4_f1: 0.9652 - o5_f1: 0.9650 - o6_f1: 0.9674 - val_loss: 232.6464 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 301/500\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9040 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8703 - o2_f1: 0.9458 - o3_f1: 0.9490 - o4_f1: 0.9507 - o5_f1: 0.9528 - o6_f1: 0.9546 - val_loss: 232.6416 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 302/500\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9040 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8717 - o2_f1: 0.9536 - o3_f1: 0.9585 - o4_f1: 0.9607 - o5_f1: 0.9602 - o6_f1: 0.9629 - val_loss: 232.6327 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 303/500\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9032 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8707 - o2_f1: 0.9476 - o3_f1: 0.9508 - o4_f1: 0.9530 - o5_f1: 0.9537 - o6_f1: 0.9556 - val_loss: 232.6350 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 304/500\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9028 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8792 - o2_f1: 0.9545 - o3_f1: 0.9586 - o4_f1: 0.9603 - o5_f1: 0.9590 - o6_f1: 0.9607 - val_loss: 232.6295 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 305/500\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 2s - loss: 59.9025 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0949 - o6_loss: 0.0869 - o1_f1: 0.8742 - o2_f1: 0.9622 - o3_f1: 0.9656 - o4_f1: 0.9673 - o5_f1: 0.9676 - o6_f1: 0.9699 - val_loss: 232.6403 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 306/500\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9017 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8756 - o2_f1: 0.9595 - o3_f1: 0.9632 - o4_f1: 0.9648 - o5_f1: 0.9657 - o6_f1: 0.9678 - val_loss: 232.6402 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 307/500\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9013 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8848 - o2_f1: 0.9560 - o3_f1: 0.9605 - o4_f1: 0.9629 - o5_f1: 0.9630 - o6_f1: 0.9647 - val_loss: 232.6331 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 308/500\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9007 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8732 - o2_f1: 0.9581 - o3_f1: 0.9614 - o4_f1: 0.9632 - o5_f1: 0.9637 - o6_f1: 0.9660 - val_loss: 232.6250 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3514 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 309/500\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.9004 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8787 - o2_f1: 0.9556 - o3_f1: 0.9595 - o4_f1: 0.9616 - o5_f1: 0.9616 - o6_f1: 0.9634 - val_loss: 232.6163 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 310/500\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8993 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8732 - o2_f1: 0.9512 - o3_f1: 0.9571 - o4_f1: 0.9591 - o5_f1: 0.9595 - o6_f1: 0.9613 - val_loss: 232.6107 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 311/500\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8983 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8802 - o2_f1: 0.9583 - o3_f1: 0.9624 - o4_f1: 0.9645 - o5_f1: 0.9630 - o6_f1: 0.9657 - val_loss: 232.6142 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/500\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8975 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8783 - o2_f1: 0.9558 - o3_f1: 0.9601 - o4_f1: 0.9628 - o5_f1: 0.9633 - o6_f1: 0.9650 - val_loss: 232.6119 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3767 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 313/500\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8972 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0933 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8689 - o2_f1: 0.9494 - o3_f1: 0.9533 - o4_f1: 0.9560 - o5_f1: 0.9559 - o6_f1: 0.9576 - val_loss: 232.6085 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 314/500\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 2s - loss: 59.8967 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8751 - o2_f1: 0.9550 - o3_f1: 0.9584 - o4_f1: 0.9602 - o5_f1: 0.9623 - o6_f1: 0.9644 - val_loss: 232.6003 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 315/500\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8963 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8814 - o2_f1: 0.9568 - o3_f1: 0.9599 - o4_f1: 0.9617 - o5_f1: 0.9628 - o6_f1: 0.9644 - val_loss: 232.5922 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 316/500\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8955 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8725 - o2_f1: 0.9542 - o3_f1: 0.9591 - o4_f1: 0.9607 - o5_f1: 0.9603 - o6_f1: 0.9626 - val_loss: 232.5949 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 317/500\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8946 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8732 - o2_f1: 0.9509 - o3_f1: 0.9561 - o4_f1: 0.9580 - o5_f1: 0.9584 - o6_f1: 0.9605 - val_loss: 232.5960 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 318/500\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8941 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8747 - o2_f1: 0.9515 - o3_f1: 0.9560 - o4_f1: 0.9586 - o5_f1: 0.9596 - o6_f1: 0.9611 - val_loss: 232.5985 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 319/500\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8937 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8796 - o2_f1: 0.9556 - o3_f1: 0.9607 - o4_f1: 0.9629 - o5_f1: 0.9634 - o6_f1: 0.9653 - val_loss: 232.5958 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 320/500\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8932 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8777 - o2_f1: 0.9594 - o3_f1: 0.9627 - o4_f1: 0.9647 - o5_f1: 0.9654 - o6_f1: 0.9674 - val_loss: 232.5885 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 321/500\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8923 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8776 - o2_f1: 0.9564 - o3_f1: 0.9602 - o4_f1: 0.9623 - o5_f1: 0.9623 - o6_f1: 0.9641 - val_loss: 232.5901 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 322/500\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8920 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8755 - o2_f1: 0.9575 - o3_f1: 0.9608 - o4_f1: 0.9631 - o5_f1: 0.9632 - o6_f1: 0.9657 - val_loss: 232.5912 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 323/500\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8914 - o1_loss: 0.2514 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8837 - o2_f1: 0.9563 - o3_f1: 0.9603 - o4_f1: 0.9620 - o5_f1: 0.9638 - o6_f1: 0.9657 - val_loss: 232.5882 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 324/500\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8907 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8794 - o2_f1: 0.9572 - o3_f1: 0.9615 - o4_f1: 0.9631 - o5_f1: 0.9646 - o6_f1: 0.9666 - val_loss: 232.5927 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 325/500\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8905 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8702 - o2_f1: 0.9532 - o3_f1: 0.9588 - o4_f1: 0.9609 - o5_f1: 0.9618 - o6_f1: 0.9635 - val_loss: 232.5964 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/500\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8898 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8625 - o2_f1: 0.9552 - o3_f1: 0.9587 - o4_f1: 0.9611 - o5_f1: 0.9579 - o6_f1: 0.9615 - val_loss: 232.5972 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 327/500\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8891 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8751 - o2_f1: 0.9567 - o3_f1: 0.9605 - o4_f1: 0.9626 - o5_f1: 0.9616 - o6_f1: 0.9646 - val_loss: 232.5954 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 328/500\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8890 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8771 - o2_f1: 0.9553 - o3_f1: 0.9588 - o4_f1: 0.9605 - o5_f1: 0.9619 - o6_f1: 0.9642 - val_loss: 232.5948 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 329/500\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8879 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8817 - o2_f1: 0.9572 - o3_f1: 0.9611 - o4_f1: 0.9633 - o5_f1: 0.9641 - o6_f1: 0.9658 - val_loss: 232.5904 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 330/500\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8873 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8742 - o2_f1: 0.9565 - o3_f1: 0.9605 - o4_f1: 0.9619 - o5_f1: 0.9624 - o6_f1: 0.9643 - val_loss: 232.5856 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 331/500\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8864 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8661 - o2_f1: 0.9515 - o3_f1: 0.9555 - o4_f1: 0.9584 - o5_f1: 0.9591 - o6_f1: 0.9613 - val_loss: 232.5749 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 332/500\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8864 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8777 - o2_f1: 0.9546 - o3_f1: 0.9589 - o4_f1: 0.9614 - o5_f1: 0.9614 - o6_f1: 0.9631 - val_loss: 232.5737 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 333/500\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8868 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8756 - o2_f1: 0.9541 - o3_f1: 0.9583 - o4_f1: 0.9606 - o5_f1: 0.9608 - o6_f1: 0.9625 - val_loss: 232.5806 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 334/500\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8860 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8705 - o2_f1: 0.9546 - o3_f1: 0.9579 - o4_f1: 0.9600 - o5_f1: 0.9607 - o6_f1: 0.9626 - val_loss: 232.5808 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 335/500\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8845 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8733 - o2_f1: 0.9562 - o3_f1: 0.9598 - o4_f1: 0.9617 - o5_f1: 0.9617 - o6_f1: 0.9643 - val_loss: 232.5729 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 336/500\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8838 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8759 - o2_f1: 0.9579 - o3_f1: 0.9616 - o4_f1: 0.9633 - o5_f1: 0.9635 - o6_f1: 0.9648 - val_loss: 232.5706 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 337/500\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8837 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8717 - o2_f1: 0.9484 - o3_f1: 0.9529 - o4_f1: 0.9545 - o5_f1: 0.9549 - o6_f1: 0.9563 - val_loss: 232.5747 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3356 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 338/500\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8828 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8709 - o2_f1: 0.9487 - o3_f1: 0.9527 - o4_f1: 0.9548 - o5_f1: 0.9547 - o6_f1: 0.9566 - val_loss: 232.5669 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3766 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7091 - val_o6_f1: 0.7091\n",
      "Epoch 339/500\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8827 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8679 - o2_f1: 0.9492 - o3_f1: 0.9539 - o4_f1: 0.9555 - o5_f1: 0.9560 - o6_f1: 0.9582 - val_loss: 232.5558 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/500\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8811 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8748 - o2_f1: 0.9555 - o3_f1: 0.9595 - o4_f1: 0.9616 - o5_f1: 0.9624 - o6_f1: 0.9645 - val_loss: 232.5499 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 341/500\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8807 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8759 - o2_f1: 0.9543 - o3_f1: 0.9584 - o4_f1: 0.9598 - o5_f1: 0.9613 - o6_f1: 0.9629 - val_loss: 232.5447 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 342/500\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8802 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8752 - o2_f1: 0.9527 - o3_f1: 0.9569 - o4_f1: 0.9596 - o5_f1: 0.9621 - o6_f1: 0.9638 - val_loss: 232.5464 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 343/500\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8798 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8652 - o2_f1: 0.9467 - o3_f1: 0.9522 - o4_f1: 0.9552 - o5_f1: 0.9554 - o6_f1: 0.9573 - val_loss: 232.5540 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 344/500\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8791 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8751 - o2_f1: 0.9568 - o3_f1: 0.9610 - o4_f1: 0.9628 - o5_f1: 0.9630 - o6_f1: 0.9657 - val_loss: 232.5508 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 345/500\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8787 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8795 - o2_f1: 0.9567 - o3_f1: 0.9610 - o4_f1: 0.9632 - o5_f1: 0.9632 - o6_f1: 0.9655 - val_loss: 232.5485 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 346/500\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8783 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8752 - o2_f1: 0.9576 - o3_f1: 0.9615 - o4_f1: 0.9647 - o5_f1: 0.9651 - o6_f1: 0.9665 - val_loss: 232.5443 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 347/500\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8776 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8765 - o2_f1: 0.9539 - o3_f1: 0.9581 - o4_f1: 0.9614 - o5_f1: 0.9609 - o6_f1: 0.9627 - val_loss: 232.5421 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 348/500\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8767 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8809 - o2_f1: 0.9558 - o3_f1: 0.9591 - o4_f1: 0.9615 - o5_f1: 0.9626 - o6_f1: 0.9649 - val_loss: 232.5553 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 349/500\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 1s - loss: 59.8761 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8733 - o2_f1: 0.9520 - o3_f1: 0.9562 - o4_f1: 0.9587 - o5_f1: 0.9583 - o6_f1: 0.9608 - val_loss: 232.5435 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 350/500\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8757 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8814 - o2_f1: 0.9564 - o3_f1: 0.9616 - o4_f1: 0.9635 - o5_f1: 0.9636 - o6_f1: 0.9659 - val_loss: 232.5420 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 351/500\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8758 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8738 - o2_f1: 0.9518 - o3_f1: 0.9553 - o4_f1: 0.9573 - o5_f1: 0.9645 - o6_f1: 0.9663 - val_loss: 232.5408 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 352/500\n",
      "\n",
      "Epoch 00352: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8757 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8654 - o2_f1: 0.9527 - o3_f1: 0.9562 - o4_f1: 0.9602 - o5_f1: 0.9593 - o6_f1: 0.9613 - val_loss: 232.5406 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 353/500\n",
      "\n",
      "Epoch 00353: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8755 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8766 - o2_f1: 0.9566 - o3_f1: 0.9601 - o4_f1: 0.9626 - o5_f1: 0.9628 - o6_f1: 0.9648 - val_loss: 232.5417 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500\n",
      "\n",
      "Epoch 00354: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8754 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8803 - o2_f1: 0.9613 - o3_f1: 0.9643 - o4_f1: 0.9657 - o5_f1: 0.9640 - o6_f1: 0.9664 - val_loss: 232.5413 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 355/500\n",
      "\n",
      "Epoch 00355: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8754 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8758 - o2_f1: 0.9558 - o3_f1: 0.9591 - o4_f1: 0.9616 - o5_f1: 0.9608 - o6_f1: 0.9636 - val_loss: 232.5408 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 356/500\n",
      "\n",
      "Epoch 00356: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8752 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8758 - o2_f1: 0.9541 - o3_f1: 0.9585 - o4_f1: 0.9600 - o5_f1: 0.9607 - o6_f1: 0.9625 - val_loss: 232.5426 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 357/500\n",
      "\n",
      "Epoch 00357: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8751 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8783 - o2_f1: 0.9583 - o3_f1: 0.9629 - o4_f1: 0.9647 - o5_f1: 0.9648 - o6_f1: 0.9664 - val_loss: 232.5417 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 358/500\n",
      "\n",
      "Epoch 00358: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8750 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8771 - o2_f1: 0.9561 - o3_f1: 0.9605 - o4_f1: 0.9622 - o5_f1: 0.9623 - o6_f1: 0.9641 - val_loss: 232.5416 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 359/500\n",
      "\n",
      "Epoch 00359: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8750 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8716 - o2_f1: 0.9537 - o3_f1: 0.9591 - o4_f1: 0.9610 - o5_f1: 0.9619 - o6_f1: 0.9636 - val_loss: 232.5404 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 360/500\n",
      "\n",
      "Epoch 00360: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8751 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8778 - o2_f1: 0.9574 - o3_f1: 0.9608 - o4_f1: 0.9631 - o5_f1: 0.9628 - o6_f1: 0.9646 - val_loss: 232.5429 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 361/500\n",
      "\n",
      "Epoch 00361: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8747 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8763 - o2_f1: 0.9538 - o3_f1: 0.9579 - o4_f1: 0.9612 - o5_f1: 0.9611 - o6_f1: 0.9634 - val_loss: 232.5407 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 362/500\n",
      "\n",
      "Epoch 00362: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8746 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8784 - o2_f1: 0.9524 - o3_f1: 0.9583 - o4_f1: 0.9599 - o5_f1: 0.9609 - o6_f1: 0.9641 - val_loss: 232.5393 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 363/500\n",
      "\n",
      "Epoch 00363: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8744 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8765 - o2_f1: 0.9588 - o3_f1: 0.9627 - o4_f1: 0.9649 - o5_f1: 0.9652 - o6_f1: 0.9669 - val_loss: 232.5347 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3180 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 364/500\n",
      "\n",
      "Epoch 00364: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8744 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8700 - o2_f1: 0.9554 - o3_f1: 0.9597 - o4_f1: 0.9618 - o5_f1: 0.9611 - o6_f1: 0.9628 - val_loss: 232.5329 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 365/500\n",
      "\n",
      "Epoch 00365: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8742 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8819 - o2_f1: 0.9550 - o3_f1: 0.9585 - o4_f1: 0.9602 - o5_f1: 0.9607 - o6_f1: 0.9621 - val_loss: 232.5312 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 366/500\n",
      "\n",
      "Epoch 00366: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8743 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8812 - o2_f1: 0.9583 - o3_f1: 0.9621 - o4_f1: 0.9641 - o5_f1: 0.9644 - o6_f1: 0.9669 - val_loss: 232.5322 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 367/500\n",
      "\n",
      "Epoch 00367: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8740 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8806 - o2_f1: 0.9565 - o3_f1: 0.9602 - o4_f1: 0.9626 - o5_f1: 0.9630 - o6_f1: 0.9651 - val_loss: 232.5307 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/500\n",
      "\n",
      "Epoch 00368: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8739 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8767 - o2_f1: 0.9582 - o3_f1: 0.9618 - o4_f1: 0.9636 - o5_f1: 0.9644 - o6_f1: 0.9662 - val_loss: 232.5271 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 369/500\n",
      "\n",
      "Epoch 00369: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8737 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8738 - o2_f1: 0.9566 - o3_f1: 0.9608 - o4_f1: 0.9631 - o5_f1: 0.9639 - o6_f1: 0.9656 - val_loss: 232.5255 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3513 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 370/500\n",
      "\n",
      "Epoch 00370: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8736 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8775 - o2_f1: 0.9573 - o3_f1: 0.9609 - o4_f1: 0.9632 - o5_f1: 0.9641 - o6_f1: 0.9657 - val_loss: 232.5238 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 371/500\n",
      "\n",
      "Epoch 00371: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8735 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8777 - o2_f1: 0.9563 - o3_f1: 0.9611 - o4_f1: 0.9625 - o5_f1: 0.9635 - o6_f1: 0.9656 - val_loss: 232.5230 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 372/500\n",
      "\n",
      "Epoch 00372: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8736 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8783 - o2_f1: 0.9574 - o3_f1: 0.9607 - o4_f1: 0.9624 - o5_f1: 0.9622 - o6_f1: 0.9645 - val_loss: 232.5215 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 373/500\n",
      "\n",
      "Epoch 00373: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8733 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8695 - o2_f1: 0.9561 - o3_f1: 0.9601 - o4_f1: 0.9619 - o5_f1: 0.9604 - o6_f1: 0.9636 - val_loss: 232.5225 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 374/500\n",
      "\n",
      "Epoch 00374: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8734 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8736 - o2_f1: 0.9512 - o3_f1: 0.9558 - o4_f1: 0.9582 - o5_f1: 0.9578 - o6_f1: 0.9610 - val_loss: 232.5206 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 375/500\n",
      "\n",
      "Epoch 00375: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 2s - loss: 59.8731 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8739 - o2_f1: 0.9541 - o3_f1: 0.9579 - o4_f1: 0.9599 - o5_f1: 0.9589 - o6_f1: 0.9616 - val_loss: 232.5195 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 376/500\n",
      "\n",
      "Epoch 00376: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8731 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8752 - o2_f1: 0.9565 - o3_f1: 0.9608 - o4_f1: 0.9629 - o5_f1: 0.9629 - o6_f1: 0.9648 - val_loss: 232.5200 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 377/500\n",
      "\n",
      "Epoch 00377: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8730 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8790 - o2_f1: 0.9568 - o3_f1: 0.9604 - o4_f1: 0.9624 - o5_f1: 0.9637 - o6_f1: 0.9653 - val_loss: 232.5175 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 378/500\n",
      "\n",
      "Epoch 00378: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8728 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8725 - o2_f1: 0.9559 - o3_f1: 0.9603 - o4_f1: 0.9636 - o5_f1: 0.9622 - o6_f1: 0.9655 - val_loss: 232.5177 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 379/500\n",
      "\n",
      "Epoch 00379: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8728 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8728 - o2_f1: 0.9491 - o3_f1: 0.9536 - o4_f1: 0.9556 - o5_f1: 0.9583 - o6_f1: 0.9600 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 380/500\n",
      "\n",
      "Epoch 00380: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8727 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8719 - o2_f1: 0.9486 - o3_f1: 0.9529 - o4_f1: 0.9544 - o5_f1: 0.9553 - o6_f1: 0.9577 - val_loss: 232.5161 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 381/500\n",
      "\n",
      "Epoch 00381: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8727 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8769 - o2_f1: 0.9565 - o3_f1: 0.9602 - o4_f1: 0.9627 - o5_f1: 0.9619 - o6_f1: 0.9646 - val_loss: 232.5194 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/500\n",
      "\n",
      "Epoch 00382: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8726 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8757 - o2_f1: 0.9579 - o3_f1: 0.9617 - o4_f1: 0.9639 - o5_f1: 0.9626 - o6_f1: 0.9655 - val_loss: 232.5186 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 383/500\n",
      "\n",
      "Epoch 00383: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8724 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8731 - o2_f1: 0.9573 - o3_f1: 0.9619 - o4_f1: 0.9640 - o5_f1: 0.9644 - o6_f1: 0.9664 - val_loss: 232.5179 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 384/500\n",
      "\n",
      "Epoch 00384: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8723 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8745 - o2_f1: 0.9537 - o3_f1: 0.9575 - o4_f1: 0.9597 - o5_f1: 0.9599 - o6_f1: 0.9622 - val_loss: 232.5177 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 385/500\n",
      "\n",
      "Epoch 00385: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8722 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8748 - o2_f1: 0.9548 - o3_f1: 0.9598 - o4_f1: 0.9619 - o5_f1: 0.9644 - o6_f1: 0.9662 - val_loss: 232.5173 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 386/500\n",
      "\n",
      "Epoch 00386: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8721 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8763 - o2_f1: 0.9569 - o3_f1: 0.9612 - o4_f1: 0.9630 - o5_f1: 0.9632 - o6_f1: 0.9657 - val_loss: 232.5216 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 387/500\n",
      "\n",
      "Epoch 00387: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 2s - loss: 59.8721 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8678 - o2_f1: 0.9478 - o3_f1: 0.9516 - o4_f1: 0.9533 - o5_f1: 0.9517 - o6_f1: 0.9553 - val_loss: 232.5224 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 388/500\n",
      "\n",
      "Epoch 00388: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8719 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8806 - o2_f1: 0.9561 - o3_f1: 0.9599 - o4_f1: 0.9624 - o5_f1: 0.9638 - o6_f1: 0.9654 - val_loss: 232.5217 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 389/500\n",
      "\n",
      "Epoch 00389: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8718 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8729 - o2_f1: 0.9522 - o3_f1: 0.9555 - o4_f1: 0.9574 - o5_f1: 0.9572 - o6_f1: 0.9588 - val_loss: 232.5209 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 390/500\n",
      "\n",
      "Epoch 00390: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8718 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8749 - o2_f1: 0.9582 - o3_f1: 0.9625 - o4_f1: 0.9642 - o5_f1: 0.9637 - o6_f1: 0.9660 - val_loss: 232.5212 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 391/500\n",
      "\n",
      "Epoch 00391: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8716 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8606 - o2_f1: 0.9432 - o3_f1: 0.9474 - o4_f1: 0.9497 - o5_f1: 0.9499 - o6_f1: 0.9517 - val_loss: 232.5202 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 392/500\n",
      "\n",
      "Epoch 00392: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8716 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8739 - o2_f1: 0.9565 - o3_f1: 0.9617 - o4_f1: 0.9640 - o5_f1: 0.9649 - o6_f1: 0.9667 - val_loss: 232.5185 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 393/500\n",
      "\n",
      "Epoch 00393: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8715 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8803 - o2_f1: 0.9563 - o3_f1: 0.9614 - o4_f1: 0.9634 - o5_f1: 0.9631 - o6_f1: 0.9649 - val_loss: 232.5197 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 394/500\n",
      "\n",
      "Epoch 00394: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8713 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8752 - o2_f1: 0.9549 - o3_f1: 0.9591 - o4_f1: 0.9618 - o5_f1: 0.9628 - o6_f1: 0.9643 - val_loss: 232.5227 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 395/500\n",
      "\n",
      "Epoch 00395: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8715 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8763 - o2_f1: 0.9551 - o3_f1: 0.9607 - o4_f1: 0.9625 - o5_f1: 0.9620 - o6_f1: 0.9644 - val_loss: 232.5210 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "\n",
      "Epoch 00396: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8713 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8832 - o2_f1: 0.9586 - o3_f1: 0.9623 - o4_f1: 0.9641 - o5_f1: 0.9624 - o6_f1: 0.9649 - val_loss: 232.5212 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 397/500\n",
      "\n",
      "Epoch 00397: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8711 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8685 - o2_f1: 0.9467 - o3_f1: 0.9506 - o4_f1: 0.9530 - o5_f1: 0.9540 - o6_f1: 0.9559 - val_loss: 232.5220 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 398/500\n",
      "\n",
      "Epoch 00398: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8710 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8817 - o2_f1: 0.9584 - o3_f1: 0.9621 - o4_f1: 0.9648 - o5_f1: 0.9654 - o6_f1: 0.9674 - val_loss: 232.5196 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 399/500\n",
      "\n",
      "Epoch 00399: LearningRateScheduler setting learning rate to 6.103515625e-08.\n",
      " - 1s - loss: 59.8711 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8704 - o2_f1: 0.9465 - o3_f1: 0.9522 - o4_f1: 0.9539 - o5_f1: 0.9557 - o6_f1: 0.9573 - val_loss: 232.5217 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 400/500\n",
      "\n",
      "Epoch 00400: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8769 - o2_f1: 0.9576 - o3_f1: 0.9624 - o4_f1: 0.9640 - o5_f1: 0.9638 - o6_f1: 0.9658 - val_loss: 232.5217 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 401/500\n",
      "\n",
      "Epoch 00401: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8749 - o2_f1: 0.9552 - o3_f1: 0.9612 - o4_f1: 0.9634 - o5_f1: 0.9653 - o6_f1: 0.9666 - val_loss: 232.5218 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 402/500\n",
      "\n",
      "Epoch 00402: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8752 - o2_f1: 0.9558 - o3_f1: 0.9614 - o4_f1: 0.9631 - o5_f1: 0.9628 - o6_f1: 0.9646 - val_loss: 232.5218 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 403/500\n",
      "\n",
      "Epoch 00403: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8709 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8738 - o2_f1: 0.9546 - o3_f1: 0.9590 - o4_f1: 0.9615 - o5_f1: 0.9609 - o6_f1: 0.9623 - val_loss: 232.5214 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 404/500\n",
      "\n",
      "Epoch 00404: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8756 - o2_f1: 0.9570 - o3_f1: 0.9605 - o4_f1: 0.9627 - o5_f1: 0.9629 - o6_f1: 0.9655 - val_loss: 232.5217 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 405/500\n",
      "\n",
      "Epoch 00405: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8688 - o2_f1: 0.9521 - o3_f1: 0.9573 - o4_f1: 0.9594 - o5_f1: 0.9608 - o6_f1: 0.9629 - val_loss: 232.5217 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 406/500\n",
      "\n",
      "Epoch 00406: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8676 - o2_f1: 0.9497 - o3_f1: 0.9538 - o4_f1: 0.9557 - o5_f1: 0.9550 - o6_f1: 0.9571 - val_loss: 232.5209 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 407/500\n",
      "\n",
      "Epoch 00407: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8782 - o2_f1: 0.9591 - o3_f1: 0.9626 - o4_f1: 0.9644 - o5_f1: 0.9639 - o6_f1: 0.9657 - val_loss: 232.5204 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 408/500\n",
      "\n",
      "Epoch 00408: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8721 - o2_f1: 0.9529 - o3_f1: 0.9571 - o4_f1: 0.9591 - o5_f1: 0.9590 - o6_f1: 0.9619 - val_loss: 232.5200 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 409/500\n",
      "\n",
      "Epoch 00409: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8717 - o2_f1: 0.9509 - o3_f1: 0.9555 - o4_f1: 0.9582 - o5_f1: 0.9583 - o6_f1: 0.9608 - val_loss: 232.5187 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/500\n",
      "\n",
      "Epoch 00410: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8755 - o2_f1: 0.9579 - o3_f1: 0.9621 - o4_f1: 0.9640 - o5_f1: 0.9631 - o6_f1: 0.9649 - val_loss: 232.5183 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 411/500\n",
      "\n",
      "Epoch 00411: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8775 - o2_f1: 0.9556 - o3_f1: 0.9599 - o4_f1: 0.9612 - o5_f1: 0.9599 - o6_f1: 0.9628 - val_loss: 232.5182 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 412/500\n",
      "\n",
      "Epoch 00412: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8773 - o2_f1: 0.9568 - o3_f1: 0.9607 - o4_f1: 0.9648 - o5_f1: 0.9641 - o6_f1: 0.9664 - val_loss: 232.5183 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 413/500\n",
      "\n",
      "Epoch 00413: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8765 - o2_f1: 0.9575 - o3_f1: 0.9614 - o4_f1: 0.9627 - o5_f1: 0.9617 - o6_f1: 0.9646 - val_loss: 232.5182 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 414/500\n",
      "\n",
      "Epoch 00414: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8688 - o2_f1: 0.9473 - o3_f1: 0.9524 - o4_f1: 0.9541 - o5_f1: 0.9548 - o6_f1: 0.9569 - val_loss: 232.5181 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 415/500\n",
      "\n",
      "Epoch 00415: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8742 - o2_f1: 0.9555 - o3_f1: 0.9587 - o4_f1: 0.9620 - o5_f1: 0.9636 - o6_f1: 0.9653 - val_loss: 232.5180 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 416/500\n",
      "\n",
      "Epoch 00416: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8668 - o2_f1: 0.9551 - o3_f1: 0.9592 - o4_f1: 0.9608 - o5_f1: 0.9611 - o6_f1: 0.9627 - val_loss: 232.5176 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 417/500\n",
      "\n",
      "Epoch 00417: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8759 - o2_f1: 0.9559 - o3_f1: 0.9600 - o4_f1: 0.9627 - o5_f1: 0.9620 - o6_f1: 0.9647 - val_loss: 232.5177 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 418/500\n",
      "\n",
      "Epoch 00418: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8765 - o2_f1: 0.9565 - o3_f1: 0.9605 - o4_f1: 0.9625 - o5_f1: 0.9628 - o6_f1: 0.9649 - val_loss: 232.5175 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 419/500\n",
      "\n",
      "Epoch 00419: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8708 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8766 - o2_f1: 0.9584 - o3_f1: 0.9627 - o4_f1: 0.9644 - o5_f1: 0.9647 - o6_f1: 0.9670 - val_loss: 232.5186 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 420/500\n",
      "\n",
      "Epoch 00420: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8745 - o2_f1: 0.9580 - o3_f1: 0.9611 - o4_f1: 0.9640 - o5_f1: 0.9635 - o6_f1: 0.9660 - val_loss: 232.5181 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 421/500\n",
      "\n",
      "Epoch 00421: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8760 - o2_f1: 0.9573 - o3_f1: 0.9612 - o4_f1: 0.9639 - o5_f1: 0.9640 - o6_f1: 0.9657 - val_loss: 232.5180 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 422/500\n",
      "\n",
      "Epoch 00422: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8732 - o2_f1: 0.9538 - o3_f1: 0.9595 - o4_f1: 0.9618 - o5_f1: 0.9615 - o6_f1: 0.9635 - val_loss: 232.5175 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 423/500\n",
      "\n",
      "Epoch 00423: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8716 - o2_f1: 0.9532 - o3_f1: 0.9591 - o4_f1: 0.9616 - o5_f1: 0.9612 - o6_f1: 0.9627 - val_loss: 232.5176 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/500\n",
      "\n",
      "Epoch 00424: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8768 - o2_f1: 0.9559 - o3_f1: 0.9598 - o4_f1: 0.9621 - o5_f1: 0.9613 - o6_f1: 0.9632 - val_loss: 232.5174 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 425/500\n",
      "\n",
      "Epoch 00425: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8763 - o2_f1: 0.9582 - o3_f1: 0.9626 - o4_f1: 0.9644 - o5_f1: 0.9633 - o6_f1: 0.9653 - val_loss: 232.5165 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 426/500\n",
      "\n",
      "Epoch 00426: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8786 - o2_f1: 0.9576 - o3_f1: 0.9615 - o4_f1: 0.9640 - o5_f1: 0.9633 - o6_f1: 0.9660 - val_loss: 232.5166 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 427/500\n",
      "\n",
      "Epoch 00427: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8785 - o2_f1: 0.9551 - o3_f1: 0.9594 - o4_f1: 0.9616 - o5_f1: 0.9620 - o6_f1: 0.9636 - val_loss: 232.5165 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 428/500\n",
      "\n",
      "Epoch 00428: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8749 - o2_f1: 0.9564 - o3_f1: 0.9604 - o4_f1: 0.9627 - o5_f1: 0.9633 - o6_f1: 0.9650 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 429/500\n",
      "\n",
      "Epoch 00429: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8821 - o2_f1: 0.9565 - o3_f1: 0.9604 - o4_f1: 0.9621 - o5_f1: 0.9607 - o6_f1: 0.9629 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 430/500\n",
      "\n",
      "Epoch 00430: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8750 - o2_f1: 0.9552 - o3_f1: 0.9598 - o4_f1: 0.9623 - o5_f1: 0.9621 - o6_f1: 0.9641 - val_loss: 232.5167 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 431/500\n",
      "\n",
      "Epoch 00431: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8718 - o2_f1: 0.9477 - o3_f1: 0.9534 - o4_f1: 0.9558 - o5_f1: 0.9555 - o6_f1: 0.9575 - val_loss: 232.5172 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 432/500\n",
      "\n",
      "Epoch 00432: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8815 - o2_f1: 0.9599 - o3_f1: 0.9642 - o4_f1: 0.9658 - o5_f1: 0.9650 - o6_f1: 0.9673 - val_loss: 232.5176 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 433/500\n",
      "\n",
      "Epoch 00433: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 2s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8695 - o2_f1: 0.9573 - o3_f1: 0.9611 - o4_f1: 0.9632 - o5_f1: 0.9629 - o6_f1: 0.9652 - val_loss: 232.5182 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 434/500\n",
      "\n",
      "Epoch 00434: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8729 - o2_f1: 0.9563 - o3_f1: 0.9606 - o4_f1: 0.9631 - o5_f1: 0.9621 - o6_f1: 0.9645 - val_loss: 232.5181 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 435/500\n",
      "\n",
      "Epoch 00435: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 2s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8725 - o2_f1: 0.9566 - o3_f1: 0.9616 - o4_f1: 0.9646 - o5_f1: 0.9649 - o6_f1: 0.9672 - val_loss: 232.5180 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 436/500\n",
      "\n",
      "Epoch 00436: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 2s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8699 - o2_f1: 0.9567 - o3_f1: 0.9612 - o4_f1: 0.9630 - o5_f1: 0.9643 - o6_f1: 0.9661 - val_loss: 232.5180 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 437/500\n",
      "\n",
      "Epoch 00437: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8815 - o2_f1: 0.9565 - o3_f1: 0.9607 - o4_f1: 0.9624 - o5_f1: 0.9627 - o6_f1: 0.9650 - val_loss: 232.5180 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/500\n",
      "\n",
      "Epoch 00438: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8773 - o2_f1: 0.9572 - o3_f1: 0.9613 - o4_f1: 0.9636 - o5_f1: 0.9633 - o6_f1: 0.9655 - val_loss: 232.5178 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 439/500\n",
      "\n",
      "Epoch 00439: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8818 - o2_f1: 0.9573 - o3_f1: 0.9602 - o4_f1: 0.9625 - o5_f1: 0.9625 - o6_f1: 0.9650 - val_loss: 232.5174 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 440/500\n",
      "\n",
      "Epoch 00440: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8693 - o2_f1: 0.9487 - o3_f1: 0.9535 - o4_f1: 0.9560 - o5_f1: 0.9568 - o6_f1: 0.9584 - val_loss: 232.5177 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 441/500\n",
      "\n",
      "Epoch 00441: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8710 - o2_f1: 0.9514 - o3_f1: 0.9568 - o4_f1: 0.9587 - o5_f1: 0.9577 - o6_f1: 0.9603 - val_loss: 232.5181 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 442/500\n",
      "\n",
      "Epoch 00442: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8736 - o2_f1: 0.9556 - o3_f1: 0.9605 - o4_f1: 0.9625 - o5_f1: 0.9629 - o6_f1: 0.9644 - val_loss: 232.5180 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 443/500\n",
      "\n",
      "Epoch 00443: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8759 - o2_f1: 0.9507 - o3_f1: 0.9541 - o4_f1: 0.9559 - o5_f1: 0.9556 - o6_f1: 0.9574 - val_loss: 232.5176 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 444/500\n",
      "\n",
      "Epoch 00444: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8804 - o2_f1: 0.9583 - o3_f1: 0.9618 - o4_f1: 0.9631 - o5_f1: 0.9624 - o6_f1: 0.9642 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 445/500\n",
      "\n",
      "Epoch 00445: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8707 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8745 - o2_f1: 0.9566 - o3_f1: 0.9612 - o4_f1: 0.9641 - o5_f1: 0.9640 - o6_f1: 0.9661 - val_loss: 232.5158 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 446/500\n",
      "\n",
      "Epoch 00446: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8757 - o2_f1: 0.9536 - o3_f1: 0.9573 - o4_f1: 0.9592 - o5_f1: 0.9604 - o6_f1: 0.9624 - val_loss: 232.5165 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 447/500\n",
      "\n",
      "Epoch 00447: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8789 - o2_f1: 0.9571 - o3_f1: 0.9615 - o4_f1: 0.9634 - o5_f1: 0.9633 - o6_f1: 0.9657 - val_loss: 232.5164 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 448/500\n",
      "\n",
      "Epoch 00448: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8755 - o2_f1: 0.9535 - o3_f1: 0.9572 - o4_f1: 0.9595 - o5_f1: 0.9597 - o6_f1: 0.9610 - val_loss: 232.5165 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 449/500\n",
      "\n",
      "Epoch 00449: LearningRateScheduler setting learning rate to 1.52587890625e-08.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8716 - o2_f1: 0.9538 - o3_f1: 0.9573 - o4_f1: 0.9589 - o5_f1: 0.9585 - o6_f1: 0.9602 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 450/500\n",
      "\n",
      "Epoch 00450: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 2s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8814 - o2_f1: 0.9591 - o3_f1: 0.9628 - o4_f1: 0.9646 - o5_f1: 0.9648 - o6_f1: 0.9666 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 451/500\n",
      "\n",
      "Epoch 00451: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8699 - o2_f1: 0.9576 - o3_f1: 0.9628 - o4_f1: 0.9652 - o5_f1: 0.9652 - o6_f1: 0.9677 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/500\n",
      "\n",
      "Epoch 00452: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8725 - o2_f1: 0.9571 - o3_f1: 0.9618 - o4_f1: 0.9632 - o5_f1: 0.9637 - o6_f1: 0.9653 - val_loss: 232.5172 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 453/500\n",
      "\n",
      "Epoch 00453: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8762 - o2_f1: 0.9570 - o3_f1: 0.9610 - o4_f1: 0.9631 - o5_f1: 0.9627 - o6_f1: 0.9650 - val_loss: 232.5172 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 454/500\n",
      "\n",
      "Epoch 00454: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8719 - o2_f1: 0.9531 - o3_f1: 0.9566 - o4_f1: 0.9592 - o5_f1: 0.9578 - o6_f1: 0.9607 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 455/500\n",
      "\n",
      "Epoch 00455: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8612 - o2_f1: 0.9517 - o3_f1: 0.9575 - o4_f1: 0.9595 - o5_f1: 0.9588 - o6_f1: 0.9608 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 456/500\n",
      "\n",
      "Epoch 00456: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8823 - o2_f1: 0.9563 - o3_f1: 0.9606 - o4_f1: 0.9623 - o5_f1: 0.9625 - o6_f1: 0.9642 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 457/500\n",
      "\n",
      "Epoch 00457: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 2s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8777 - o2_f1: 0.9507 - o3_f1: 0.9610 - o4_f1: 0.9631 - o5_f1: 0.9646 - o6_f1: 0.9663 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 458/500\n",
      "\n",
      "Epoch 00458: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8715 - o2_f1: 0.9565 - o3_f1: 0.9608 - o4_f1: 0.9632 - o5_f1: 0.9624 - o6_f1: 0.9653 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 459/500\n",
      "\n",
      "Epoch 00459: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8770 - o2_f1: 0.9558 - o3_f1: 0.9604 - o4_f1: 0.9621 - o5_f1: 0.9626 - o6_f1: 0.9645 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 460/500\n",
      "\n",
      "Epoch 00460: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8771 - o2_f1: 0.9562 - o3_f1: 0.9609 - o4_f1: 0.9622 - o5_f1: 0.9620 - o6_f1: 0.9645 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 461/500\n",
      "\n",
      "Epoch 00461: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8799 - o2_f1: 0.9579 - o3_f1: 0.9618 - o4_f1: 0.9636 - o5_f1: 0.9632 - o6_f1: 0.9653 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 462/500\n",
      "\n",
      "Epoch 00462: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8795 - o2_f1: 0.9558 - o3_f1: 0.9596 - o4_f1: 0.9618 - o5_f1: 0.9630 - o6_f1: 0.9653 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 463/500\n",
      "\n",
      "Epoch 00463: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8710 - o2_f1: 0.9561 - o3_f1: 0.9610 - o4_f1: 0.9624 - o5_f1: 0.9620 - o6_f1: 0.9635 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 464/500\n",
      "\n",
      "Epoch 00464: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8763 - o2_f1: 0.9558 - o3_f1: 0.9597 - o4_f1: 0.9612 - o5_f1: 0.9619 - o6_f1: 0.9641 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 465/500\n",
      "\n",
      "Epoch 00465: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8726 - o2_f1: 0.9448 - o3_f1: 0.9486 - o4_f1: 0.9501 - o5_f1: 0.9508 - o6_f1: 0.9523 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "\n",
      "Epoch 00466: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8737 - o2_f1: 0.9555 - o3_f1: 0.9602 - o4_f1: 0.9621 - o5_f1: 0.9624 - o6_f1: 0.9651 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 467/500\n",
      "\n",
      "Epoch 00467: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8741 - o2_f1: 0.9559 - o3_f1: 0.9604 - o4_f1: 0.9624 - o5_f1: 0.9636 - o6_f1: 0.9653 - val_loss: 232.5173 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 468/500\n",
      "\n",
      "Epoch 00468: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8735 - o2_f1: 0.9559 - o3_f1: 0.9610 - o4_f1: 0.9627 - o5_f1: 0.9627 - o6_f1: 0.9643 - val_loss: 232.5173 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 469/500\n",
      "\n",
      "Epoch 00469: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8766 - o2_f1: 0.9564 - o3_f1: 0.9604 - o4_f1: 0.9624 - o5_f1: 0.9624 - o6_f1: 0.9648 - val_loss: 232.5172 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 470/500\n",
      "\n",
      "Epoch 00470: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8809 - o2_f1: 0.9566 - o3_f1: 0.9604 - o4_f1: 0.9627 - o5_f1: 0.9618 - o6_f1: 0.9648 - val_loss: 232.5172 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 471/500\n",
      "\n",
      "Epoch 00471: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8781 - o2_f1: 0.9551 - o3_f1: 0.9590 - o4_f1: 0.9607 - o5_f1: 0.9601 - o6_f1: 0.9626 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 472/500\n",
      "\n",
      "Epoch 00472: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8772 - o2_f1: 0.9563 - o3_f1: 0.9605 - o4_f1: 0.9627 - o5_f1: 0.9630 - o6_f1: 0.9647 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 473/500\n",
      "\n",
      "Epoch 00473: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8682 - o2_f1: 0.9475 - o3_f1: 0.9527 - o4_f1: 0.9546 - o5_f1: 0.9555 - o6_f1: 0.9571 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 474/500\n",
      "\n",
      "Epoch 00474: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8652 - o2_f1: 0.9486 - o3_f1: 0.9528 - o4_f1: 0.9545 - o5_f1: 0.9536 - o6_f1: 0.9565 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 475/500\n",
      "\n",
      "Epoch 00475: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8816 - o2_f1: 0.9562 - o3_f1: 0.9609 - o4_f1: 0.9629 - o5_f1: 0.9614 - o6_f1: 0.9641 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 476/500\n",
      "\n",
      "Epoch 00476: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8667 - o2_f1: 0.9535 - o3_f1: 0.9568 - o4_f1: 0.9591 - o5_f1: 0.9599 - o6_f1: 0.9624 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 477/500\n",
      "\n",
      "Epoch 00477: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8788 - o2_f1: 0.9584 - o3_f1: 0.9626 - o4_f1: 0.9646 - o5_f1: 0.9649 - o6_f1: 0.9667 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 478/500\n",
      "\n",
      "Epoch 00478: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8792 - o2_f1: 0.9578 - o3_f1: 0.9624 - o4_f1: 0.9644 - o5_f1: 0.9652 - o6_f1: 0.9675 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 479/500\n",
      "\n",
      "Epoch 00479: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8698 - o2_f1: 0.9536 - o3_f1: 0.9592 - o4_f1: 0.9613 - o5_f1: 0.9613 - o6_f1: 0.9632 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/500\n",
      "\n",
      "Epoch 00480: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8766 - o2_f1: 0.9564 - o3_f1: 0.9603 - o4_f1: 0.9644 - o5_f1: 0.9627 - o6_f1: 0.9668 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 481/500\n",
      "\n",
      "Epoch 00481: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8769 - o2_f1: 0.9572 - o3_f1: 0.9613 - o4_f1: 0.9632 - o5_f1: 0.9638 - o6_f1: 0.9658 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 482/500\n",
      "\n",
      "Epoch 00482: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8747 - o2_f1: 0.9520 - o3_f1: 0.9557 - o4_f1: 0.9593 - o5_f1: 0.9584 - o6_f1: 0.9603 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 483/500\n",
      "\n",
      "Epoch 00483: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8725 - o2_f1: 0.9545 - o3_f1: 0.9586 - o4_f1: 0.9608 - o5_f1: 0.9608 - o6_f1: 0.9627 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 484/500\n",
      "\n",
      "Epoch 00484: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8724 - o2_f1: 0.9547 - o3_f1: 0.9582 - o4_f1: 0.9600 - o5_f1: 0.9602 - o6_f1: 0.9623 - val_loss: 232.5168 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 485/500\n",
      "\n",
      "Epoch 00485: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8771 - o2_f1: 0.9607 - o3_f1: 0.9636 - o4_f1: 0.9649 - o5_f1: 0.9651 - o6_f1: 0.9670 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 486/500\n",
      "\n",
      "Epoch 00486: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8820 - o2_f1: 0.9598 - o3_f1: 0.9634 - o4_f1: 0.9655 - o5_f1: 0.9653 - o6_f1: 0.9676 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 487/500\n",
      "\n",
      "Epoch 00487: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8719 - o2_f1: 0.9466 - o3_f1: 0.9507 - o4_f1: 0.9538 - o5_f1: 0.9549 - o6_f1: 0.9572 - val_loss: 232.5169 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 488/500\n",
      "\n",
      "Epoch 00488: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8771 - o2_f1: 0.9551 - o3_f1: 0.9592 - o4_f1: 0.9608 - o5_f1: 0.9616 - o6_f1: 0.9630 - val_loss: 232.5171 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 489/500\n",
      "\n",
      "Epoch 00489: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8766 - o2_f1: 0.9568 - o3_f1: 0.9604 - o4_f1: 0.9625 - o5_f1: 0.9613 - o6_f1: 0.9638 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 490/500\n",
      "\n",
      "Epoch 00490: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8758 - o2_f1: 0.9538 - o3_f1: 0.9578 - o4_f1: 0.9596 - o5_f1: 0.9593 - o6_f1: 0.9618 - val_loss: 232.5170 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 491/500\n",
      "\n",
      "Epoch 00491: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8738 - o2_f1: 0.9560 - o3_f1: 0.9603 - o4_f1: 0.9623 - o5_f1: 0.9621 - o6_f1: 0.9638 - val_loss: 232.5168 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 492/500\n",
      "\n",
      "Epoch 00492: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8737 - o2_f1: 0.9559 - o3_f1: 0.9620 - o4_f1: 0.9639 - o5_f1: 0.9648 - o6_f1: 0.9664 - val_loss: 232.5168 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 493/500\n",
      "\n",
      "Epoch 00493: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8698 - o2_f1: 0.9510 - o3_f1: 0.9556 - o4_f1: 0.9577 - o5_f1: 0.9580 - o6_f1: 0.9596 - val_loss: 232.5167 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/500\n",
      "\n",
      "Epoch 00494: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8777 - o2_f1: 0.9559 - o3_f1: 0.9603 - o4_f1: 0.9623 - o5_f1: 0.9619 - o6_f1: 0.9638 - val_loss: 232.5166 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 495/500\n",
      "\n",
      "Epoch 00495: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8803 - o2_f1: 0.9559 - o3_f1: 0.9607 - o4_f1: 0.9633 - o5_f1: 0.9637 - o6_f1: 0.9657 - val_loss: 232.5165 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 496/500\n",
      "\n",
      "Epoch 00496: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8693 - o2_f1: 0.9562 - o3_f1: 0.9605 - o4_f1: 0.9623 - o5_f1: 0.9624 - o6_f1: 0.9647 - val_loss: 232.5167 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 497/500\n",
      "\n",
      "Epoch 00497: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8727 - o2_f1: 0.9568 - o3_f1: 0.9609 - o4_f1: 0.9625 - o5_f1: 0.9625 - o6_f1: 0.9649 - val_loss: 232.5167 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 498/500\n",
      "\n",
      "Epoch 00498: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8774 - o2_f1: 0.9575 - o3_f1: 0.9621 - o4_f1: 0.9641 - o5_f1: 0.9634 - o6_f1: 0.9657 - val_loss: 232.5166 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 499/500\n",
      "\n",
      "Epoch 00499: LearningRateScheduler setting learning rate to 3.81469726563e-09.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8752 - o2_f1: 0.9585 - o3_f1: 0.9624 - o4_f1: 0.9656 - o5_f1: 0.9655 - o6_f1: 0.9671 - val_loss: 232.5167 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "Epoch 500/500\n",
      "\n",
      "Epoch 00500: LearningRateScheduler setting learning rate to 9.53674316406e-10.\n",
      " - 1s - loss: 59.8706 - o1_loss: 0.2513 - o2_loss: 0.1240 - o3_loss: 0.1055 - o4_loss: 0.0932 - o5_loss: 0.0948 - o6_loss: 0.0869 - o1_f1: 0.8722 - o2_f1: 0.9449 - o3_f1: 0.9488 - o4_f1: 0.9514 - o5_f1: 0.9520 - o6_f1: 0.9540 - val_loss: 232.5168 - val_o1_loss: 0.3612 - val_o2_loss: 0.3102 - val_o3_loss: 0.3179 - val_o4_loss: 0.3355 - val_o5_loss: 0.3512 - val_o6_loss: 0.3765 - val_o1_f1: 0.6914 - val_o2_f1: 0.7181 - val_o3_f1: 0.7090 - val_o4_f1: 0.7059 - val_o5_f1: 0.7251 - val_o6_f1: 0.7091\n",
      "['val_o1_loss', 'val_o2_loss', 'val_o3_loss', 'val_o4_loss', 'val_o5_loss', 'val_o6_loss']\n",
      "['o1_loss', 'o2_loss', 'o3_loss', 'o4_loss', 'o5_loss', 'o6_loss']\n",
      "['lr', 'o1_f1', 'o2_f1', 'o3_f1', 'o4_f1', 'o5_f1', 'o6_f1', 'val_o1_f1', 'val_o2_f1', 'val_o3_f1', 'val_o4_f1', 'val_o5_f1', 'val_o6_f1']\n",
      "(807, 1)\n",
      "[0.1  0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23\n",
      " 0.24 0.25 0.26 0.27 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37\n",
      " 0.38 0.39 0.4  0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51\n",
      " 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65\n",
      " 0.66 0.67 0.68 0.69 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79\n",
      " 0.8  0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89]\n",
      "    accuracy        f1  precision    recall    th\n",
      "0   0.864932  0.828885   0.711590  0.992481  0.10\n",
      "1   0.879802  0.844800   0.735376  0.992481  0.11\n",
      "2   0.892193  0.858537   0.756447  0.992481  0.12\n",
      "3   0.900867  0.867110   0.776786  0.981203  0.13\n",
      "4   0.914498  0.883249   0.803077  0.981203  0.14\n",
      "5   0.920694  0.890785   0.815625  0.981203  0.15\n",
      "6   0.926890  0.898451   0.828571  0.981203  0.16\n",
      "7   0.938042  0.912587   0.852941  0.981203  0.17\n",
      "8   0.945477  0.921986   0.872483  0.977444  0.18\n",
      "9   0.947955  0.924731   0.883562  0.969925  0.19\n",
      "10  0.954151  0.933092   0.898955  0.969925  0.20\n",
      "11  0.962825  0.945055   0.921429  0.969925  0.21\n",
      "12  0.966543  0.950276   0.931408  0.969925  0.22\n",
      "13  0.971499  0.957328   0.945055  0.969925  0.23\n",
      "14  0.972739  0.959108   0.948529  0.969925  0.24\n",
      "15  0.973978  0.960894   0.952030  0.969925  0.25\n",
      "16  0.975217  0.962687   0.955556  0.969925  0.26\n",
      "17  0.980173  0.969925   0.969925  0.969925  0.27\n",
      "18  0.978934  0.967985   0.969811  0.966165  0.28\n",
      "19  0.977695  0.966038   0.969697  0.962406  0.29\n",
      "20  0.978934  0.967864   0.973384  0.962406  0.30\n",
      "21  0.978934  0.967864   0.973384  0.962406  0.31\n",
      "22  0.978934  0.967864   0.973384  0.962406  0.32\n",
      "23  0.978934  0.967864   0.973384  0.962406  0.33\n",
      "24  0.980173  0.969582   0.980769  0.958647  0.34\n",
      "25  0.981413  0.971429   0.984556  0.958647  0.35\n",
      "26  0.981413  0.971429   0.984556  0.958647  0.36\n",
      "27  0.981413  0.971429   0.984556  0.958647  0.37\n",
      "28  0.980173  0.969466   0.984496  0.954887  0.38\n",
      "29  0.978934  0.967495   0.984436  0.951128  0.39\n",
      "..       ...       ...        ...       ...   ...\n",
      "50  0.971499  0.955166   0.991903  0.921053  0.60\n",
      "51  0.971499  0.955166   0.991903  0.921053  0.61\n",
      "52  0.966543  0.946955   0.991770  0.906015  0.62\n",
      "53  0.966543  0.946746   0.995851  0.902256  0.63\n",
      "54  0.964064  0.942574   0.995816  0.894737  0.64\n",
      "55  0.964064  0.942574   0.995816  0.894737  0.65\n",
      "56  0.964064  0.942346   1.000000  0.890977  0.66\n",
      "57  0.960347  0.936000   1.000000  0.879699  0.67\n",
      "58  0.955390  0.927419   1.000000  0.864662  0.68\n",
      "59  0.954151  0.925253   1.000000  0.860902  0.69\n",
      "60  0.949195  0.916497   1.000000  0.845865  0.70\n",
      "61  0.947955  0.914286   1.000000  0.842105  0.71\n",
      "62  0.946716  0.912065   1.000000  0.838346  0.72\n",
      "63  0.945477  0.909836   1.000000  0.834586  0.73\n",
      "64  0.942999  0.905350   1.000000  0.827068  0.74\n",
      "65  0.938042  0.896266   1.000000  0.812030  0.75\n",
      "66  0.933086  0.887029   1.000000  0.796992  0.76\n",
      "67  0.929368  0.880000   1.000000  0.785714  0.77\n",
      "68  0.926890  0.875264   1.000000  0.778195  0.78\n",
      "69  0.923172  0.868085   1.000000  0.766917  0.79\n",
      "70  0.919455  0.860814   1.000000  0.755639  0.80\n",
      "71  0.919455  0.860814   1.000000  0.755639  0.81\n",
      "72  0.916976  0.855914   1.000000  0.748120  0.82\n",
      "73  0.909542  0.840959   1.000000  0.725564  0.83\n",
      "74  0.907063  0.835886   1.000000  0.718045  0.84\n",
      "75  0.900867  0.823009   1.000000  0.699248  0.85\n",
      "76  0.897150  0.815145   1.000000  0.687970  0.86\n",
      "77  0.889715  0.799097   1.000000  0.665414  0.87\n",
      "78  0.885998  0.790909   1.000000  0.654135  0.88\n",
      "79  0.884758  0.788155   1.000000  0.650376  0.89\n",
      "\n",
      "[80 rows x 5 columns]\n",
      "prediction threshold 0.35\n",
      "layer # 0, layer name inputs,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "inputs\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa037659990> None\n",
      "input dimensions (None, 27687)\n",
      "inputs\n",
      "model.inputs [<tf.Tensor 'inputs_1:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_1/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_1/Tanh\n",
      "h1_1/Tanh\n",
      "h2_1/Tanh\n",
      "h3_1/Tanh\n",
      "h4_1/Tanh\n",
      "h5_1/Tanh\n",
      "o6_1/Sigmoid\n",
      "ins [<tf.Tensor 'h0_1/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_1/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_1/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_1/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_1/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_1/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_1/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 27687)\n",
      "gradients.shape (807, 27687)\n",
      "feature_weights.shape (27687,)\n",
      "feature_weights min max -2.0158868 42.59691\n",
      "layer # 1, layer name h0,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "h0\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa03787bed0> None\n",
      "input dimensions (None, 27687)\n",
      "h0\n",
      "model.inputs [<tf.Tensor 'inputs_2:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_2/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h0_2/Tanh:0\", shape=(?, 9229), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_2/Tanh\n",
      "h1_2/Tanh\n",
      "h2_2/Tanh\n",
      "h3_2/Tanh\n",
      "h4_2/Tanh\n",
      "h5_2/Tanh\n",
      "o6_2/Sigmoid\n",
      "ins [<tf.Tensor 'h0_2/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_2/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_2/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_2/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_2/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_2/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_2/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_2:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_2:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_2:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 9229)\n",
      "gradients.shape (807, 9229)\n",
      "feature_weights.shape (9229,)\n",
      "feature_weights min max -2.0020685 58.28807\n",
      "layer # 2, layer name h1,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "h1\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa0378c0b90> None\n",
      "input dimensions (None, 27687)\n",
      "h1\n",
      "model.inputs [<tf.Tensor 'inputs_3:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_3/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h1_3/Tanh:0\", shape=(?, 1387), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_3/Tanh\n",
      "h1_3/Tanh\n",
      "h2_3/Tanh\n",
      "h3_3/Tanh\n",
      "h4_3/Tanh\n",
      "h5_3/Tanh\n",
      "o6_3/Sigmoid\n",
      "ins [<tf.Tensor 'h0_3/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_3/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_3/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_3/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_3/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_3/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_3/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_3:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_3:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_3:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 1387)\n",
      "gradients.shape (807, 1387)\n",
      "feature_weights.shape (1387,)\n",
      "feature_weights min max -1.8969474 18.08677\n",
      "layer # 3, layer name h2,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "h2\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa035c15650> None\n",
      "input dimensions (None, 27687)\n",
      "h2\n",
      "model.inputs [<tf.Tensor 'inputs_4:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_4/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h2_4/Tanh:0\", shape=(?, 1066), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_4/Tanh\n",
      "h1_4/Tanh\n",
      "h2_4/Tanh\n",
      "h3_4/Tanh\n",
      "h4_4/Tanh\n",
      "h5_4/Tanh\n",
      "o6_4/Sigmoid\n",
      "ins [<tf.Tensor 'h0_4/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_4/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_4/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_4/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_4/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_4/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_4/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_4:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_4:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_4:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 1066)\n",
      "gradients.shape (807, 1066)\n",
      "feature_weights.shape (1066,)\n",
      "feature_weights min max -1.8969474 18.08677\n",
      "layer # 4, layer name h3,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "h3\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa038bf68d0> None\n",
      "input dimensions (None, 27687)\n",
      "h3\n",
      "model.inputs [<tf.Tensor 'inputs_5:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_5/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h3_5/Tanh:0\", shape=(?, 447), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_5/Tanh\n",
      "h1_5/Tanh\n",
      "h2_5/Tanh\n",
      "h3_5/Tanh\n",
      "h4_5/Tanh\n",
      "h5_5/Tanh\n",
      "o6_5/Sigmoid\n",
      "ins [<tf.Tensor 'h0_5/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_5/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_5/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_5/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_5/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_5/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_5/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_5:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_5:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_5:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 447)\n",
      "gradients.shape (807, 447)\n",
      "feature_weights.shape (447,)\n",
      "feature_weights min max -1.8969474 40.41783\n",
      "layer # 5, layer name h4,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "h4\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa038dcf8d0> None\n",
      "input dimensions (None, 27687)\n",
      "h4\n",
      "model.inputs [<tf.Tensor 'inputs_6:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_6/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h4_6/Tanh:0\", shape=(?, 147), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_6/Tanh\n",
      "h1_6/Tanh\n",
      "h2_6/Tanh\n",
      "h3_6/Tanh\n",
      "h4_6/Tanh\n",
      "h5_6/Tanh\n",
      "o6_6/Sigmoid\n",
      "ins [<tf.Tensor 'h0_6/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_6/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_6/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_6/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_6/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_6/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_6/BiasAdd:0' shape=(?, 1) dtype=float32>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inputs_6:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_6:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_6:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 147)\n",
      "gradients.shape (807, 147)\n",
      "feature_weights.shape (147,)\n",
      "feature_weights min max -1.8969401 45.075405\n",
      "layer # 6, layer name h5,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fa105bf27d0>\n",
      "h5\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fa038045510> None\n",
      "input dimensions (None, 27687)\n",
      "h5\n",
      "model.inputs [<tf.Tensor 'inputs_7:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_7/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h5_7/Tanh:0\", shape=(?, 26), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_7/Tanh\n",
      "h1_7/Tanh\n",
      "h2_7/Tanh\n",
      "h3_7/Tanh\n",
      "h4_7/Tanh\n",
      "h5_7/Tanh\n",
      "o6_7/Sigmoid\n",
      "ins [<tf.Tensor 'h0_7/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_7/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_7/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_7/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_7/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_7/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_7/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_7:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_7:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_7:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 26)\n",
      "gradients.shape (807, 26)\n",
      "feature_weights.shape (26,)\n",
      "feature_weights min max -1.8622969 51.480335\n",
      "predicting\n",
      "model id: P-net_ALL\n",
      "predicitng ...\n",
      "(204, 1)\n",
      "(204, 1)\n",
      "(204, 2)\n",
      "y_pred_test (204, 1) (204,)\n",
      "(204, 1) (204, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       137\n",
      "           1       0.76      0.76      0.76        67\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       204\n",
      "   macro avg       0.82      0.82      0.82       204\n",
      "weighted avg       0.84      0.84      0.84       204\n",
      "\n",
      "model name P-net_ALL -- Test score {'aupr': 0.8789418150513575, 'f1': 0.7611940298507462, 'auc': 0.927334132258416, 'recall': 0.7611940298507462, 'precision': 0.7611940298507462, 'accuracy': 0.8431372549019608}\n",
      "saving results\n",
      "saving yml : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/P-net_ALL_params.yml\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/P-net_ALL_testing.csv\n",
      "('info', Index([u'01-087MM_BONE', u'01-095N1_LN', u'08-093J1_LN', u'10362',\n",
      "       u'AAPC-IP_LG-069-Tumor-SM-3NC72', u'AAPC-STID0000002909-Tumor-SM-2XTZ4',\n",
      "       u'AAPC-STID0000003057-Tumor-SM-2XTZT',\n",
      "       u'AAPC-STID0000007180-Tumor-SM-2XU14',\n",
      "       u'AAPC-STID0000012110-Tumor-SM-2XU1J',\n",
      "       u'AAPC-STID0000017088-Tumor-SM-2XU1V',\n",
      "       ...\n",
      "       u'TCGA-V1-A9OY', u'TCGA-V1-A9Z9', u'TCGA-VN-A88O', u'TCGA-VN-A943',\n",
      "       u'TCGA-XK-AAJP', u'TCGA-YL-A8HL', u'TCGA-ZG-A9LM', u'TCGA-ZG-A9LN',\n",
      "       u'TCGA-ZG-A9MC', u'TP_2034'],\n",
      "      dtype='object', length=204))\n",
      "saving coef \n",
      "Confusion matrix, without normalization\n",
      "[[121  16]\n",
      " [ 16  51]]\n",
      "Normalized confusion matrix\n",
      "[[0.88321168 0.11678832]\n",
      " [0.23880597 0.76119403]]\n",
      "saving coef\n",
      "saving coef\n",
      "saving model P-net_ALL coef to dir (/Users/jongha523/pnet_prostate_paper/_logs/p1000/pnet/onsplit_average_reg_10_tanh_large_testing/fs)\n",
      "FS dir (/Users/jongha523/pnet_prostate_paper/_logs/p1000/pnet/onsplit_average_reg_10_tanh_large_testing/fs/P-net_ALL.h5)\n",
      "predicitng ...\n",
      "(807, 1)\n",
      "(807, 1)\n",
      "(807, 2)\n",
      "y_pred_test (807, 1) (807,)\n",
      "(807, 1) (807, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       541\n",
      "           1       0.98      0.96      0.97       266\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       807\n",
      "   macro avg       0.98      0.98      0.98       807\n",
      "weighted avg       0.98      0.98      0.98       807\n",
      "\n",
      "model P-net_ALL -- Train score {'aupr': 0.9918850442967053, 'f1': 0.9714285714285714, 'auc': 0.9944651369644074, 'recall': 0.9586466165413534, 'precision': 0.9845559845559846, 'accuracy': 0.9814126394052045}\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/P-net_ALL_training.csv\n",
      "('info', Index([u'01-120A1_LIVER', u'02-083E1_LN', u'03-082H1_LIVER',\n",
      "       u'03-130L_RETROPERITONEAL', u'03-139E3_RETROPERITONEAL',\n",
      "       u'03-163S4_LIVER', u'03-192B_LUNG', u'05-116F_LUNG', u'05-148E3_LIVER',\n",
      "       u'05-165O_ADRENAL',\n",
      "       ...\n",
      "       u'TCGA-ZG-A9ND', u'TCGA-ZG-A9NI', u'TP_2010', u'TP_2032', u'TP_2054',\n",
      "       u'TP_2060', u'TP_2061', u'TP_2069', u'TP_2078', u'TP_2079'],\n",
      "      dtype='object', length=807))\n",
      "fitting\n",
      "{'type': 'sgd', 'params': {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01, 'class_weight': {0: 0.75, 1: 1.5}}, 'id': 'Logistic Regression'}\n",
      "/opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "predicting\n",
      "model id: Logistic Regression_ALL\n",
      "predicitng ...\n",
      "y_pred_test (204,) (204,)\n",
      "(204, 1) (204,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       137\n",
      "           1       0.79      0.67      0.73        67\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       204\n",
      "   macro avg       0.82      0.79      0.80       204\n",
      "weighted avg       0.83      0.83      0.83       204\n",
      "\n",
      "model name Logistic Regression_ALL -- Test score {'aupr': 0.8089833666704149, 'f1': 0.7258064516129032, 'auc': 0.881904346878745, 'recall': 0.6716417910447762, 'precision': 0.7894736842105263, 'accuracy': 0.8333333333333334}\n",
      "saving results\n",
      "saving yml : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/Logistic Regression_ALL_params.yml\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/Logistic Regression_ALL_testing.csv\n",
      "('info', Index([u'01-087MM_BONE', u'01-095N1_LN', u'08-093J1_LN', u'10362',\n",
      "       u'AAPC-IP_LG-069-Tumor-SM-3NC72', u'AAPC-STID0000002909-Tumor-SM-2XTZ4',\n",
      "       u'AAPC-STID0000003057-Tumor-SM-2XTZT',\n",
      "       u'AAPC-STID0000007180-Tumor-SM-2XU14',\n",
      "       u'AAPC-STID0000012110-Tumor-SM-2XU1J',\n",
      "       u'AAPC-STID0000017088-Tumor-SM-2XU1V',\n",
      "       ...\n",
      "       u'TCGA-V1-A9OY', u'TCGA-V1-A9Z9', u'TCGA-VN-A88O', u'TCGA-VN-A943',\n",
      "       u'TCGA-XK-AAJP', u'TCGA-YL-A8HL', u'TCGA-ZG-A9LM', u'TCGA-ZG-A9LN',\n",
      "       u'TCGA-ZG-A9MC', u'TP_2034'],\n",
      "      dtype='object', length=204))\n",
      "saving coef \n",
      "Confusion matrix, without normalization\n",
      "[[125  12]\n",
      " [ 22  45]]\n",
      "Normalized confusion matrix\n",
      "[[0.91240876 0.08759124]\n",
      " [0.32835821 0.67164179]]\n",
      "saving coef\n",
      "predicitng ...\n",
      "y_pred_test (807,) (807,)\n",
      "(807, 1) (807,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       541\n",
      "           1       0.99      0.98      0.99       266\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       807\n",
      "   macro avg       0.99      0.99      0.99       807\n",
      "weighted avg       0.99      0.99      0.99       807\n",
      "\n",
      "model Logistic Regression_ALL -- Train score {'aupr': 0.998589320472007, 'f1': 0.9886792452830188, 'auc': 0.9991800202910233, 'recall': 0.9849624060150376, 'precision': 0.9924242424242424, 'accuracy': 0.9925650557620818}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/Logistic Regression_ALL_training.csv\n",
      "('info', Index([u'01-120A1_LIVER', u'02-083E1_LN', u'03-082H1_LIVER',\n",
      "       u'03-130L_RETROPERITONEAL', u'03-139E3_RETROPERITONEAL',\n",
      "       u'03-163S4_LIVER', u'03-192B_LUNG', u'05-116F_LUNG', u'05-148E3_LIVER',\n",
      "       u'05-165O_ADRENAL',\n",
      "       ...\n",
      "       u'TCGA-ZG-A9ND', u'TCGA-ZG-A9NI', u'TP_2010', u'TP_2032', u'TP_2054',\n",
      "       u'TP_2060', u'TP_2061', u'TP_2069', u'TP_2078', u'TP_2079'],\n",
      "      dtype='object', length=807))\n",
      "accuracy\n",
      "auc\n",
      "aupr\n",
      "f1\n",
      "precision\n",
      "recall\n",
      "                         accuracy       auc  ...  precision    recall\n",
      "P-net_ALL                0.843137  0.927334  ...   0.761194  0.761194\n",
      "Logistic Regression_ALL  0.833333  0.881904  ...   0.789474  0.671642\n",
      "\n",
      "[2 rows x 6 columns]\n",
      "Elapsed Time: 12m 54s\n",
      "(pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#Run the run_me.py file to retrain the model with newly defined parameters (epoch=500)\n",
    "#evaluation metrics shown at the very bottom\n",
    "pythonw run_me.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the parameter file again using vim editor and this time change batch size from 50 to 20 (revert epoch to original 300)\n",
    "\n",
    "vim params/P1000/pnet/onsplit_average_reg_10_tanh_large.py\n",
    "\n",
    "#After making changes exit file with esc :wq command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pnet_env) Using TensorFlow backend.\n",
      "setting logs\n",
      "random seed 234\n",
      "/Users/jongha523/pnet_prostate_paper/train/params/P1000/./pnet/onsplit_average_reg_10_tanh_large_testing.py\n",
      "/Users/jongha523/pnet_prostate_paper/train/params/P1000/./pnet/onsplit_average_reg_10_tanh_large_testing.py:1: RuntimeWarning: Parent module '/Users/jongha523/pnet_prostate_paper/train/params/P1000/' not found while handling absolute import\n",
      "  from model.builders.prostate_models import build_pnet2\n",
      "{'params': {'save_train': True, 'eval_dataset': 'test'}, 'type': 'one_split'}\n",
      "[{'params': {'drop_AR': False, 'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'combine_type': 'union', 'training_split': 0, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True}, 'type': 'prostate_paper', 'id': 'ALL'}]\n",
      "data_params {'params': {'drop_AR': False, 'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'combine_type': 'union', 'training_split': 0, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True}, 'type': 'prostate_paper', 'id': 'ALL'}\n",
      "loading data....\n",
      "loading mut_important\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_final_analysis_set_cross_important_only.csv,\n",
      "(1011, 14378)\n",
      "loading response from response_paper.csv\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1011 samples, 8319 variables, 1011 responses \n",
      "8319\n",
      "mut_binary = True\n",
      "loading cnv_del\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "loading cnv_amp\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "loading from memory cached_data\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "After combining, loaded data 1011 samples, 27687 variables, 1011 responses \n",
      "predicting\n",
      "x_train (807, 27687) y_train (807, 1) \n",
      "x_test (204, 27687) y_test (204, 1) \n",
      "preprocessing....\n",
      "preprocessing....\n",
      "{'type': None}\n",
      "Pre-processing: None\n",
      "class_weight auto\n",
      "fitting\n",
      "{'type': 'nn', 'params': {'model_params': {'shuffle_genes': False, 'dropout_testing': False, 'kernel_initializer': 'lecun_uniform', 'n_hidden_layers': 5, 'dropout': [0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 'attention': False, 'w_reg_outcomes': [0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 'loss_weights': [2, 7, 20, 54, 148, 400], 'w_reg': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001], 'add_unk_genes': False, 'activation': 'tanh', 'optimizer': 'Adam', 'use_bias': True, 'data_params': {'type': 'prostate_paper', 'params': {'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True, 'drop_AR': False, 'combine_type': 'union', 'training_split': 0}, 'id': 'ALL'}}, 'fitting_params': {'early_stop': False, 'shuffle': True, 'verbose': 2, 'samples_per_epoch': 10, 'reduce_lr': False, 'save_gradient': False, 'reduce_lr_after_nepochs': {'epochs_drop': 50, 'drop': 0.25}, 'batch_size': 20, 'max_f1': True, 'epoch': 300, 'monitor': 'val_o6_f1', 'save_name': 'pnet', 'select_best_model': False, 'n_outputs': 6, 'lr': 0.001, 'prediction_output': 'average', 'debug': False, 'class_weight': 'auto'}, 'feature_importance': 'deepexplain_deeplift', 'build_fn': <function build_pnet2 at 0x7fe42c2a91b8>}, 'id': 'P-net'}\n",
      "{'type': 'prostate_paper', 'params': {'balanced_data': False, 'data_type': ['mut_important', 'cnv_del', 'cnv_amp'], 'mut_binary': True, 'cnv_levels': 3, 'selected_genes': 'tcga_prostate_expressed_genes_and_cancer_genes.csv', 'use_coding_genes_only': True, 'drop_AR': False, 'combine_type': 'union', 'training_split': 0}, 'id': 'ALL'}\n",
      "n_hidden_layers 5\n",
      "loading mut_important\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_final_analysis_set_cross_important_only.csv,\n",
      "loading from memory cached_data\n",
      "(1011, 14378)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1011 samples, 8319 variables, 1011 responses \n",
      "8319\n",
      "mut_binary = True\n",
      "loading cnv_del\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "loading from memory cached_data\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "loading cnv_amp\n",
      "loading data from /Users/jongha523/pnet_prostate_paper/_database/prostate/processed/P1000_data_CNA_paper.csv,\n",
      "loading from memory cached_data\n",
      "(1013, 13802)\n",
      "loading from memory cached_data\n",
      "some genes dont exist in the original data set\n",
      "loaded data 1013 samples, 6344 variables, 1013 responses \n",
      "6344\n",
      "After combining, loaded data 1011 samples, 27687 variables, 1011 responses \n",
      "(1011, 27687)\n",
      "(1011, 1)\n",
      "(1011,)\n",
      "(27687,)\n",
      "x shape (1011, 27687) , y shape (1011, 1) info (1011,) genes (27687,)\n",
      "x shape (1011, 27687) , y shape (1011, 1) info (1011,) genes (27687,)\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer <keras.regularizers.L1L2 object at 0x7fe411e1b350> <keras.initializers.VarianceScaling object at 0x7fe411e1b650> <keras.regularizers.L1L2 object at 0x7fe411e1b350>\n",
      "input dimensions (None, 27687)\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:145: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear0\")`\n",
      "  decision_outcome = Dense(1, activation='linear', name='o_linear{}'.format(0), W_regularizer=reg_l(w_reg_outcome0))(\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:162: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear1\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome1 / 2.))(outcome)\n",
      "layer # 0\n",
      "pathways 1387\n",
      "genes 9275\n",
      "filtered_map (9229, 0)\n",
      "filtered_map (9229, 0)\n",
      "filtered_map (9229, 0)\n",
      "layer 0 , # of edges  15651.0\n",
      "layer # 1\n",
      "pathways 1066\n",
      "genes 1399\n",
      "filtered_map (1387, 0)\n",
      "filtered_map (1387, 0)\n",
      "filtered_map (1387, 0)\n",
      "layer 1 , # of edges  1396.0\n",
      "layer # 2\n",
      "pathways 447\n",
      "genes 1068\n",
      "filtered_map (1066, 0)\n",
      "filtered_map (1066, 0)\n",
      "filtered_map (1066, 0)\n",
      "layer 2 , # of edges  1070.0\n",
      "layer # 3\n",
      "pathways 147\n",
      "genes 448\n",
      "filtered_map (447, 0)\n",
      "filtered_map (447, 0)\n",
      "filtered_map (447, 0)\n",
      "layer 3 , # of edges  447.0\n",
      "layer # 4\n",
      "pathways 26\n",
      "genes 147\n",
      "filtered_map (147, 0)\n",
      "filtered_map (147, 0)\n",
      "filtered_map (147, 0)\n",
      "layer 4 , # of edges  148.0\n",
      "layer # 5\n",
      "pathways 1\n",
      "genes 26\n",
      "filtered_map (26, 0)\n",
      "filtered_map (26, 0)\n",
      "filtered_map (26, 0)\n",
      "layer 5 , # of edges  26.0\n",
      "original dropout [0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "dropout [1, 2, 3, 4, 5] [0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1] [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n",
      "n_genes, n_pathways 9229 1387 \n",
      "layer 0, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear2\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "n_genes, n_pathways 1387 1066 \n",
      "layer 1, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear3\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "n_genes, n_pathways 1066 447 \n",
      "layer 2, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear4\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_genes, n_pathways 447 147 \n",
      "layer 3, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear5\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "n_genes, n_pathways 147 26 \n",
      "layer 4, dropout  0.1 w_reg 0.001\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/builders_utils.py:228: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_regularizer=<keras.reg..., name=\"o_linear6\")`\n",
      "  W_regularizer=reg_l(w_reg_outcome))(outcome)\n",
      "Compiling...\n",
      "/Users/jongha523/pnet_prostate_paper/model/builders/prostate_models.py:171: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  model = Model(input=[ins], output=outcome)\n",
      "loss_weights [2, 7, 20, 54, 148, 400]\n",
      "done compiling\n",
      "  - 0 inputs (None, 27687)\n",
      "  - 1 h0 (None, 9229)\n",
      "  - 2 dropout_0 (None, 9229)\n",
      "  - 3 h1 (None, 1387)\n",
      "  - 4 dropout_1 (None, 1387)\n",
      "  - 5 h2 (None, 1066)\n",
      "  - 6 dropout_2 (None, 1066)\n",
      "  - 7 h3 (None, 447)\n",
      "  - 8 dropout_3 (None, 447)\n",
      "  - 9 h4 (None, 147)\n",
      "  - 10 dropout_4 (None, 147)\n",
      "  - 11 h5 (None, 26)\n",
      "  - 12 o_linear1 (None, 1)\n",
      "  - 13 o_linear2 (None, 1)\n",
      "  - 14 o_linear3 (None, 1)\n",
      "  - 15 o_linear4 (None, 1)\n",
      "  - 16 o_linear5 (None, 1)\n",
      "  - 17 o_linear6 (None, 1)\n",
      "  - 18 o1 (None, 1)\n",
      "  - 19 o2 (None, 1)\n",
      "  - 20 o3 (None, 1)\n",
      "  - 21 o4 (None, 1)\n",
      "  - 22 o5 (None, 1)\n",
      "  - 23 o6 (None, 1)\n",
      "[<keras.engine.input_layer.InputLayer object at 0x7fe42b416410>, <model.layers_custom.Diagonal object at 0x7fe411e1be10>, <keras.layers.core.Dropout object at 0x7fe3da177ad0>, <model.layers_custom.SparseTF object at 0x7fe3f0d39350>, <keras.layers.core.Dropout object at 0x7fe3fcd1fd10>, <model.layers_custom.SparseTF object at 0x7fe3fcd1f810>, <keras.layers.core.Dropout object at 0x7fe35fa40e90>, <model.layers_custom.SparseTF object at 0x7fe35fa40cd0>, <keras.layers.core.Dropout object at 0x7fe3f73d9d50>, <model.layers_custom.SparseTF object at 0x7fe3f73d9b10>, <keras.layers.core.Dropout object at 0x7fe3ffa18b90>, <model.layers_custom.SparseTF object at 0x7fe3ffa18950>, <keras.layers.core.Dense object at 0x7fe3da177d10>, <keras.layers.core.Dense object at 0x7fe3d41da2d0>, <keras.layers.core.Dense object at 0x7fe41277df90>, <keras.layers.core.Dense object at 0x7fe3f73cbf10>, <keras.layers.core.Dense object at 0x7fe3f795db50>, <keras.layers.core.Dense object at 0x7fe3ffa1d990>, <keras.layers.core.Activation object at 0x7fe3da177290>, <keras.layers.core.Activation object at 0x7fe3f0d39150>, <keras.layers.core.Activation object at 0x7fe35fa40650>, <keras.layers.core.Activation object at 0x7fe3f73d94d0>, <keras.layers.core.Activation object at 0x7fe3ffa18310>, <keras.layers.core.Activation object at 0x7fe3fc23de10>]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 27687)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h0 (Diagonal)                   (None, 9229)         36916       inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_0 (Dropout)             (None, 9229)         0           h0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h1 (SparseTF)                   (None, 1387)         17038       dropout_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1387)         0           h1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h2 (SparseTF)                   (None, 1066)         2462        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1066)         0           h2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h3 (SparseTF)                   (None, 447)          1517        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 447)          0           h3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h4 (SparseTF)                   (None, 147)          594         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 147)          0           h4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "h5 (SparseTF)                   (None, 26)           174         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o_linear1 (Dense)               (None, 1)            9230        h0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear2 (Dense)               (None, 1)            1388        h1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear3 (Dense)               (None, 1)            1067        h2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear4 (Dense)               (None, 1)            448         h3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear5 (Dense)               (None, 1)            148         h4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o_linear6 (Dense)               (None, 1)            27          h5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "o1 (Activation)                 (None, 1)            0           o_linear1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o2 (Activation)                 (None, 1)            0           o_linear2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o3 (Activation)                 (None, 1)            0           o_linear3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o4 (Activation)                 (None, 1)            0           o_linear4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o5 (Activation)                 (None, 1)            0           o_linear5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o6 (Activation)                 (None, 1)            0           o_linear6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 71,009\n",
      "Trainable params: 71,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "# of trainable params of the model is 71009\n",
      "start fitting\n",
      "class_weight {0: 0.7458410351201479, 1: 1.5169172932330828}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 807 samples, validate on 102 samples\n",
      "Epoch 1/300\n",
      "2021-12-24 12:09:57.978350: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-24 12:09:57.978603: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 8s - loss: 412.5132 - o1_loss: 0.6355 - o2_loss: 0.6419 - o3_loss: 0.6448 - o4_loss: 0.6500 - o5_loss: 0.6575 - o6_loss: 0.6524 - o1_f1: 0.0093 - o2_f1: 0.0165 - o3_f1: 0.0099 - o4_f1: 0.0130 - o5_f1: 0.0093 - o6_f1: 0.0104 - val_loss: 397.8674 - val_o1_loss: 0.6167 - val_o2_loss: 0.6278 - val_o3_loss: 0.6300 - val_o4_loss: 0.6297 - val_o5_loss: 0.6305 - val_o6_loss: 0.6297 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 400.9476 - o1_loss: 0.6118 - o2_loss: 0.6324 - o3_loss: 0.6356 - o4_loss: 0.6356 - o5_loss: 0.6347 - o6_loss: 0.6348 - o1_f1: 0.0055 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.4861 - val_o1_loss: 0.6082 - val_o2_loss: 0.6257 - val_o3_loss: 0.6290 - val_o4_loss: 0.6294 - val_o5_loss: 0.6294 - val_o6_loss: 0.6295 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 401.3377 - o1_loss: 0.5998 - o2_loss: 0.6321 - o3_loss: 0.6373 - o4_loss: 0.6364 - o5_loss: 0.6355 - o6_loss: 0.6355 - o1_f1: 0.0181 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.4186 - val_o1_loss: 0.5999 - val_o2_loss: 0.6213 - val_o3_loss: 0.6288 - val_o4_loss: 0.6295 - val_o5_loss: 0.6294 - val_o6_loss: 0.6295 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 400.4473 - o1_loss: 0.5804 - o2_loss: 0.6220 - o3_loss: 0.6338 - o4_loss: 0.6346 - o5_loss: 0.6343 - o6_loss: 0.6344 - o1_f1: 0.1138 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.2610 - val_o1_loss: 0.5816 - val_o2_loss: 0.6126 - val_o3_loss: 0.6276 - val_o4_loss: 0.6291 - val_o5_loss: 0.6294 - val_o6_loss: 0.6295 - val_o1_f1: 0.0000e+00 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 400.6434 - o1_loss: 0.5608 - o2_loss: 0.6114 - o3_loss: 0.6334 - o4_loss: 0.6351 - o5_loss: 0.6348 - o6_loss: 0.6349 - o1_f1: 0.1699 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 397.0107 - val_o1_loss: 0.5653 - val_o2_loss: 0.5976 - val_o3_loss: 0.6263 - val_o4_loss: 0.6292 - val_o5_loss: 0.6292 - val_o6_loss: 0.6293 - val_o1_f1: 0.0769 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 399.8760 - o1_loss: 0.5377 - o2_loss: 0.5896 - o3_loss: 0.6289 - o4_loss: 0.6339 - o5_loss: 0.6340 - o6_loss: 0.6342 - o1_f1: 0.2410 - o2_f1: 0.0000e+00 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 396.4501 - val_o1_loss: 0.5575 - val_o2_loss: 0.5713 - val_o3_loss: 0.6195 - val_o4_loss: 0.6278 - val_o5_loss: 0.6288 - val_o6_loss: 0.6290 - val_o1_f1: 0.2262 - val_o2_f1: 0.0000e+00 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 399.0208 - o1_loss: 0.5231 - o2_loss: 0.5592 - o3_loss: 0.6203 - o4_loss: 0.6320 - o5_loss: 0.6333 - o6_loss: 0.6335 - o1_f1: 0.3995 - o2_f1: 0.1258 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 395.7166 - val_o1_loss: 0.5373 - val_o2_loss: 0.5357 - val_o3_loss: 0.6067 - val_o4_loss: 0.6255 - val_o5_loss: 0.6284 - val_o6_loss: 0.6289 - val_o1_f1: 0.2262 - val_o2_f1: 0.0891 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 398.1289 - o1_loss: 0.5031 - o2_loss: 0.5207 - o3_loss: 0.6039 - o4_loss: 0.6286 - o5_loss: 0.6327 - o6_loss: 0.6335 - o1_f1: 0.4749 - o2_f1: 0.3904 - o3_f1: 0.0000e+00 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 393.5809 - val_o1_loss: 0.5176 - val_o2_loss: 0.4910 - val_o3_loss: 0.5796 - val_o4_loss: 0.6174 - val_o5_loss: 0.6261 - val_o6_loss: 0.6277 - val_o1_f1: 0.2160 - val_o2_f1: 0.3029 - val_o3_f1: 0.0000e+00 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 395.9173 - o1_loss: 0.4887 - o2_loss: 0.4858 - o3_loss: 0.5750 - o4_loss: 0.6184 - o5_loss: 0.6300 - o6_loss: 0.6323 - o1_f1: 0.4760 - o2_f1: 0.5217 - o3_f1: 0.0375 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 389.1513 - val_o1_loss: 0.5110 - val_o2_loss: 0.4515 - val_o3_loss: 0.5368 - val_o4_loss: 0.5973 - val_o5_loss: 0.6195 - val_o6_loss: 0.6245 - val_o1_f1: 0.3338 - val_o2_f1: 0.4250 - val_o3_f1: 0.0588 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 389.4101 - o1_loss: 0.4634 - o2_loss: 0.4358 - o3_loss: 0.5232 - o4_loss: 0.5902 - o5_loss: 0.6195 - o6_loss: 0.6272 - o1_f1: 0.5504 - o2_f1: 0.6598 - o3_f1: 0.3748 - o4_f1: 0.0000e+00 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 379.9310 - val_o1_loss: 0.4872 - val_o2_loss: 0.4166 - val_o3_loss: 0.4835 - val_o4_loss: 0.5577 - val_o5_loss: 0.6016 - val_o6_loss: 0.6166 - val_o1_f1: 0.2262 - val_o2_f1: 0.4250 - val_o3_f1: 0.3735 - val_o4_f1: 0.0000e+00 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 377.6989 - o1_loss: 0.4547 - o2_loss: 0.4229 - o3_loss: 0.4782 - o4_loss: 0.5474 - o5_loss: 0.5949 - o6_loss: 0.6152 - o1_f1: 0.5551 - o2_f1: 0.6904 - o3_f1: 0.5301 - o4_f1: 0.1830 - o5_f1: 0.0000e+00 - o6_f1: 0.0000e+00 - val_loss: 361.7964 - val_o1_loss: 0.4831 - val_o2_loss: 0.3944 - val_o3_loss: 0.4361 - val_o4_loss: 0.5018 - val_o5_loss: 0.5627 - val_o6_loss: 0.5959 - val_o1_f1: 0.2160 - val_o2_f1: 0.4408 - val_o3_f1: 0.4147 - val_o4_f1: 0.2797 - val_o5_f1: 0.0000e+00 - val_o6_f1: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 354.6107 - o1_loss: 0.4322 - o2_loss: 0.3831 - o3_loss: 0.4255 - o4_loss: 0.4891 - o5_loss: 0.5487 - o6_loss: 0.5857 - o1_f1: 0.6207 - o2_f1: 0.6938 - o3_f1: 0.6684 - o4_f1: 0.5587 - o5_f1: 0.1254 - o6_f1: 0.0000e+00 - val_loss: 333.6748 - val_o1_loss: 0.4621 - val_o2_loss: 0.3788 - val_o3_loss: 0.4017 - val_o4_loss: 0.4465 - val_o5_loss: 0.5079 - val_o6_loss: 0.5552 - val_o1_f1: 0.3011 - val_o2_f1: 0.4571 - val_o3_f1: 0.4369 - val_o4_f1: 0.4664 - val_o5_f1: 0.3614 - val_o6_f1: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 325.2144 - o1_loss: 0.4189 - o2_loss: 0.3719 - o3_loss: 0.3976 - o4_loss: 0.4406 - o5_loss: 0.4960 - o6_loss: 0.5397 - o1_f1: 0.6169 - o2_f1: 0.7011 - o3_f1: 0.6854 - o4_f1: 0.6130 - o5_f1: 0.4717 - o6_f1: 0.1676 - val_loss: 302.3931 - val_o1_loss: 0.4496 - val_o2_loss: 0.3570 - val_o3_loss: 0.3771 - val_o4_loss: 0.4053 - val_o5_loss: 0.4561 - val_o6_loss: 0.5032 - val_o1_f1: 0.2916 - val_o2_f1: 0.4675 - val_o3_f1: 0.4675 - val_o4_f1: 0.4573 - val_o5_f1: 0.4553 - val_o6_f1: 0.4118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 296.6662 - o1_loss: 0.4074 - o2_loss: 0.3559 - o3_loss: 0.3764 - o4_loss: 0.4068 - o5_loss: 0.4521 - o6_loss: 0.4904 - o1_f1: 0.7054 - o2_f1: 0.7291 - o3_f1: 0.7067 - o4_f1: 0.6794 - o5_f1: 0.6548 - o6_f1: 0.6038 - val_loss: 275.6087 - val_o1_loss: 0.4396 - val_o2_loss: 0.3464 - val_o3_loss: 0.3645 - val_o4_loss: 0.3806 - val_o5_loss: 0.4177 - val_o6_loss: 0.4545 - val_o1_f1: 0.2916 - val_o2_f1: 0.4573 - val_o3_f1: 0.4573 - val_o4_f1: 0.4573 - val_o5_f1: 0.4664 - val_o6_f1: 0.4553\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 273.6457 - o1_loss: 0.3962 - o2_loss: 0.3475 - o3_loss: 0.3634 - o4_loss: 0.3837 - o5_loss: 0.4201 - o6_loss: 0.4484 - o1_f1: 0.6294 - o2_f1: 0.7020 - o3_f1: 0.6764 - o4_f1: 0.6787 - o5_f1: 0.6581 - o6_f1: 0.6381 - val_loss: 260.9116 - val_o1_loss: 0.4341 - val_o2_loss: 0.3408 - val_o3_loss: 0.3571 - val_o4_loss: 0.3708 - val_o5_loss: 0.3999 - val_o6_loss: 0.4260 - val_o1_f1: 0.4720 - val_o2_f1: 0.5156 - val_o3_f1: 0.4884 - val_o4_f1: 0.4573 - val_o5_f1: 0.4573 - val_o6_f1: 0.4573\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 251.5057 - o1_loss: 0.3784 - o2_loss: 0.3226 - o3_loss: 0.3368 - o4_loss: 0.3564 - o5_loss: 0.3896 - o6_loss: 0.4097 - o1_f1: 0.7141 - o2_f1: 0.7321 - o3_f1: 0.7225 - o4_f1: 0.7255 - o5_f1: 0.6859 - o6_f1: 0.6862 - val_loss: 250.3938 - val_o1_loss: 0.4238 - val_o2_loss: 0.3333 - val_o3_loss: 0.3494 - val_o4_loss: 0.3625 - val_o5_loss: 0.3870 - val_o6_loss: 0.4060 - val_o1_f1: 0.4316 - val_o2_f1: 0.5156 - val_o3_f1: 0.4789 - val_o4_f1: 0.4789 - val_o5_f1: 0.4573 - val_o6_f1: 0.4573\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 235.9449 - o1_loss: 0.3688 - o2_loss: 0.3128 - o3_loss: 0.3242 - o4_loss: 0.3395 - o5_loss: 0.3676 - o6_loss: 0.3819 - o1_f1: 0.7155 - o2_f1: 0.7221 - o3_f1: 0.7178 - o4_f1: 0.7073 - o5_f1: 0.6988 - o6_f1: 0.6897 - val_loss: 240.6765 - val_o1_loss: 0.4178 - val_o2_loss: 0.3313 - val_o3_loss: 0.3477 - val_o4_loss: 0.3573 - val_o5_loss: 0.3739 - val_o6_loss: 0.3872 - val_o1_f1: 0.3733 - val_o2_f1: 0.5051 - val_o3_f1: 0.4573 - val_o4_f1: 0.4686 - val_o5_f1: 0.4573 - val_o6_f1: 0.4573\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 227.0218 - o1_loss: 0.3643 - o2_loss: 0.3116 - o3_loss: 0.3220 - o4_loss: 0.3331 - o5_loss: 0.3552 - o6_loss: 0.3650 - o1_f1: 0.6675 - o2_f1: 0.7527 - o3_f1: 0.7510 - o4_f1: 0.7489 - o5_f1: 0.7302 - o6_f1: 0.7269 - val_loss: 249.7324 - val_o1_loss: 0.4352 - val_o2_loss: 0.3690 - val_o3_loss: 0.3814 - val_o4_loss: 0.3808 - val_o5_loss: 0.3852 - val_o6_loss: 0.3999 - val_o1_f1: 0.4808 - val_o2_f1: 0.4809 - val_o3_f1: 0.4753 - val_o4_f1: 0.4753 - val_o5_f1: 0.4807 - val_o6_f1: 0.4725\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 211.8693 - o1_loss: 0.3564 - o2_loss: 0.2954 - o3_loss: 0.3030 - o4_loss: 0.3124 - o5_loss: 0.3323 - o6_loss: 0.3396 - o1_f1: 0.7436 - o2_f1: 0.7878 - o3_f1: 0.7816 - o4_f1: 0.7706 - o5_f1: 0.7693 - o6_f1: 0.7641 - val_loss: 229.9680 - val_o1_loss: 0.4064 - val_o2_loss: 0.3203 - val_o3_loss: 0.3333 - val_o4_loss: 0.3446 - val_o5_loss: 0.3590 - val_o6_loss: 0.3683 - val_o1_f1: 0.5224 - val_o2_f1: 0.5061 - val_o3_f1: 0.5061 - val_o4_f1: 0.4959 - val_o5_f1: 0.4686 - val_o6_f1: 0.4686\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 201.6864 - o1_loss: 0.3444 - o2_loss: 0.2840 - o3_loss: 0.2904 - o4_loss: 0.2988 - o5_loss: 0.3171 - o6_loss: 0.3223 - o1_f1: 0.7546 - o2_f1: 0.7911 - o3_f1: 0.7926 - o4_f1: 0.7808 - o5_f1: 0.7745 - o6_f1: 0.7788 - val_loss: 236.9125 - val_o1_loss: 0.4116 - val_o2_loss: 0.3291 - val_o3_loss: 0.3410 - val_o4_loss: 0.3528 - val_o5_loss: 0.3681 - val_o6_loss: 0.3805 - val_o1_f1: 0.4897 - val_o2_f1: 0.4982 - val_o3_f1: 0.5244 - val_o4_f1: 0.5244 - val_o5_f1: 0.5070 - val_o6_f1: 0.4927\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 197.5588 - o1_loss: 0.3402 - o2_loss: 0.2825 - o3_loss: 0.2908 - o4_loss: 0.2966 - o5_loss: 0.3097 - o6_loss: 0.3149 - o1_f1: 0.7759 - o2_f1: 0.8056 - o3_f1: 0.8038 - o4_f1: 0.7971 - o5_f1: 0.7941 - o6_f1: 0.7912 - val_loss: 222.8616 - val_o1_loss: 0.3966 - val_o2_loss: 0.3142 - val_o3_loss: 0.3251 - val_o4_loss: 0.3358 - val_o5_loss: 0.3478 - val_o6_loss: 0.3562 - val_o1_f1: 0.5224 - val_o2_f1: 0.5061 - val_o3_f1: 0.5061 - val_o4_f1: 0.5061 - val_o5_f1: 0.4959 - val_o6_f1: 0.4959\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 181.6901 - o1_loss: 0.3282 - o2_loss: 0.2615 - o3_loss: 0.2648 - o4_loss: 0.2706 - o5_loss: 0.2855 - o6_loss: 0.2893 - o1_f1: 0.7839 - o2_f1: 0.8106 - o3_f1: 0.8054 - o4_f1: 0.8017 - o5_f1: 0.7965 - o6_f1: 0.7958 - val_loss: 228.3348 - val_o1_loss: 0.3980 - val_o2_loss: 0.3184 - val_o3_loss: 0.3273 - val_o4_loss: 0.3409 - val_o5_loss: 0.3568 - val_o6_loss: 0.3655 - val_o1_f1: 0.5046 - val_o2_f1: 0.5156 - val_o3_f1: 0.5156 - val_o4_f1: 0.5156 - val_o5_f1: 0.5156 - val_o6_f1: 0.4839\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 169.9829 - o1_loss: 0.3205 - o2_loss: 0.2504 - o3_loss: 0.2520 - o4_loss: 0.2555 - o5_loss: 0.2686 - o6_loss: 0.2690 - o1_f1: 0.7992 - o2_f1: 0.8165 - o3_f1: 0.8164 - o4_f1: 0.8188 - o5_f1: 0.8084 - o6_f1: 0.8169 - val_loss: 223.0844 - val_o1_loss: 0.3921 - val_o2_loss: 0.3122 - val_o3_loss: 0.3219 - val_o4_loss: 0.3347 - val_o5_loss: 0.3474 - val_o6_loss: 0.3569 - val_o1_f1: 0.4135 - val_o2_f1: 0.5154 - val_o3_f1: 0.5154 - val_o4_f1: 0.5061 - val_o5_f1: 0.5061 - val_o6_f1: 0.5061\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 159.9893 - o1_loss: 0.3163 - o2_loss: 0.2394 - o3_loss: 0.2391 - o4_loss: 0.2413 - o5_loss: 0.2526 - o6_loss: 0.2526 - o1_f1: 0.7712 - o2_f1: 0.8027 - o3_f1: 0.8229 - o4_f1: 0.8192 - o5_f1: 0.8265 - o6_f1: 0.8262 - val_loss: 249.1381 - val_o1_loss: 0.4021 - val_o2_loss: 0.3435 - val_o3_loss: 0.3552 - val_o4_loss: 0.3703 - val_o5_loss: 0.3804 - val_o6_loss: 0.4026 - val_o1_f1: 0.4808 - val_o2_f1: 0.4927 - val_o3_f1: 0.4809 - val_o4_f1: 0.4809 - val_o5_f1: 0.4809 - val_o6_f1: 0.4807\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 163.9208 - o1_loss: 0.3146 - o2_loss: 0.2455 - o3_loss: 0.2469 - o4_loss: 0.2485 - o5_loss: 0.2573 - o6_loss: 0.2591 - o1_f1: 0.7760 - o2_f1: 0.8222 - o3_f1: 0.8243 - o4_f1: 0.8239 - o5_f1: 0.8154 - o6_f1: 0.8238 - val_loss: 245.7699 - val_o1_loss: 0.3978 - val_o2_loss: 0.3441 - val_o3_loss: 0.3527 - val_o4_loss: 0.3651 - val_o5_loss: 0.3749 - val_o6_loss: 0.3970 - val_o1_f1: 0.4808 - val_o2_f1: 0.4927 - val_o3_f1: 0.4809 - val_o4_f1: 0.4809 - val_o5_f1: 0.4809 - val_o6_f1: 0.4809\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 146.5794 - o1_loss: 0.3043 - o2_loss: 0.2255 - o3_loss: 0.2226 - o4_loss: 0.2224 - o5_loss: 0.2312 - o6_loss: 0.2304 - o1_f1: 0.7982 - o2_f1: 0.8287 - o3_f1: 0.8373 - o4_f1: 0.8366 - o5_f1: 0.8313 - o6_f1: 0.8435 - val_loss: 221.0788 - val_o1_loss: 0.3796 - val_o2_loss: 0.3111 - val_o3_loss: 0.3197 - val_o4_loss: 0.3322 - val_o5_loss: 0.3443 - val_o6_loss: 0.3532 - val_o1_f1: 0.5006 - val_o2_f1: 0.5249 - val_o3_f1: 0.5154 - val_o4_f1: 0.5154 - val_o5_f1: 0.5061 - val_o6_f1: 0.5156\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 137.9210 - o1_loss: 0.3010 - o2_loss: 0.2174 - o3_loss: 0.2132 - o4_loss: 0.2113 - o5_loss: 0.2184 - o6_loss: 0.2155 - o1_f1: 0.8176 - o2_f1: 0.8582 - o3_f1: 0.8614 - o4_f1: 0.8642 - o5_f1: 0.8664 - o6_f1: 0.8680 - val_loss: 224.3083 - val_o1_loss: 0.3796 - val_o2_loss: 0.3109 - val_o3_loss: 0.3183 - val_o4_loss: 0.3322 - val_o5_loss: 0.3483 - val_o6_loss: 0.3597 - val_o1_f1: 0.5224 - val_o2_f1: 0.5249 - val_o3_f1: 0.5249 - val_o4_f1: 0.5156 - val_o5_f1: 0.5156 - val_o6_f1: 0.4982\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 135.9429 - o1_loss: 0.2980 - o2_loss: 0.2154 - o3_loss: 0.2117 - o4_loss: 0.2099 - o5_loss: 0.2140 - o6_loss: 0.2123 - o1_f1: 0.8089 - o2_f1: 0.8635 - o3_f1: 0.8609 - o4_f1: 0.8575 - o5_f1: 0.8642 - o6_f1: 0.8670 - val_loss: 222.4669 - val_o1_loss: 0.3760 - val_o2_loss: 0.3111 - val_o3_loss: 0.3182 - val_o4_loss: 0.3302 - val_o5_loss: 0.3444 - val_o6_loss: 0.3567 - val_o1_f1: 0.5006 - val_o2_f1: 0.5249 - val_o3_f1: 0.5249 - val_o4_f1: 0.5156 - val_o5_f1: 0.5156 - val_o6_f1: 0.4982\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 122.5696 - o1_loss: 0.2900 - o2_loss: 0.2012 - o3_loss: 0.1939 - o4_loss: 0.1893 - o5_loss: 0.1942 - o6_loss: 0.1900 - o1_f1: 0.8423 - o2_f1: 0.8887 - o3_f1: 0.8991 - o4_f1: 0.8900 - o5_f1: 0.8872 - o6_f1: 0.8869 - val_loss: 234.3156 - val_o1_loss: 0.3728 - val_o2_loss: 0.3167 - val_o3_loss: 0.3244 - val_o4_loss: 0.3409 - val_o5_loss: 0.3615 - val_o6_loss: 0.3780 - val_o1_f1: 0.5006 - val_o2_f1: 0.4839 - val_o3_f1: 0.4982 - val_o4_f1: 0.5070 - val_o5_f1: 0.4927 - val_o6_f1: 0.4927\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 3s - loss: 116.0938 - o1_loss: 0.2885 - o2_loss: 0.1942 - o3_loss: 0.1858 - o4_loss: 0.1800 - o5_loss: 0.1838 - o6_loss: 0.1794 - o1_f1: 0.8326 - o2_f1: 0.8739 - o3_f1: 0.8799 - o4_f1: 0.8894 - o5_f1: 0.8897 - o6_f1: 0.8952 - val_loss: 236.3010 - val_o1_loss: 0.3720 - val_o2_loss: 0.3182 - val_o3_loss: 0.3262 - val_o4_loss: 0.3423 - val_o5_loss: 0.3613 - val_o6_loss: 0.3826 - val_o1_f1: 0.5006 - val_o2_f1: 0.4839 - val_o3_f1: 0.5070 - val_o4_f1: 0.5070 - val_o5_f1: 0.4927 - val_o6_f1: 0.4927\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 108.4098 - o1_loss: 0.2829 - o2_loss: 0.1854 - o3_loss: 0.1756 - o4_loss: 0.1689 - o5_loss: 0.1714 - o6_loss: 0.1668 - o1_f1: 0.8365 - o2_f1: 0.8964 - o3_f1: 0.9094 - o4_f1: 0.9115 - o5_f1: 0.9127 - o6_f1: 0.9093 - val_loss: 231.1287 - val_o1_loss: 0.3690 - val_o2_loss: 0.3164 - val_o3_loss: 0.3282 - val_o4_loss: 0.3442 - val_o5_loss: 0.3593 - val_o6_loss: 0.3699 - val_o1_f1: 0.4810 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5154 - val_o5_f1: 0.5154 - val_o6_f1: 0.5249\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 104.3298 - o1_loss: 0.2792 - o2_loss: 0.1810 - o3_loss: 0.1699 - o4_loss: 0.1621 - o5_loss: 0.1642 - o6_loss: 0.1604 - o1_f1: 0.8236 - o2_f1: 0.8945 - o3_f1: 0.8986 - o4_f1: 0.9073 - o5_f1: 0.8992 - o6_f1: 0.9022 - val_loss: 224.6915 - val_o1_loss: 0.3659 - val_o2_loss: 0.3200 - val_o3_loss: 0.3341 - val_o4_loss: 0.3459 - val_o5_loss: 0.3529 - val_o6_loss: 0.3555 - val_o1_f1: 0.5006 - val_o2_f1: 0.5039 - val_o3_f1: 0.5039 - val_o4_f1: 0.5039 - val_o5_f1: 0.5154 - val_o6_f1: 0.5154\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 97.6329 - o1_loss: 0.2759 - o2_loss: 0.1749 - o3_loss: 0.1621 - o4_loss: 0.1529 - o5_loss: 0.1544 - o6_loss: 0.1489 - o1_f1: 0.8569 - o2_f1: 0.9071 - o3_f1: 0.9105 - o4_f1: 0.9176 - o5_f1: 0.9191 - o6_f1: 0.9199 - val_loss: 227.7295 - val_o1_loss: 0.3648 - val_o2_loss: 0.3109 - val_o3_loss: 0.3193 - val_o4_loss: 0.3341 - val_o5_loss: 0.3523 - val_o6_loss: 0.3657 - val_o1_f1: 0.5006 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5249 - val_o5_f1: 0.5075 - val_o6_f1: 0.5075\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 90.9596 - o1_loss: 0.2710 - o2_loss: 0.1662 - o3_loss: 0.1525 - o4_loss: 0.1423 - o5_loss: 0.1433 - o6_loss: 0.1383 - o1_f1: 0.8460 - o2_f1: 0.9015 - o3_f1: 0.9099 - o4_f1: 0.9201 - o5_f1: 0.9168 - o6_f1: 0.9196 - val_loss: 236.0329 - val_o1_loss: 0.3670 - val_o2_loss: 0.3158 - val_o3_loss: 0.3243 - val_o4_loss: 0.3407 - val_o5_loss: 0.3599 - val_o6_loss: 0.3823 - val_o1_f1: 0.4960 - val_o2_f1: 0.5075 - val_o3_f1: 0.5075 - val_o4_f1: 0.4982 - val_o5_f1: 0.4982 - val_o6_f1: 0.4839\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 89.5032 - o1_loss: 0.2681 - o2_loss: 0.1632 - o3_loss: 0.1496 - o4_loss: 0.1400 - o5_loss: 0.1402 - o6_loss: 0.1362 - o1_f1: 0.8508 - o2_f1: 0.9169 - o3_f1: 0.9207 - o4_f1: 0.9260 - o5_f1: 0.9241 - o6_f1: 0.9271 - val_loss: 238.0923 - val_o1_loss: 0.3603 - val_o2_loss: 0.3203 - val_o3_loss: 0.3392 - val_o4_loss: 0.3613 - val_o5_loss: 0.3740 - val_o6_loss: 0.3785 - val_o1_f1: 0.5006 - val_o2_f1: 0.5134 - val_o3_f1: 0.5039 - val_o4_f1: 0.5039 - val_o5_f1: 0.5154 - val_o6_f1: 0.5249\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 82.3177 - o1_loss: 0.2651 - o2_loss: 0.1566 - o3_loss: 0.1411 - o4_loss: 0.1305 - o5_loss: 0.1298 - o6_loss: 0.1238 - o1_f1: 0.8580 - o2_f1: 0.9157 - o3_f1: 0.9225 - o4_f1: 0.9317 - o5_f1: 0.9295 - o6_f1: 0.9318 - val_loss: 234.1449 - val_o1_loss: 0.3583 - val_o2_loss: 0.3161 - val_o3_loss: 0.3320 - val_o4_loss: 0.3526 - val_o5_loss: 0.3653 - val_o6_loss: 0.3733 - val_o1_f1: 0.5006 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5249 - val_o6_f1: 0.5075\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 78.6865 - o1_loss: 0.2640 - o2_loss: 0.1537 - o3_loss: 0.1373 - o4_loss: 0.1250 - o5_loss: 0.1236 - o6_loss: 0.1178 - o1_f1: 0.8529 - o2_f1: 0.9252 - o3_f1: 0.9365 - o4_f1: 0.9409 - o5_f1: 0.9428 - o6_f1: 0.9444 - val_loss: 236.8370 - val_o1_loss: 0.3577 - val_o2_loss: 0.3137 - val_o3_loss: 0.3263 - val_o4_loss: 0.3455 - val_o5_loss: 0.3634 - val_o6_loss: 0.3819 - val_o1_f1: 0.5134 - val_o2_f1: 0.4960 - val_o3_f1: 0.5134 - val_o4_f1: 0.5249 - val_o5_f1: 0.5075 - val_o6_f1: 0.5075\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 72.4947 - o1_loss: 0.2609 - o2_loss: 0.1459 - o3_loss: 0.1278 - o4_loss: 0.1150 - o5_loss: 0.1133 - o6_loss: 0.1080 - o1_f1: 0.8402 - o2_f1: 0.9270 - o3_f1: 0.9397 - o4_f1: 0.9454 - o5_f1: 0.9390 - o6_f1: 0.9383 - val_loss: 240.4117 - val_o1_loss: 0.3569 - val_o2_loss: 0.3147 - val_o3_loss: 0.3274 - val_o4_loss: 0.3473 - val_o5_loss: 0.3656 - val_o6_loss: 0.3896 - val_o1_f1: 0.5134 - val_o2_f1: 0.4960 - val_o3_f1: 0.4960 - val_o4_f1: 0.5075 - val_o5_f1: 0.5075 - val_o6_f1: 0.4932\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 66.8016 - o1_loss: 0.2578 - o2_loss: 0.1408 - o3_loss: 0.1213 - o4_loss: 0.1072 - o5_loss: 0.1045 - o6_loss: 0.0984 - o1_f1: 0.8540 - o2_f1: 0.9340 - o3_f1: 0.9498 - o4_f1: 0.9551 - o5_f1: 0.9489 - o6_f1: 0.9523 - val_loss: 244.0949 - val_o1_loss: 0.3583 - val_o2_loss: 0.3152 - val_o3_loss: 0.3289 - val_o4_loss: 0.3501 - val_o5_loss: 0.3686 - val_o6_loss: 0.3971 - val_o1_f1: 0.4960 - val_o2_f1: 0.4960 - val_o3_f1: 0.4960 - val_o4_f1: 0.5075 - val_o5_f1: 0.4982 - val_o6_f1: 0.5047\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 62.3765 - o1_loss: 0.2552 - o2_loss: 0.1369 - o3_loss: 0.1164 - o4_loss: 0.1020 - o5_loss: 0.0979 - o6_loss: 0.0907 - o1_f1: 0.8848 - o2_f1: 0.9478 - o3_f1: 0.9548 - o4_f1: 0.9606 - o5_f1: 0.9637 - o6_f1: 0.9621 - val_loss: 243.2404 - val_o1_loss: 0.3522 - val_o2_loss: 0.3123 - val_o3_loss: 0.3297 - val_o4_loss: 0.3543 - val_o5_loss: 0.3725 - val_o6_loss: 0.3929 - val_o1_f1: 0.5134 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5249 - val_o6_f1: 0.5075\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 66.4234 - o1_loss: 0.2548 - o2_loss: 0.1378 - o3_loss: 0.1189 - o4_loss: 0.1067 - o5_loss: 0.1028 - o6_loss: 0.0981 - o1_f1: 0.8588 - o2_f1: 0.9246 - o3_f1: 0.9365 - o4_f1: 0.9407 - o5_f1: 0.9532 - o6_f1: 0.9532 - val_loss: 244.6613 - val_o1_loss: 0.3526 - val_o2_loss: 0.3128 - val_o3_loss: 0.3302 - val_o4_loss: 0.3562 - val_o5_loss: 0.3744 - val_o6_loss: 0.3954 - val_o1_f1: 0.4960 - val_o2_f1: 0.4960 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5075 - val_o6_f1: 0.5075\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 61.5917 - o1_loss: 0.2505 - o2_loss: 0.1326 - o3_loss: 0.1128 - o4_loss: 0.0996 - o5_loss: 0.0953 - o6_loss: 0.0901 - o1_f1: 0.8777 - o2_f1: 0.9503 - o3_f1: 0.9563 - o4_f1: 0.9642 - o5_f1: 0.9642 - o6_f1: 0.9620 - val_loss: 251.5108 - val_o1_loss: 0.3545 - val_o2_loss: 0.3155 - val_o3_loss: 0.3336 - val_o4_loss: 0.3599 - val_o5_loss: 0.3783 - val_o6_loss: 0.4103 - val_o1_f1: 0.5174 - val_o2_f1: 0.4960 - val_o3_f1: 0.4960 - val_o4_f1: 0.5075 - val_o5_f1: 0.5075 - val_o6_f1: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 54.0512 - o1_loss: 0.2490 - o2_loss: 0.1253 - o3_loss: 0.1021 - o4_loss: 0.0870 - o5_loss: 0.0835 - o6_loss: 0.0779 - o1_f1: 0.8651 - o2_f1: 0.9410 - o3_f1: 0.9532 - o4_f1: 0.9584 - o5_f1: 0.9612 - o6_f1: 0.9595 - val_loss: 253.7952 - val_o1_loss: 0.3487 - val_o2_loss: 0.3127 - val_o3_loss: 0.3323 - val_o4_loss: 0.3616 - val_o5_loss: 0.3827 - val_o6_loss: 0.4141 - val_o1_f1: 0.5134 - val_o2_f1: 0.4960 - val_o3_f1: 0.4960 - val_o4_f1: 0.5134 - val_o5_f1: 0.5075 - val_o6_f1: 0.5289\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 51.0554 - o1_loss: 0.2471 - o2_loss: 0.1203 - o3_loss: 0.0965 - o4_loss: 0.0819 - o5_loss: 0.0782 - o6_loss: 0.0733 - o1_f1: 0.8558 - o2_f1: 0.9536 - o3_f1: 0.9620 - o4_f1: 0.9706 - o5_f1: 0.9706 - o6_f1: 0.9687 - val_loss: 249.4137 - val_o1_loss: 0.3496 - val_o2_loss: 0.3118 - val_o3_loss: 0.3332 - val_o4_loss: 0.3621 - val_o5_loss: 0.3789 - val_o6_loss: 0.4044 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5075 - val_o6_f1: 0.5075\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 48.2896 - o1_loss: 0.2465 - o2_loss: 0.1190 - o3_loss: 0.0943 - o4_loss: 0.0782 - o5_loss: 0.0740 - o6_loss: 0.0685 - o1_f1: 0.8737 - o2_f1: 0.9565 - o3_f1: 0.9624 - o4_f1: 0.9674 - o5_f1: 0.9685 - o6_f1: 0.9685 - val_loss: 260.5023 - val_o1_loss: 0.3495 - val_o2_loss: 0.3138 - val_o3_loss: 0.3360 - val_o4_loss: 0.3671 - val_o5_loss: 0.3865 - val_o6_loss: 0.4283 - val_o1_f1: 0.4960 - val_o2_f1: 0.4960 - val_o3_f1: 0.4960 - val_o4_f1: 0.5289 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 53.8259 - o1_loss: 0.2461 - o2_loss: 0.1211 - o3_loss: 0.0996 - o4_loss: 0.0870 - o5_loss: 0.0822 - o6_loss: 0.0777 - o1_f1: 0.8832 - o2_f1: 0.9626 - o3_f1: 0.9718 - o4_f1: 0.9731 - o5_f1: 0.9700 - o6_f1: 0.9665 - val_loss: 285.8374 - val_o1_loss: 0.3455 - val_o2_loss: 0.3355 - val_o3_loss: 0.3889 - val_o4_loss: 0.4457 - val_o5_loss: 0.4566 - val_o6_loss: 0.4520 - val_o1_f1: 0.5134 - val_o2_f1: 0.5039 - val_o3_f1: 0.5039 - val_o4_f1: 0.5039 - val_o5_f1: 0.5039 - val_o6_f1: 0.5039\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 50.4168 - o1_loss: 0.2426 - o2_loss: 0.1184 - o3_loss: 0.0955 - o4_loss: 0.0811 - o5_loss: 0.0762 - o6_loss: 0.0724 - o1_f1: 0.8731 - o2_f1: 0.9522 - o3_f1: 0.9543 - o4_f1: 0.9553 - o5_f1: 0.9572 - o6_f1: 0.9572 - val_loss: 246.2166 - val_o1_loss: 0.3472 - val_o2_loss: 0.3113 - val_o3_loss: 0.3353 - val_o4_loss: 0.3659 - val_o5_loss: 0.3768 - val_o6_loss: 0.3963 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5289\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 44.3744 - o1_loss: 0.2421 - o2_loss: 0.1119 - o3_loss: 0.0867 - o4_loss: 0.0713 - o5_loss: 0.0669 - o6_loss: 0.0625 - o1_f1: 0.8879 - o2_f1: 0.9558 - o3_f1: 0.9664 - o4_f1: 0.9739 - o5_f1: 0.9775 - o6_f1: 0.9775 - val_loss: 264.1589 - val_o1_loss: 0.3432 - val_o2_loss: 0.3139 - val_o3_loss: 0.3471 - val_o4_loss: 0.3893 - val_o5_loss: 0.4090 - val_o6_loss: 0.4254 - val_o1_f1: 0.5134 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5134 - val_o6_f1: 0.5134\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      " - 2s - loss: 42.9226 - o1_loss: 0.2404 - o2_loss: 0.1097 - o3_loss: 0.0839 - o4_loss: 0.0685 - o5_loss: 0.0641 - o6_loss: 0.0604 - o1_f1: 0.8969 - o2_f1: 0.9650 - o3_f1: 0.9684 - o4_f1: 0.9725 - o5_f1: 0.9742 - o6_f1: 0.9775 - val_loss: 258.5020 - val_o1_loss: 0.3418 - val_o2_loss: 0.3089 - val_o3_loss: 0.3360 - val_o4_loss: 0.3720 - val_o5_loss: 0.3896 - val_o6_loss: 0.4213 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 38.4563 - o1_loss: 0.2379 - o2_loss: 0.1065 - o3_loss: 0.0797 - o4_loss: 0.0632 - o5_loss: 0.0576 - o6_loss: 0.0526 - o1_f1: 0.8716 - o2_f1: 0.9657 - o3_f1: 0.9760 - o4_f1: 0.9794 - o5_f1: 0.9811 - o6_f1: 0.9853 - val_loss: 267.8526 - val_o1_loss: 0.3430 - val_o2_loss: 0.3116 - val_o3_loss: 0.3392 - val_o4_loss: 0.3765 - val_o5_loss: 0.3962 - val_o6_loss: 0.4414 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.4960 - val_o4_f1: 0.5289 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 38.4086 - o1_loss: 0.2368 - o2_loss: 0.1051 - o3_loss: 0.0784 - o4_loss: 0.0624 - o5_loss: 0.0573 - o6_loss: 0.0528 - o1_f1: 0.8938 - o2_f1: 0.9683 - o3_f1: 0.9718 - o4_f1: 0.9754 - o5_f1: 0.9776 - o6_f1: 0.9810 - val_loss: 262.5240 - val_o1_loss: 0.3433 - val_o2_loss: 0.3098 - val_o3_loss: 0.3370 - val_o4_loss: 0.3734 - val_o5_loss: 0.3912 - val_o6_loss: 0.4305 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5289\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 37.6183 - o1_loss: 0.2369 - o2_loss: 0.1049 - o3_loss: 0.0777 - o4_loss: 0.0614 - o5_loss: 0.0560 - o6_loss: 0.0514 - o1_f1: 0.8923 - o2_f1: 0.9657 - o3_f1: 0.9741 - o4_f1: 0.9754 - o5_f1: 0.9820 - o6_f1: 0.9836 - val_loss: 259.5005 - val_o1_loss: 0.3424 - val_o2_loss: 0.3087 - val_o3_loss: 0.3363 - val_o4_loss: 0.3726 - val_o5_loss: 0.3894 - val_o6_loss: 0.4237 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5289\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 37.4087 - o1_loss: 0.2363 - o2_loss: 0.1036 - o3_loss: 0.0766 - o4_loss: 0.0606 - o5_loss: 0.0557 - o6_loss: 0.0512 - o1_f1: 0.8772 - o2_f1: 0.9652 - o3_f1: 0.9714 - o4_f1: 0.9765 - o5_f1: 0.9769 - o6_f1: 0.9784 - val_loss: 260.2204 - val_o1_loss: 0.3418 - val_o2_loss: 0.3086 - val_o3_loss: 0.3366 - val_o4_loss: 0.3731 - val_o5_loss: 0.3900 - val_o6_loss: 0.4252 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5289\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 37.6613 - o1_loss: 0.2363 - o2_loss: 0.1042 - o3_loss: 0.0773 - o4_loss: 0.0613 - o5_loss: 0.0559 - o6_loss: 0.0516 - o1_f1: 0.8912 - o2_f1: 0.9652 - o3_f1: 0.9709 - o4_f1: 0.9786 - o5_f1: 0.9814 - o6_f1: 0.9814 - val_loss: 259.9421 - val_o1_loss: 0.3422 - val_o2_loss: 0.3086 - val_o3_loss: 0.3373 - val_o4_loss: 0.3747 - val_o5_loss: 0.3915 - val_o6_loss: 0.4237 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 36.4966 - o1_loss: 0.2360 - o2_loss: 0.1031 - o3_loss: 0.0759 - o4_loss: 0.0597 - o5_loss: 0.0542 - o6_loss: 0.0496 - o1_f1: 0.9058 - o2_f1: 0.9722 - o3_f1: 0.9758 - o4_f1: 0.9791 - o5_f1: 0.9808 - o6_f1: 0.9808 - val_loss: 262.0042 - val_o1_loss: 0.3420 - val_o2_loss: 0.3088 - val_o3_loss: 0.3375 - val_o4_loss: 0.3755 - val_o5_loss: 0.3931 - val_o6_loss: 0.4281 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 36.0995 - o1_loss: 0.2359 - o2_loss: 0.1027 - o3_loss: 0.0754 - o4_loss: 0.0591 - o5_loss: 0.0535 - o6_loss: 0.0489 - o1_f1: 0.8779 - o2_f1: 0.9663 - o3_f1: 0.9704 - o4_f1: 0.9762 - o5_f1: 0.9798 - o6_f1: 0.9829 - val_loss: 265.5144 - val_o1_loss: 0.3419 - val_o2_loss: 0.3099 - val_o3_loss: 0.3390 - val_o4_loss: 0.3774 - val_o5_loss: 0.3952 - val_o6_loss: 0.4357 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 36.0317 - o1_loss: 0.2354 - o2_loss: 0.1025 - o3_loss: 0.0752 - o4_loss: 0.0590 - o5_loss: 0.0535 - o6_loss: 0.0488 - o1_f1: 0.8941 - o2_f1: 0.9675 - o3_f1: 0.9753 - o4_f1: 0.9753 - o5_f1: 0.9753 - o6_f1: 0.9806 - val_loss: 267.2174 - val_o1_loss: 0.3422 - val_o2_loss: 0.3103 - val_o3_loss: 0.3397 - val_o4_loss: 0.3787 - val_o5_loss: 0.3968 - val_o6_loss: 0.4391 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 35.2863 - o1_loss: 0.2354 - o2_loss: 0.1018 - o3_loss: 0.0743 - o4_loss: 0.0580 - o5_loss: 0.0523 - o6_loss: 0.0475 - o1_f1: 0.9028 - o2_f1: 0.9708 - o3_f1: 0.9727 - o4_f1: 0.9799 - o5_f1: 0.9825 - o6_f1: 0.9852 - val_loss: 266.7160 - val_o1_loss: 0.3422 - val_o2_loss: 0.3105 - val_o3_loss: 0.3402 - val_o4_loss: 0.3791 - val_o5_loss: 0.3965 - val_o6_loss: 0.4379 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 34.4678 - o1_loss: 0.2344 - o2_loss: 0.1003 - o3_loss: 0.0727 - o4_loss: 0.0566 - o5_loss: 0.0509 - o6_loss: 0.0463 - o1_f1: 0.8882 - o2_f1: 0.9678 - o3_f1: 0.9720 - o4_f1: 0.9755 - o5_f1: 0.9758 - o6_f1: 0.9804 - val_loss: 264.0781 - val_o1_loss: 0.3407 - val_o2_loss: 0.3088 - val_o3_loss: 0.3390 - val_o4_loss: 0.3782 - val_o5_loss: 0.3955 - val_o6_loss: 0.4319 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 34.1673 - o1_loss: 0.2344 - o2_loss: 0.1003 - o3_loss: 0.0725 - o4_loss: 0.0560 - o5_loss: 0.0502 - o6_loss: 0.0458 - o1_f1: 0.8906 - o2_f1: 0.9725 - o3_f1: 0.9802 - o4_f1: 0.9808 - o5_f1: 0.9844 - o6_f1: 0.9858 - val_loss: 267.0696 - val_o1_loss: 0.3412 - val_o2_loss: 0.3097 - val_o3_loss: 0.3401 - val_o4_loss: 0.3798 - val_o5_loss: 0.3976 - val_o6_loss: 0.4383 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5377\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 34.3369 - o1_loss: 0.2345 - o2_loss: 0.1001 - o3_loss: 0.0724 - o4_loss: 0.0562 - o5_loss: 0.0505 - o6_loss: 0.0461 - o1_f1: 0.8856 - o2_f1: 0.9644 - o3_f1: 0.9759 - o4_f1: 0.9800 - o5_f1: 0.9815 - o6_f1: 0.9815 - val_loss: 263.1956 - val_o1_loss: 0.3400 - val_o2_loss: 0.3089 - val_o3_loss: 0.3409 - val_o4_loss: 0.3816 - val_o5_loss: 0.3982 - val_o6_loss: 0.4281 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 34.7731 - o1_loss: 0.2345 - o2_loss: 0.1007 - o3_loss: 0.0732 - o4_loss: 0.0571 - o5_loss: 0.0514 - o6_loss: 0.0467 - o1_f1: 0.8804 - o2_f1: 0.9642 - o3_f1: 0.9680 - o4_f1: 0.9765 - o5_f1: 0.9765 - o6_f1: 0.9809 - val_loss: 268.5120 - val_o1_loss: 0.3408 - val_o2_loss: 0.3101 - val_o3_loss: 0.3413 - val_o4_loss: 0.3818 - val_o5_loss: 0.3997 - val_o6_loss: 0.4407 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 35.4063 - o1_loss: 0.2351 - o2_loss: 0.1011 - o3_loss: 0.0738 - o4_loss: 0.0580 - o5_loss: 0.0525 - o6_loss: 0.0477 - o1_f1: 0.8879 - o2_f1: 0.9731 - o3_f1: 0.9823 - o4_f1: 0.9823 - o5_f1: 0.9838 - o6_f1: 0.9848 - val_loss: 272.3743 - val_o1_loss: 0.3416 - val_o2_loss: 0.3117 - val_o3_loss: 0.3438 - val_o4_loss: 0.3850 - val_o5_loss: 0.4035 - val_o6_loss: 0.4484 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 33.5422 - o1_loss: 0.2338 - o2_loss: 0.0988 - o3_loss: 0.0708 - o4_loss: 0.0548 - o5_loss: 0.0492 - o6_loss: 0.0448 - o1_f1: 0.9031 - o2_f1: 0.9785 - o3_f1: 0.9822 - o4_f1: 0.9845 - o5_f1: 0.9847 - o6_f1: 0.9847 - val_loss: 268.1415 - val_o1_loss: 0.3412 - val_o2_loss: 0.3104 - val_o3_loss: 0.3421 - val_o4_loss: 0.3827 - val_o5_loss: 0.3997 - val_o6_loss: 0.4396 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 33.1087 - o1_loss: 0.2337 - o2_loss: 0.0984 - o3_loss: 0.0703 - o4_loss: 0.0541 - o5_loss: 0.0485 - o6_loss: 0.0441 - o1_f1: 0.8940 - o2_f1: 0.9721 - o3_f1: 0.9807 - o4_f1: 0.9821 - o5_f1: 0.9834 - o6_f1: 0.9853 - val_loss: 269.4080 - val_o1_loss: 0.3401 - val_o2_loss: 0.3099 - val_o3_loss: 0.3422 - val_o4_loss: 0.3838 - val_o5_loss: 0.4016 - val_o6_loss: 0.4419 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5377\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 33.0354 - o1_loss: 0.2332 - o2_loss: 0.0980 - o3_loss: 0.0701 - o4_loss: 0.0540 - o5_loss: 0.0483 - o6_loss: 0.0440 - o1_f1: 0.8870 - o2_f1: 0.9664 - o3_f1: 0.9772 - o4_f1: 0.9791 - o5_f1: 0.9827 - o6_f1: 0.9827 - val_loss: 264.3561 - val_o1_loss: 0.3395 - val_o2_loss: 0.3089 - val_o3_loss: 0.3423 - val_o4_loss: 0.3842 - val_o5_loss: 0.3997 - val_o6_loss: 0.4299 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 32.9688 - o1_loss: 0.2332 - o2_loss: 0.0974 - o3_loss: 0.0693 - o4_loss: 0.0535 - o5_loss: 0.0481 - o6_loss: 0.0440 - o1_f1: 0.8821 - o2_f1: 0.9645 - o3_f1: 0.9750 - o4_f1: 0.9790 - o5_f1: 0.9823 - o6_f1: 0.9836 - val_loss: 269.8813 - val_o1_loss: 0.3395 - val_o2_loss: 0.3095 - val_o3_loss: 0.3423 - val_o4_loss: 0.3844 - val_o5_loss: 0.4022 - val_o6_loss: 0.4427 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5377\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 32.3079 - o1_loss: 0.2327 - o2_loss: 0.0963 - o3_loss: 0.0683 - o4_loss: 0.0525 - o5_loss: 0.0470 - o6_loss: 0.0430 - o1_f1: 0.8991 - o2_f1: 0.9696 - o3_f1: 0.9770 - o4_f1: 0.9805 - o5_f1: 0.9878 - o6_f1: 0.9878 - val_loss: 266.4451 - val_o1_loss: 0.3388 - val_o2_loss: 0.3094 - val_o3_loss: 0.3451 - val_o4_loss: 0.3893 - val_o5_loss: 0.4054 - val_o6_loss: 0.4321 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5134 - val_o6_f1: 0.5174\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 33.0245 - o1_loss: 0.2321 - o2_loss: 0.0967 - o3_loss: 0.0692 - o4_loss: 0.0537 - o5_loss: 0.0482 - o6_loss: 0.0441 - o1_f1: 0.8975 - o2_f1: 0.9669 - o3_f1: 0.9735 - o4_f1: 0.9771 - o5_f1: 0.9810 - o6_f1: 0.9810 - val_loss: 266.5824 - val_o1_loss: 0.3382 - val_o2_loss: 0.3088 - val_o3_loss: 0.3434 - val_o4_loss: 0.3866 - val_o5_loss: 0.4027 - val_o6_loss: 0.4339 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 31.3058 - o1_loss: 0.2322 - o2_loss: 0.0955 - o3_loss: 0.0670 - o4_loss: 0.0509 - o5_loss: 0.0453 - o6_loss: 0.0414 - o1_f1: 0.8811 - o2_f1: 0.9700 - o3_f1: 0.9763 - o4_f1: 0.9798 - o5_f1: 0.9839 - o6_f1: 0.9839 - val_loss: 279.6573 - val_o1_loss: 0.3396 - val_o2_loss: 0.3123 - val_o3_loss: 0.3475 - val_o4_loss: 0.3926 - val_o5_loss: 0.4125 - val_o6_loss: 0.4619 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5440 - val_o4_f1: 0.5289 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 31.1618 - o1_loss: 0.2315 - o2_loss: 0.0952 - o3_loss: 0.0667 - o4_loss: 0.0507 - o5_loss: 0.0453 - o6_loss: 0.0410 - o1_f1: 0.8851 - o2_f1: 0.9611 - o3_f1: 0.9688 - o4_f1: 0.9779 - o5_f1: 0.9814 - o6_f1: 0.9814 - val_loss: 270.4617 - val_o1_loss: 0.3388 - val_o2_loss: 0.3093 - val_o3_loss: 0.3435 - val_o4_loss: 0.3863 - val_o5_loss: 0.4034 - val_o6_loss: 0.4433 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 30.8131 - o1_loss: 0.2312 - o2_loss: 0.0945 - o3_loss: 0.0660 - o4_loss: 0.0502 - o5_loss: 0.0445 - o6_loss: 0.0405 - o1_f1: 0.8919 - o2_f1: 0.9705 - o3_f1: 0.9789 - o4_f1: 0.9810 - o5_f1: 0.9871 - o6_f1: 0.9871 - val_loss: 273.4187 - val_o1_loss: 0.3387 - val_o2_loss: 0.3103 - val_o3_loss: 0.3451 - val_o4_loss: 0.3885 - val_o5_loss: 0.4059 - val_o6_loss: 0.4494 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 30.5845 - o1_loss: 0.2316 - o2_loss: 0.0943 - o3_loss: 0.0656 - o4_loss: 0.0497 - o5_loss: 0.0441 - o6_loss: 0.0402 - o1_f1: 0.8919 - o2_f1: 0.9643 - o3_f1: 0.9738 - o4_f1: 0.9834 - o5_f1: 0.9840 - o6_f1: 0.9836 - val_loss: 267.4377 - val_o1_loss: 0.3375 - val_o2_loss: 0.3087 - val_o3_loss: 0.3446 - val_o4_loss: 0.3888 - val_o5_loss: 0.4042 - val_o6_loss: 0.4351 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 30.6116 - o1_loss: 0.2308 - o2_loss: 0.0939 - o3_loss: 0.0654 - o4_loss: 0.0497 - o5_loss: 0.0441 - o6_loss: 0.0403 - o1_f1: 0.8863 - o2_f1: 0.9709 - o3_f1: 0.9786 - o4_f1: 0.9786 - o5_f1: 0.9794 - o6_f1: 0.9829 - val_loss: 271.7956 - val_o1_loss: 0.3381 - val_o2_loss: 0.3095 - val_o3_loss: 0.3449 - val_o4_loss: 0.3891 - val_o5_loss: 0.4057 - val_o6_loss: 0.4453 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5377\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 30.7066 - o1_loss: 0.2311 - o2_loss: 0.0939 - o3_loss: 0.0656 - o4_loss: 0.0501 - o5_loss: 0.0444 - o6_loss: 0.0403 - o1_f1: 0.9017 - o2_f1: 0.9739 - o3_f1: 0.9866 - o4_f1: 0.9866 - o5_f1: 0.9868 - o6_f1: 0.9868 - val_loss: 267.3754 - val_o1_loss: 0.3373 - val_o2_loss: 0.3091 - val_o3_loss: 0.3462 - val_o4_loss: 0.3913 - val_o5_loss: 0.4057 - val_o6_loss: 0.4339 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 30.6419 - o1_loss: 0.2302 - o2_loss: 0.0922 - o3_loss: 0.0641 - o4_loss: 0.0490 - o5_loss: 0.0440 - o6_loss: 0.0405 - o1_f1: 0.8874 - o2_f1: 0.9665 - o3_f1: 0.9818 - o4_f1: 0.9861 - o5_f1: 0.9847 - o6_f1: 0.9860 - val_loss: 271.3168 - val_o1_loss: 0.3372 - val_o2_loss: 0.3092 - val_o3_loss: 0.3455 - val_o4_loss: 0.3902 - val_o5_loss: 0.4065 - val_o6_loss: 0.4436 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 30.2058 - o1_loss: 0.2302 - o2_loss: 0.0931 - o3_loss: 0.0648 - o4_loss: 0.0492 - o5_loss: 0.0436 - o6_loss: 0.0395 - o1_f1: 0.8981 - o2_f1: 0.9759 - o3_f1: 0.9824 - o4_f1: 0.9847 - o5_f1: 0.9858 - o6_f1: 0.9858 - val_loss: 271.3561 - val_o1_loss: 0.3377 - val_o2_loss: 0.3092 - val_o3_loss: 0.3454 - val_o4_loss: 0.3897 - val_o5_loss: 0.4055 - val_o6_loss: 0.4441 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 29.6326 - o1_loss: 0.2305 - o2_loss: 0.0924 - o3_loss: 0.0635 - o4_loss: 0.0480 - o5_loss: 0.0425 - o6_loss: 0.0387 - o1_f1: 0.8981 - o2_f1: 0.9738 - o3_f1: 0.9805 - o4_f1: 0.9840 - o5_f1: 0.9877 - o6_f1: 0.9877 - val_loss: 273.4537 - val_o1_loss: 0.3383 - val_o2_loss: 0.3099 - val_o3_loss: 0.3464 - val_o4_loss: 0.3911 - val_o5_loss: 0.4075 - val_o6_loss: 0.4484 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 29.6450 - o1_loss: 0.2303 - o2_loss: 0.0923 - o3_loss: 0.0636 - o4_loss: 0.0481 - o5_loss: 0.0425 - o6_loss: 0.0387 - o1_f1: 0.8781 - o2_f1: 0.9726 - o3_f1: 0.9748 - o4_f1: 0.9848 - o5_f1: 0.9848 - o6_f1: 0.9848 - val_loss: 279.2618 - val_o1_loss: 0.3383 - val_o2_loss: 0.3114 - val_o3_loss: 0.3490 - val_o4_loss: 0.3957 - val_o5_loss: 0.4140 - val_o6_loss: 0.4597 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 29.2611 - o1_loss: 0.2299 - o2_loss: 0.0918 - o3_loss: 0.0629 - o4_loss: 0.0472 - o5_loss: 0.0417 - o6_loss: 0.0382 - o1_f1: 0.8906 - o2_f1: 0.9751 - o3_f1: 0.9844 - o4_f1: 0.9844 - o5_f1: 0.9828 - o6_f1: 0.9828 - val_loss: 270.4138 - val_o1_loss: 0.3360 - val_o2_loss: 0.3087 - val_o3_loss: 0.3472 - val_o4_loss: 0.3938 - val_o5_loss: 0.4087 - val_o6_loss: 0.4399 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 28.7233 - o1_loss: 0.2298 - o2_loss: 0.0914 - o3_loss: 0.0623 - o4_loss: 0.0465 - o5_loss: 0.0409 - o6_loss: 0.0372 - o1_f1: 0.8972 - o2_f1: 0.9710 - o3_f1: 0.9831 - o4_f1: 0.9850 - o5_f1: 0.9850 - o6_f1: 0.9862 - val_loss: 278.3219 - val_o1_loss: 0.3376 - val_o2_loss: 0.3104 - val_o3_loss: 0.3485 - val_o4_loss: 0.3955 - val_o5_loss: 0.4135 - val_o6_loss: 0.4575 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 29.1771 - o1_loss: 0.2293 - o2_loss: 0.0913 - o3_loss: 0.0626 - o4_loss: 0.0472 - o5_loss: 0.0416 - o6_loss: 0.0380 - o1_f1: 0.8855 - o2_f1: 0.9739 - o3_f1: 0.9801 - o4_f1: 0.9836 - o5_f1: 0.9838 - o6_f1: 0.9838 - val_loss: 272.5766 - val_o1_loss: 0.3361 - val_o2_loss: 0.3088 - val_o3_loss: 0.3474 - val_o4_loss: 0.3943 - val_o5_loss: 0.4100 - val_o6_loss: 0.4447 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 28.1948 - o1_loss: 0.2291 - o2_loss: 0.0900 - o3_loss: 0.0609 - o4_loss: 0.0455 - o5_loss: 0.0400 - o6_loss: 0.0364 - o1_f1: 0.8938 - o2_f1: 0.9738 - o3_f1: 0.9836 - o4_f1: 0.9870 - o5_f1: 0.9867 - o6_f1: 0.9886 - val_loss: 272.4267 - val_o1_loss: 0.3361 - val_o2_loss: 0.3087 - val_o3_loss: 0.3479 - val_o4_loss: 0.3951 - val_o5_loss: 0.4104 - val_o6_loss: 0.4440 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 27.2676 - o1_loss: 0.2290 - o2_loss: 0.0894 - o3_loss: 0.0598 - o4_loss: 0.0441 - o5_loss: 0.0386 - o6_loss: 0.0349 - o1_f1: 0.8906 - o2_f1: 0.9749 - o3_f1: 0.9824 - o4_f1: 0.9870 - o5_f1: 0.9877 - o6_f1: 0.9894 - val_loss: 282.5531 - val_o1_loss: 0.3374 - val_o2_loss: 0.3115 - val_o3_loss: 0.3512 - val_o4_loss: 0.3997 - val_o5_loss: 0.4185 - val_o6_loss: 0.4655 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5467 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 28.0548 - o1_loss: 0.2289 - o2_loss: 0.0897 - o3_loss: 0.0605 - o4_loss: 0.0452 - o5_loss: 0.0397 - o6_loss: 0.0362 - o1_f1: 0.8884 - o2_f1: 0.9775 - o3_f1: 0.9860 - o4_f1: 0.9881 - o5_f1: 0.9893 - o6_f1: 0.9910 - val_loss: 275.8229 - val_o1_loss: 0.3360 - val_o2_loss: 0.3093 - val_o3_loss: 0.3487 - val_o4_loss: 0.3964 - val_o5_loss: 0.4126 - val_o6_loss: 0.4515 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.00025.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 30.3260 - o1_loss: 0.2288 - o2_loss: 0.0906 - o3_loss: 0.0629 - o4_loss: 0.0487 - o5_loss: 0.0434 - o6_loss: 0.0399 - o1_f1: 0.9090 - o2_f1: 0.9747 - o3_f1: 0.9817 - o4_f1: 0.9832 - o5_f1: 0.9838 - o6_f1: 0.9867 - val_loss: 274.5033 - val_o1_loss: 0.3362 - val_o2_loss: 0.3089 - val_o3_loss: 0.3487 - val_o4_loss: 0.3971 - val_o5_loss: 0.4127 - val_o6_loss: 0.4480 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 28.6562 - o1_loss: 0.2290 - o2_loss: 0.0900 - o3_loss: 0.0608 - o4_loss: 0.0457 - o5_loss: 0.0404 - o6_loss: 0.0373 - o1_f1: 0.8920 - o2_f1: 0.9681 - o3_f1: 0.9793 - o4_f1: 0.9900 - o5_f1: 0.9871 - o6_f1: 0.9884 - val_loss: 273.1957 - val_o1_loss: 0.3354 - val_o2_loss: 0.3090 - val_o3_loss: 0.3494 - val_o4_loss: 0.3978 - val_o5_loss: 0.4122 - val_o6_loss: 0.4448 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 26.4693 - o1_loss: 0.2277 - o2_loss: 0.0875 - o3_loss: 0.0579 - o4_loss: 0.0425 - o5_loss: 0.0372 - o6_loss: 0.0337 - o1_f1: 0.8975 - o2_f1: 0.9799 - o3_f1: 0.9851 - o4_f1: 0.9889 - o5_f1: 0.9889 - o6_f1: 0.9905 - val_loss: 275.6334 - val_o1_loss: 0.3341 - val_o2_loss: 0.3104 - val_o3_loss: 0.3553 - val_o4_loss: 0.4078 - val_o5_loss: 0.4221 - val_o6_loss: 0.4455 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5134 - val_o5_f1: 0.5134 - val_o6_f1: 0.5352\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 28.0031 - o1_loss: 0.2280 - o2_loss: 0.0889 - o3_loss: 0.0600 - o4_loss: 0.0451 - o5_loss: 0.0396 - o6_loss: 0.0361 - o1_f1: 0.8879 - o2_f1: 0.9676 - o3_f1: 0.9788 - o4_f1: 0.9810 - o5_f1: 0.9802 - o6_f1: 0.9848 - val_loss: 280.8827 - val_o1_loss: 0.3355 - val_o2_loss: 0.3104 - val_o3_loss: 0.3516 - val_o4_loss: 0.4009 - val_o5_loss: 0.4178 - val_o6_loss: 0.4614 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 27.0385 - o1_loss: 0.2280 - o2_loss: 0.0885 - o3_loss: 0.0594 - o4_loss: 0.0440 - o5_loss: 0.0382 - o6_loss: 0.0344 - o1_f1: 0.9002 - o2_f1: 0.9668 - o3_f1: 0.9772 - o4_f1: 0.9845 - o5_f1: 0.9867 - o6_f1: 0.9867 - val_loss: 276.2617 - val_o1_loss: 0.3345 - val_o2_loss: 0.3089 - val_o3_loss: 0.3515 - val_o4_loss: 0.4024 - val_o5_loss: 0.4178 - val_o6_loss: 0.4496 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5174\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 28.1693 - o1_loss: 0.2275 - o2_loss: 0.0886 - o3_loss: 0.0599 - o4_loss: 0.0452 - o5_loss: 0.0398 - o6_loss: 0.0364 - o1_f1: 0.8990 - o2_f1: 0.9736 - o3_f1: 0.9828 - o4_f1: 0.9894 - o5_f1: 0.9871 - o6_f1: 0.9894 - val_loss: 275.9764 - val_o1_loss: 0.3345 - val_o2_loss: 0.3087 - val_o3_loss: 0.3511 - val_o4_loss: 0.4016 - val_o5_loss: 0.4166 - val_o6_loss: 0.4495 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 25.9031 - o1_loss: 0.2271 - o2_loss: 0.0863 - o3_loss: 0.0565 - o4_loss: 0.0413 - o5_loss: 0.0360 - o6_loss: 0.0329 - o1_f1: 0.8923 - o2_f1: 0.9744 - o3_f1: 0.9827 - o4_f1: 0.9866 - o5_f1: 0.9875 - o6_f1: 0.9911 - val_loss: 284.4382 - val_o1_loss: 0.3349 - val_o2_loss: 0.3110 - val_o3_loss: 0.3535 - val_o4_loss: 0.4044 - val_o5_loss: 0.4220 - val_o6_loss: 0.4681 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5289 - val_o6_f1: 0.5228\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 26.2583 - o1_loss: 0.2271 - o2_loss: 0.0861 - o3_loss: 0.0566 - o4_loss: 0.0418 - o5_loss: 0.0367 - o6_loss: 0.0334 - o1_f1: 0.8935 - o2_f1: 0.9690 - o3_f1: 0.9736 - o4_f1: 0.9807 - o5_f1: 0.9815 - o6_f1: 0.9834 - val_loss: 277.2948 - val_o1_loss: 0.3341 - val_o2_loss: 0.3087 - val_o3_loss: 0.3514 - val_o4_loss: 0.4020 - val_o5_loss: 0.4172 - val_o6_loss: 0.4524 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 26.0158 - o1_loss: 0.2272 - o2_loss: 0.0860 - o3_loss: 0.0562 - o4_loss: 0.0413 - o5_loss: 0.0362 - o6_loss: 0.0331 - o1_f1: 0.8825 - o2_f1: 0.9688 - o3_f1: 0.9801 - o4_f1: 0.9864 - o5_f1: 0.9864 - o6_f1: 0.9877 - val_loss: 279.5072 - val_o1_loss: 0.3340 - val_o2_loss: 0.3088 - val_o3_loss: 0.3515 - val_o4_loss: 0.4023 - val_o5_loss: 0.4183 - val_o6_loss: 0.4575 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 26.9152 - o1_loss: 0.2270 - o2_loss: 0.0871 - o3_loss: 0.0578 - o4_loss: 0.0428 - o5_loss: 0.0376 - o6_loss: 0.0345 - o1_f1: 0.8871 - o2_f1: 0.9731 - o3_f1: 0.9781 - o4_f1: 0.9821 - o5_f1: 0.9844 - o6_f1: 0.9872 - val_loss: 282.9275 - val_o1_loss: 0.3351 - val_o2_loss: 0.3098 - val_o3_loss: 0.3529 - val_o4_loss: 0.4042 - val_o5_loss: 0.4211 - val_o6_loss: 0.4647 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5228\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 26.5919 - o1_loss: 0.2268 - o2_loss: 0.0866 - o3_loss: 0.0573 - o4_loss: 0.0426 - o5_loss: 0.0372 - o6_loss: 0.0339 - o1_f1: 0.9112 - o2_f1: 0.9751 - o3_f1: 0.9839 - o4_f1: 0.9877 - o5_f1: 0.9887 - o6_f1: 0.9903 - val_loss: 277.1021 - val_o1_loss: 0.3336 - val_o2_loss: 0.3090 - val_o3_loss: 0.3543 - val_o4_loss: 0.4067 - val_o5_loss: 0.4206 - val_o6_loss: 0.4499 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5352\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 26.7377 - o1_loss: 0.2266 - o2_loss: 0.0861 - o3_loss: 0.0569 - o4_loss: 0.0424 - o5_loss: 0.0371 - o6_loss: 0.0343 - o1_f1: 0.8951 - o2_f1: 0.9695 - o3_f1: 0.9788 - o4_f1: 0.9884 - o5_f1: 0.9884 - o6_f1: 0.9884 - val_loss: 279.2390 - val_o1_loss: 0.3333 - val_o2_loss: 0.3090 - val_o3_loss: 0.3537 - val_o4_loss: 0.4064 - val_o5_loss: 0.4216 - val_o6_loss: 0.4549 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 25.0330 - o1_loss: 0.2262 - o2_loss: 0.0848 - o3_loss: 0.0549 - o4_loss: 0.0398 - o5_loss: 0.0347 - o6_loss: 0.0314 - o1_f1: 0.8942 - o2_f1: 0.9773 - o3_f1: 0.9821 - o4_f1: 0.9862 - o5_f1: 0.9862 - o6_f1: 0.9898 - val_loss: 280.9614 - val_o1_loss: 0.3327 - val_o2_loss: 0.3097 - val_o3_loss: 0.3569 - val_o4_loss: 0.4116 - val_o5_loss: 0.4270 - val_o6_loss: 0.4563 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5134 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5352\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.00025.\n",
      " - 2s - loss: 25.1856 - o1_loss: 0.2258 - o2_loss: 0.0846 - o3_loss: 0.0546 - o4_loss: 0.0397 - o5_loss: 0.0346 - o6_loss: 0.0318 - o1_f1: 0.8956 - o2_f1: 0.9697 - o3_f1: 0.9771 - o4_f1: 0.9865 - o5_f1: 0.9901 - o6_f1: 0.9901 - val_loss: 280.1116 - val_o1_loss: 0.3334 - val_o2_loss: 0.3090 - val_o3_loss: 0.3537 - val_o4_loss: 0.4057 - val_o5_loss: 0.4205 - val_o6_loss: 0.4575 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 3s - loss: 24.3991 - o1_loss: 0.2254 - o2_loss: 0.0839 - o3_loss: 0.0537 - o4_loss: 0.0387 - o5_loss: 0.0335 - o6_loss: 0.0305 - o1_f1: 0.9037 - o2_f1: 0.9775 - o3_f1: 0.9856 - o4_f1: 0.9898 - o5_f1: 0.9898 - o6_f1: 0.9921 - val_loss: 279.4450 - val_o1_loss: 0.3331 - val_o2_loss: 0.3089 - val_o3_loss: 0.3540 - val_o4_loss: 0.4062 - val_o5_loss: 0.4207 - val_o6_loss: 0.4557 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.2876 - o1_loss: 0.2253 - o2_loss: 0.0836 - o3_loss: 0.0535 - o4_loss: 0.0384 - o5_loss: 0.0333 - o6_loss: 0.0303 - o1_f1: 0.9044 - o2_f1: 0.9748 - o3_f1: 0.9820 - o4_f1: 0.9881 - o5_f1: 0.9881 - o6_f1: 0.9898 - val_loss: 281.4135 - val_o1_loss: 0.3334 - val_o2_loss: 0.3092 - val_o3_loss: 0.3538 - val_o4_loss: 0.4057 - val_o5_loss: 0.4209 - val_o6_loss: 0.4606 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.2205 - o1_loss: 0.2254 - o2_loss: 0.0836 - o3_loss: 0.0535 - o4_loss: 0.0384 - o5_loss: 0.0333 - o6_loss: 0.0301 - o1_f1: 0.8886 - o2_f1: 0.9698 - o3_f1: 0.9772 - o4_f1: 0.9807 - o5_f1: 0.9807 - o6_f1: 0.9830 - val_loss: 280.3729 - val_o1_loss: 0.3330 - val_o2_loss: 0.3089 - val_o3_loss: 0.3543 - val_o4_loss: 0.4069 - val_o5_loss: 0.4218 - val_o6_loss: 0.4575 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.3327 - o1_loss: 0.2252 - o2_loss: 0.0835 - o3_loss: 0.0535 - o4_loss: 0.0385 - o5_loss: 0.0334 - o6_loss: 0.0304 - o1_f1: 0.8946 - o2_f1: 0.9760 - o3_f1: 0.9832 - o4_f1: 0.9874 - o5_f1: 0.9878 - o6_f1: 0.9916 - val_loss: 282.4752 - val_o1_loss: 0.3335 - val_o2_loss: 0.3092 - val_o3_loss: 0.3541 - val_o4_loss: 0.4065 - val_o5_loss: 0.4222 - val_o6_loss: 0.4627 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.3797 - o1_loss: 0.2254 - o2_loss: 0.0840 - o3_loss: 0.0539 - o4_loss: 0.0387 - o5_loss: 0.0335 - o6_loss: 0.0304 - o1_f1: 0.8942 - o2_f1: 0.9766 - o3_f1: 0.9829 - o4_f1: 0.9881 - o5_f1: 0.9881 - o6_f1: 0.9898 - val_loss: 282.5395 - val_o1_loss: 0.3336 - val_o2_loss: 0.3092 - val_o3_loss: 0.3542 - val_o4_loss: 0.4067 - val_o5_loss: 0.4223 - val_o6_loss: 0.4628 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.1505 - o1_loss: 0.2253 - o2_loss: 0.0836 - o3_loss: 0.0534 - o4_loss: 0.0384 - o5_loss: 0.0331 - o6_loss: 0.0300 - o1_f1: 0.9042 - o2_f1: 0.9809 - o3_f1: 0.9832 - o4_f1: 0.9866 - o5_f1: 0.9879 - o6_f1: 0.9879 - val_loss: 280.0498 - val_o1_loss: 0.3330 - val_o2_loss: 0.3089 - val_o3_loss: 0.3546 - val_o4_loss: 0.4073 - val_o5_loss: 0.4217 - val_o6_loss: 0.4567 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.3382 - o1_loss: 0.2252 - o2_loss: 0.0835 - o3_loss: 0.0534 - o4_loss: 0.0385 - o5_loss: 0.0334 - o6_loss: 0.0304 - o1_f1: 0.9016 - o2_f1: 0.9769 - o3_f1: 0.9834 - o4_f1: 0.9892 - o5_f1: 0.9892 - o6_f1: 0.9909 - val_loss: 279.8361 - val_o1_loss: 0.3328 - val_o2_loss: 0.3090 - val_o3_loss: 0.3552 - val_o4_loss: 0.4084 - val_o5_loss: 0.4226 - val_o6_loss: 0.4556 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.1185 - o1_loss: 0.2251 - o2_loss: 0.0834 - o3_loss: 0.0533 - o4_loss: 0.0383 - o5_loss: 0.0331 - o6_loss: 0.0300 - o1_f1: 0.9022 - o2_f1: 0.9774 - o3_f1: 0.9864 - o4_f1: 0.9914 - o5_f1: 0.9925 - o6_f1: 0.9927 - val_loss: 284.0143 - val_o1_loss: 0.3336 - val_o2_loss: 0.3093 - val_o3_loss: 0.3545 - val_o4_loss: 0.4075 - val_o5_loss: 0.4239 - val_o6_loss: 0.4657 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.7266 - o1_loss: 0.2252 - o2_loss: 0.0839 - o3_loss: 0.0540 - o4_loss: 0.0392 - o5_loss: 0.0341 - o6_loss: 0.0310 - o1_f1: 0.9052 - o2_f1: 0.9751 - o3_f1: 0.9815 - o4_f1: 0.9847 - o5_f1: 0.9820 - o6_f1: 0.9874 - val_loss: 283.8355 - val_o1_loss: 0.3335 - val_o2_loss: 0.3092 - val_o3_loss: 0.3545 - val_o4_loss: 0.4075 - val_o5_loss: 0.4236 - val_o6_loss: 0.4654 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5289\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.8370 - o1_loss: 0.2251 - o2_loss: 0.0830 - o3_loss: 0.0527 - o4_loss: 0.0377 - o5_loss: 0.0326 - o6_loss: 0.0295 - o1_f1: 0.9012 - o2_f1: 0.9735 - o3_f1: 0.9787 - o4_f1: 0.9828 - o5_f1: 0.9828 - o6_f1: 0.9850 - val_loss: 281.7602 - val_o1_loss: 0.3329 - val_o2_loss: 0.3089 - val_o3_loss: 0.3550 - val_o4_loss: 0.4085 - val_o5_loss: 0.4237 - val_o6_loss: 0.4600 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 24.2796 - o1_loss: 0.2249 - o2_loss: 0.0832 - o3_loss: 0.0532 - o4_loss: 0.0383 - o5_loss: 0.0333 - o6_loss: 0.0303 - o1_f1: 0.8972 - o2_f1: 0.9762 - o3_f1: 0.9841 - o4_f1: 0.9877 - o5_f1: 0.9890 - o6_f1: 0.9890 - val_loss: 284.6080 - val_o1_loss: 0.3334 - val_o2_loss: 0.3094 - val_o3_loss: 0.3549 - val_o4_loss: 0.4080 - val_o5_loss: 0.4243 - val_o6_loss: 0.4670 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5228\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.8714 - o1_loss: 0.2249 - o2_loss: 0.0829 - o3_loss: 0.0527 - o4_loss: 0.0378 - o5_loss: 0.0327 - o6_loss: 0.0296 - o1_f1: 0.8951 - o2_f1: 0.9770 - o3_f1: 0.9844 - o4_f1: 0.9879 - o5_f1: 0.9896 - o6_f1: 0.9896 - val_loss: 281.7162 - val_o1_loss: 0.3330 - val_o2_loss: 0.3089 - val_o3_loss: 0.3549 - val_o4_loss: 0.4081 - val_o5_loss: 0.4231 - val_o6_loss: 0.4602 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.9221 - o1_loss: 0.2249 - o2_loss: 0.0829 - o3_loss: 0.0527 - o4_loss: 0.0378 - o5_loss: 0.0327 - o6_loss: 0.0297 - o1_f1: 0.9027 - o2_f1: 0.9778 - o3_f1: 0.9835 - o4_f1: 0.9872 - o5_f1: 0.9913 - o6_f1: 0.9924 - val_loss: 282.6068 - val_o1_loss: 0.3328 - val_o2_loss: 0.3089 - val_o3_loss: 0.3549 - val_o4_loss: 0.4082 - val_o5_loss: 0.4236 - val_o6_loss: 0.4622 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.8137 - o1_loss: 0.2249 - o2_loss: 0.0828 - o3_loss: 0.0525 - o4_loss: 0.0376 - o5_loss: 0.0325 - o6_loss: 0.0295 - o1_f1: 0.8808 - o2_f1: 0.9771 - o3_f1: 0.9831 - o4_f1: 0.9878 - o5_f1: 0.9878 - o6_f1: 0.9901 - val_loss: 281.9591 - val_o1_loss: 0.3327 - val_o2_loss: 0.3088 - val_o3_loss: 0.3549 - val_o4_loss: 0.4083 - val_o5_loss: 0.4232 - val_o6_loss: 0.4607 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.8003 - o1_loss: 0.2249 - o2_loss: 0.0828 - o3_loss: 0.0525 - o4_loss: 0.0376 - o5_loss: 0.0325 - o6_loss: 0.0295 - o1_f1: 0.8966 - o2_f1: 0.9743 - o3_f1: 0.9804 - o4_f1: 0.9853 - o5_f1: 0.9853 - o6_f1: 0.9889 - val_loss: 282.5002 - val_o1_loss: 0.3327 - val_o2_loss: 0.3088 - val_o3_loss: 0.3550 - val_o4_loss: 0.4086 - val_o5_loss: 0.4238 - val_o6_loss: 0.4618 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 6.25e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 24.0641 - o1_loss: 0.2249 - o2_loss: 0.0829 - o3_loss: 0.0529 - o4_loss: 0.0381 - o5_loss: 0.0330 - o6_loss: 0.0299 - o1_f1: 0.8899 - o2_f1: 0.9707 - o3_f1: 0.9795 - o4_f1: 0.9840 - o5_f1: 0.9840 - o6_f1: 0.9889 - val_loss: 281.9060 - val_o1_loss: 0.3325 - val_o2_loss: 0.3088 - val_o3_loss: 0.3556 - val_o4_loss: 0.4096 - val_o5_loss: 0.4244 - val_o6_loss: 0.4599 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.6964 - o1_loss: 0.2247 - o2_loss: 0.0826 - o3_loss: 0.0524 - o4_loss: 0.0374 - o5_loss: 0.0324 - o6_loss: 0.0293 - o1_f1: 0.8881 - o2_f1: 0.9738 - o3_f1: 0.9814 - o4_f1: 0.9852 - o5_f1: 0.9852 - o6_f1: 0.9875 - val_loss: 282.2388 - val_o1_loss: 0.3325 - val_o2_loss: 0.3088 - val_o3_loss: 0.3554 - val_o4_loss: 0.4093 - val_o5_loss: 0.4242 - val_o6_loss: 0.4609 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.6606 - o1_loss: 0.2247 - o2_loss: 0.0825 - o3_loss: 0.0522 - o4_loss: 0.0373 - o5_loss: 0.0323 - o6_loss: 0.0293 - o1_f1: 0.9046 - o2_f1: 0.9729 - o3_f1: 0.9808 - o4_f1: 0.9854 - o5_f1: 0.9854 - o6_f1: 0.9873 - val_loss: 282.2697 - val_o1_loss: 0.3324 - val_o2_loss: 0.3088 - val_o3_loss: 0.3554 - val_o4_loss: 0.4091 - val_o5_loss: 0.4239 - val_o6_loss: 0.4611 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.4859 - o1_loss: 0.2246 - o2_loss: 0.0823 - o3_loss: 0.0519 - o4_loss: 0.0370 - o5_loss: 0.0320 - o6_loss: 0.0290 - o1_f1: 0.9048 - o2_f1: 0.9745 - o3_f1: 0.9810 - o4_f1: 0.9865 - o5_f1: 0.9865 - o6_f1: 0.9881 - val_loss: 282.9902 - val_o1_loss: 0.3326 - val_o2_loss: 0.3088 - val_o3_loss: 0.3553 - val_o4_loss: 0.4091 - val_o5_loss: 0.4241 - val_o6_loss: 0.4628 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.6790 - o1_loss: 0.2247 - o2_loss: 0.0825 - o3_loss: 0.0523 - o4_loss: 0.0375 - o5_loss: 0.0324 - o6_loss: 0.0293 - o1_f1: 0.9073 - o2_f1: 0.9784 - o3_f1: 0.9816 - o4_f1: 0.9914 - o5_f1: 0.9931 - o6_f1: 0.9931 - val_loss: 282.2703 - val_o1_loss: 0.3320 - val_o2_loss: 0.3090 - val_o3_loss: 0.3572 - val_o4_loss: 0.4124 - val_o5_loss: 0.4270 - val_o6_loss: 0.4594 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5352\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.9049 - o1_loss: 0.2247 - o2_loss: 0.0827 - o3_loss: 0.0524 - o4_loss: 0.0377 - o5_loss: 0.0327 - o6_loss: 0.0297 - o1_f1: 0.9068 - o2_f1: 0.9764 - o3_f1: 0.9818 - o4_f1: 0.9890 - o5_f1: 0.9918 - o6_f1: 0.9931 - val_loss: 282.7310 - val_o1_loss: 0.3323 - val_o2_loss: 0.3087 - val_o3_loss: 0.3556 - val_o4_loss: 0.4097 - val_o5_loss: 0.4245 - val_o6_loss: 0.4619 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.5289 - o1_loss: 0.2245 - o2_loss: 0.0821 - o3_loss: 0.0519 - o4_loss: 0.0371 - o5_loss: 0.0321 - o6_loss: 0.0291 - o1_f1: 0.8663 - o2_f1: 0.9702 - o3_f1: 0.9794 - o4_f1: 0.9856 - o5_f1: 0.9856 - o6_f1: 0.9884 - val_loss: 282.5294 - val_o1_loss: 0.3322 - val_o2_loss: 0.3087 - val_o3_loss: 0.3557 - val_o4_loss: 0.4097 - val_o5_loss: 0.4243 - val_o6_loss: 0.4615 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.4893 - o1_loss: 0.2245 - o2_loss: 0.0821 - o3_loss: 0.0518 - o4_loss: 0.0369 - o5_loss: 0.0319 - o6_loss: 0.0291 - o1_f1: 0.8802 - o2_f1: 0.9754 - o3_f1: 0.9807 - o4_f1: 0.9873 - o5_f1: 0.9888 - o6_f1: 0.9907 - val_loss: 284.4680 - val_o1_loss: 0.3325 - val_o2_loss: 0.3090 - val_o3_loss: 0.3558 - val_o4_loss: 0.4100 - val_o5_loss: 0.4254 - val_o6_loss: 0.4658 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.3381 - o1_loss: 0.2244 - o2_loss: 0.0820 - o3_loss: 0.0516 - o4_loss: 0.0368 - o5_loss: 0.0318 - o6_loss: 0.0288 - o1_f1: 0.9007 - o2_f1: 0.9785 - o3_f1: 0.9843 - o4_f1: 0.9888 - o5_f1: 0.9927 - o6_f1: 0.9911 - val_loss: 282.8327 - val_o1_loss: 0.3321 - val_o2_loss: 0.3087 - val_o3_loss: 0.3560 - val_o4_loss: 0.4105 - val_o5_loss: 0.4252 - val_o6_loss: 0.4618 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.3284 - o1_loss: 0.2245 - o2_loss: 0.0818 - o3_loss: 0.0515 - o4_loss: 0.0367 - o5_loss: 0.0317 - o6_loss: 0.0288 - o1_f1: 0.9046 - o2_f1: 0.9715 - o3_f1: 0.9797 - o4_f1: 0.9869 - o5_f1: 0.9869 - o6_f1: 0.9927 - val_loss: 282.6794 - val_o1_loss: 0.3323 - val_o2_loss: 0.3088 - val_o3_loss: 0.3561 - val_o4_loss: 0.4104 - val_o5_loss: 0.4248 - val_o6_loss: 0.4615 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.2374 - o1_loss: 0.2243 - o2_loss: 0.0818 - o3_loss: 0.0514 - o4_loss: 0.0366 - o5_loss: 0.0316 - o6_loss: 0.0286 - o1_f1: 0.8992 - o2_f1: 0.9742 - o3_f1: 0.9852 - o4_f1: 0.9885 - o5_f1: 0.9919 - o6_f1: 0.9900 - val_loss: 282.9690 - val_o1_loss: 0.3321 - val_o2_loss: 0.3087 - val_o3_loss: 0.3563 - val_o4_loss: 0.4109 - val_o5_loss: 0.4255 - val_o6_loss: 0.4619 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.3829 - o1_loss: 0.2244 - o2_loss: 0.0819 - o3_loss: 0.0516 - o4_loss: 0.0368 - o5_loss: 0.0318 - o6_loss: 0.0289 - o1_f1: 0.9044 - o2_f1: 0.9772 - o3_f1: 0.9828 - o4_f1: 0.9898 - o5_f1: 0.9917 - o6_f1: 0.9933 - val_loss: 284.9558 - val_o1_loss: 0.3324 - val_o2_loss: 0.3090 - val_o3_loss: 0.3561 - val_o4_loss: 0.4107 - val_o5_loss: 0.4261 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.1480 - o1_loss: 0.2244 - o2_loss: 0.0818 - o3_loss: 0.0513 - o4_loss: 0.0365 - o5_loss: 0.0314 - o6_loss: 0.0285 - o1_f1: 0.9105 - o2_f1: 0.9812 - o3_f1: 0.9868 - o4_f1: 0.9895 - o5_f1: 0.9918 - o6_f1: 0.9918 - val_loss: 283.1368 - val_o1_loss: 0.3319 - val_o2_loss: 0.3086 - val_o3_loss: 0.3564 - val_o4_loss: 0.4112 - val_o5_loss: 0.4257 - val_o6_loss: 0.4622 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.1550 - o1_loss: 0.2242 - o2_loss: 0.0815 - o3_loss: 0.0511 - o4_loss: 0.0363 - o5_loss: 0.0314 - o6_loss: 0.0285 - o1_f1: 0.9009 - o2_f1: 0.9730 - o3_f1: 0.9826 - o4_f1: 0.9858 - o5_f1: 0.9858 - o6_f1: 0.9870 - val_loss: 283.3388 - val_o1_loss: 0.3320 - val_o2_loss: 0.3087 - val_o3_loss: 0.3564 - val_o4_loss: 0.4113 - val_o5_loss: 0.4259 - val_o6_loss: 0.4626 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.0832 - o1_loss: 0.2243 - o2_loss: 0.0814 - o3_loss: 0.0509 - o4_loss: 0.0361 - o5_loss: 0.0312 - o6_loss: 0.0284 - o1_f1: 0.8975 - o2_f1: 0.9706 - o3_f1: 0.9789 - o4_f1: 0.9859 - o5_f1: 0.9881 - o6_f1: 0.9904 - val_loss: 285.6888 - val_o1_loss: 0.3322 - val_o2_loss: 0.3090 - val_o3_loss: 0.3563 - val_o4_loss: 0.4111 - val_o5_loss: 0.4266 - val_o6_loss: 0.4682 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.4424 - o1_loss: 0.2244 - o2_loss: 0.0819 - o3_loss: 0.0516 - o4_loss: 0.0369 - o5_loss: 0.0319 - o6_loss: 0.0289 - o1_f1: 0.9053 - o2_f1: 0.9809 - o3_f1: 0.9854 - o4_f1: 0.9899 - o5_f1: 0.9899 - o6_f1: 0.9916 - val_loss: 284.1925 - val_o1_loss: 0.3323 - val_o2_loss: 0.3088 - val_o3_loss: 0.3563 - val_o4_loss: 0.4109 - val_o5_loss: 0.4255 - val_o6_loss: 0.4649 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.2736 - o1_loss: 0.2242 - o2_loss: 0.0815 - o3_loss: 0.0512 - o4_loss: 0.0365 - o5_loss: 0.0316 - o6_loss: 0.0287 - o1_f1: 0.9021 - o2_f1: 0.9736 - o3_f1: 0.9807 - o4_f1: 0.9869 - o5_f1: 0.9888 - o6_f1: 0.9906 - val_loss: 284.3964 - val_o1_loss: 0.3321 - val_o2_loss: 0.3087 - val_o3_loss: 0.3564 - val_o4_loss: 0.4111 - val_o5_loss: 0.4259 - val_o6_loss: 0.4652 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.1486 - o1_loss: 0.2241 - o2_loss: 0.0816 - o3_loss: 0.0512 - o4_loss: 0.0364 - o5_loss: 0.0314 - o6_loss: 0.0284 - o1_f1: 0.9052 - o2_f1: 0.9771 - o3_f1: 0.9837 - o4_f1: 0.9874 - o5_f1: 0.9924 - o6_f1: 0.9889 - val_loss: 283.0325 - val_o1_loss: 0.3317 - val_o2_loss: 0.3086 - val_o3_loss: 0.3571 - val_o4_loss: 0.4125 - val_o5_loss: 0.4266 - val_o6_loss: 0.4614 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.0423 - o1_loss: 0.2242 - o2_loss: 0.0814 - o3_loss: 0.0509 - o4_loss: 0.0362 - o5_loss: 0.0312 - o6_loss: 0.0283 - o1_f1: 0.8939 - o2_f1: 0.9812 - o3_f1: 0.9862 - o4_f1: 0.9897 - o5_f1: 0.9897 - o6_f1: 0.9916 - val_loss: 283.2753 - val_o1_loss: 0.3317 - val_o2_loss: 0.3086 - val_o3_loss: 0.3571 - val_o4_loss: 0.4125 - val_o5_loss: 0.4266 - val_o6_loss: 0.4620 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 23.0850 - o1_loss: 0.2242 - o2_loss: 0.0813 - o3_loss: 0.0509 - o4_loss: 0.0362 - o5_loss: 0.0313 - o6_loss: 0.0284 - o1_f1: 0.8992 - o2_f1: 0.9720 - o3_f1: 0.9768 - o4_f1: 0.9799 - o5_f1: 0.9815 - o6_f1: 0.9815 - val_loss: 283.1938 - val_o1_loss: 0.3317 - val_o2_loss: 0.3086 - val_o3_loss: 0.3573 - val_o4_loss: 0.4130 - val_o5_loss: 0.4270 - val_o6_loss: 0.4615 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.9434 - o1_loss: 0.2240 - o2_loss: 0.0812 - o3_loss: 0.0507 - o4_loss: 0.0360 - o5_loss: 0.0310 - o6_loss: 0.0282 - o1_f1: 0.8999 - o2_f1: 0.9770 - o3_f1: 0.9801 - o4_f1: 0.9876 - o5_f1: 0.9898 - o6_f1: 0.9915 - val_loss: 284.0655 - val_o1_loss: 0.3317 - val_o2_loss: 0.3087 - val_o3_loss: 0.3569 - val_o4_loss: 0.4121 - val_o5_loss: 0.4264 - val_o6_loss: 0.4641 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.9269 - o1_loss: 0.2239 - o2_loss: 0.0810 - o3_loss: 0.0505 - o4_loss: 0.0359 - o5_loss: 0.0310 - o6_loss: 0.0282 - o1_f1: 0.8937 - o2_f1: 0.9796 - o3_f1: 0.9835 - o4_f1: 0.9871 - o5_f1: 0.9871 - o6_f1: 0.9890 - val_loss: 285.0268 - val_o1_loss: 0.3317 - val_o2_loss: 0.3087 - val_o3_loss: 0.3569 - val_o4_loss: 0.4122 - val_o5_loss: 0.4269 - val_o6_loss: 0.4663 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.7250 - o1_loss: 0.2239 - o2_loss: 0.0809 - o3_loss: 0.0504 - o4_loss: 0.0357 - o5_loss: 0.0307 - o6_loss: 0.0278 - o1_f1: 0.8860 - o2_f1: 0.9812 - o3_f1: 0.9857 - o4_f1: 0.9890 - o5_f1: 0.9924 - o6_f1: 0.9905 - val_loss: 283.7088 - val_o1_loss: 0.3313 - val_o2_loss: 0.3086 - val_o3_loss: 0.3577 - val_o4_loss: 0.4136 - val_o5_loss: 0.4277 - val_o6_loss: 0.4625 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5174\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.9580 - o1_loss: 0.2241 - o2_loss: 0.0813 - o3_loss: 0.0509 - o4_loss: 0.0361 - o5_loss: 0.0311 - o6_loss: 0.0281 - o1_f1: 0.8785 - o2_f1: 0.9788 - o3_f1: 0.9850 - o4_f1: 0.9888 - o5_f1: 0.9902 - o6_f1: 0.9904 - val_loss: 283.5570 - val_o1_loss: 0.3313 - val_o2_loss: 0.3085 - val_o3_loss: 0.3576 - val_o4_loss: 0.4135 - val_o5_loss: 0.4275 - val_o6_loss: 0.4622 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.7801 - o1_loss: 0.2239 - o2_loss: 0.0808 - o3_loss: 0.0503 - o4_loss: 0.0356 - o5_loss: 0.0307 - o6_loss: 0.0279 - o1_f1: 0.8977 - o2_f1: 0.9649 - o3_f1: 0.9712 - o4_f1: 0.9751 - o5_f1: 0.9768 - o6_f1: 0.9787 - val_loss: 284.3719 - val_o1_loss: 0.3315 - val_o2_loss: 0.3086 - val_o3_loss: 0.3576 - val_o4_loss: 0.4135 - val_o5_loss: 0.4278 - val_o6_loss: 0.4641 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.6863 - o1_loss: 0.2238 - o2_loss: 0.0806 - o3_loss: 0.0501 - o4_loss: 0.0355 - o5_loss: 0.0306 - o6_loss: 0.0278 - o1_f1: 0.9013 - o2_f1: 0.9752 - o3_f1: 0.9844 - o4_f1: 0.9896 - o5_f1: 0.9909 - o6_f1: 0.9931 - val_loss: 284.9069 - val_o1_loss: 0.3315 - val_o2_loss: 0.3086 - val_o3_loss: 0.3574 - val_o4_loss: 0.4132 - val_o5_loss: 0.4277 - val_o6_loss: 0.4655 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.7945 - o1_loss: 0.2239 - o2_loss: 0.0808 - o3_loss: 0.0503 - o4_loss: 0.0356 - o5_loss: 0.0307 - o6_loss: 0.0280 - o1_f1: 0.8942 - o2_f1: 0.9793 - o3_f1: 0.9838 - o4_f1: 0.9869 - o5_f1: 0.9869 - o6_f1: 0.9900 - val_loss: 285.3448 - val_o1_loss: 0.3316 - val_o2_loss: 0.3087 - val_o3_loss: 0.3575 - val_o4_loss: 0.4133 - val_o5_loss: 0.4279 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.5870 - o1_loss: 0.2239 - o2_loss: 0.0807 - o3_loss: 0.0500 - o4_loss: 0.0354 - o5_loss: 0.0305 - o6_loss: 0.0276 - o1_f1: 0.9056 - o2_f1: 0.9772 - o3_f1: 0.9822 - o4_f1: 0.9863 - o5_f1: 0.9935 - o6_f1: 0.9955 - val_loss: 284.7054 - val_o1_loss: 0.3315 - val_o2_loss: 0.3085 - val_o3_loss: 0.3575 - val_o4_loss: 0.4134 - val_o5_loss: 0.4276 - val_o6_loss: 0.4650 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.6247 - o1_loss: 0.2237 - o2_loss: 0.0806 - o3_loss: 0.0500 - o4_loss: 0.0354 - o5_loss: 0.0305 - o6_loss: 0.0277 - o1_f1: 0.8941 - o2_f1: 0.9745 - o3_f1: 0.9813 - o4_f1: 0.9868 - o5_f1: 0.9890 - o6_f1: 0.9907 - val_loss: 283.8936 - val_o1_loss: 0.3313 - val_o2_loss: 0.3085 - val_o3_loss: 0.3580 - val_o4_loss: 0.4142 - val_o5_loss: 0.4279 - val_o6_loss: 0.4627 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 6.25e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 23.0237 - o1_loss: 0.2242 - o2_loss: 0.0813 - o3_loss: 0.0508 - o4_loss: 0.0362 - o5_loss: 0.0311 - o6_loss: 0.0283 - o1_f1: 0.9088 - o2_f1: 0.9714 - o3_f1: 0.9738 - o4_f1: 0.9897 - o5_f1: 0.9916 - o6_f1: 0.9916 - val_loss: 283.4568 - val_o1_loss: 0.3311 - val_o2_loss: 0.3083 - val_o3_loss: 0.3579 - val_o4_loss: 0.4140 - val_o5_loss: 0.4275 - val_o6_loss: 0.4618 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.6093 - o1_loss: 0.2238 - o2_loss: 0.0806 - o3_loss: 0.0500 - o4_loss: 0.0354 - o5_loss: 0.0305 - o6_loss: 0.0276 - o1_f1: 0.9074 - o2_f1: 0.9787 - o3_f1: 0.9851 - o4_f1: 0.9898 - o5_f1: 0.9909 - o6_f1: 0.9928 - val_loss: 285.2597 - val_o1_loss: 0.3317 - val_o2_loss: 0.3086 - val_o3_loss: 0.3575 - val_o4_loss: 0.4132 - val_o5_loss: 0.4275 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.6676 - o1_loss: 0.2237 - o2_loss: 0.0805 - o3_loss: 0.0500 - o4_loss: 0.0355 - o5_loss: 0.0306 - o6_loss: 0.0277 - o1_f1: 0.8954 - o2_f1: 0.9792 - o3_f1: 0.9828 - o4_f1: 0.9893 - o5_f1: 0.9908 - o6_f1: 0.9931 - val_loss: 286.4865 - val_o1_loss: 0.3318 - val_o2_loss: 0.3088 - val_o3_loss: 0.3576 - val_o4_loss: 0.4135 - val_o5_loss: 0.4282 - val_o6_loss: 0.4692 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5467 - val_o6_f1: 0.5377\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.3600 - o1_loss: 0.2236 - o2_loss: 0.0803 - o3_loss: 0.0497 - o4_loss: 0.0350 - o5_loss: 0.0301 - o6_loss: 0.0272 - o1_f1: 0.8935 - o2_f1: 0.9757 - o3_f1: 0.9818 - o4_f1: 0.9875 - o5_f1: 0.9926 - o6_f1: 0.9926 - val_loss: 284.3918 - val_o1_loss: 0.3311 - val_o2_loss: 0.3083 - val_o3_loss: 0.3579 - val_o4_loss: 0.4142 - val_o5_loss: 0.4280 - val_o6_loss: 0.4639 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.3753 - o1_loss: 0.2235 - o2_loss: 0.0801 - o3_loss: 0.0495 - o4_loss: 0.0349 - o5_loss: 0.0301 - o6_loss: 0.0273 - o1_f1: 0.9114 - o2_f1: 0.9807 - o3_f1: 0.9857 - o4_f1: 0.9884 - o5_f1: 0.9903 - o6_f1: 0.9922 - val_loss: 284.3542 - val_o1_loss: 0.3313 - val_o2_loss: 0.3083 - val_o3_loss: 0.3581 - val_o4_loss: 0.4146 - val_o5_loss: 0.4282 - val_o6_loss: 0.4637 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      " - 2s - loss: 22.3462 - o1_loss: 0.2234 - o2_loss: 0.0798 - o3_loss: 0.0491 - o4_loss: 0.0347 - o5_loss: 0.0300 - o6_loss: 0.0273 - o1_f1: 0.8970 - o2_f1: 0.9767 - o3_f1: 0.9827 - o4_f1: 0.9869 - o5_f1: 0.9892 - o6_f1: 0.9908 - val_loss: 286.1790 - val_o1_loss: 0.3315 - val_o2_loss: 0.3085 - val_o3_loss: 0.3578 - val_o4_loss: 0.4140 - val_o5_loss: 0.4284 - val_o6_loss: 0.4683 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.2241 - o1_loss: 0.2233 - o2_loss: 0.0799 - o3_loss: 0.0492 - o4_loss: 0.0347 - o5_loss: 0.0298 - o6_loss: 0.0270 - o1_f1: 0.9032 - o2_f1: 0.9780 - o3_f1: 0.9824 - o4_f1: 0.9868 - o5_f1: 0.9902 - o6_f1: 0.9937 - val_loss: 285.4858 - val_o1_loss: 0.3314 - val_o2_loss: 0.3084 - val_o3_loss: 0.3578 - val_o4_loss: 0.4140 - val_o5_loss: 0.4281 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.1147 - o1_loss: 0.2233 - o2_loss: 0.0798 - o3_loss: 0.0491 - o4_loss: 0.0345 - o5_loss: 0.0296 - o6_loss: 0.0269 - o1_f1: 0.8930 - o2_f1: 0.9820 - o3_f1: 0.9842 - o4_f1: 0.9873 - o5_f1: 0.9911 - o6_f1: 0.9919 - val_loss: 284.9203 - val_o1_loss: 0.3312 - val_o2_loss: 0.3083 - val_o3_loss: 0.3580 - val_o4_loss: 0.4143 - val_o5_loss: 0.4281 - val_o6_loss: 0.4652 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0437 - o1_loss: 0.2233 - o2_loss: 0.0797 - o3_loss: 0.0489 - o4_loss: 0.0343 - o5_loss: 0.0295 - o6_loss: 0.0268 - o1_f1: 0.9042 - o2_f1: 0.9807 - o3_f1: 0.9838 - o4_f1: 0.9876 - o5_f1: 0.9921 - o6_f1: 0.9921 - val_loss: 285.1571 - val_o1_loss: 0.3312 - val_o2_loss: 0.3083 - val_o3_loss: 0.3579 - val_o4_loss: 0.4143 - val_o5_loss: 0.4282 - val_o6_loss: 0.4657 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0976 - o1_loss: 0.2233 - o2_loss: 0.0797 - o3_loss: 0.0490 - o4_loss: 0.0344 - o5_loss: 0.0296 - o6_loss: 0.0268 - o1_f1: 0.8955 - o2_f1: 0.9815 - o3_f1: 0.9844 - o4_f1: 0.9882 - o5_f1: 0.9929 - o6_f1: 0.9929 - val_loss: 285.3224 - val_o1_loss: 0.3313 - val_o2_loss: 0.3083 - val_o3_loss: 0.3579 - val_o4_loss: 0.4142 - val_o5_loss: 0.4282 - val_o6_loss: 0.4662 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.1524 - o1_loss: 0.2233 - o2_loss: 0.0798 - o3_loss: 0.0491 - o4_loss: 0.0345 - o5_loss: 0.0297 - o6_loss: 0.0269 - o1_f1: 0.9058 - o2_f1: 0.9744 - o3_f1: 0.9855 - o4_f1: 0.9893 - o5_f1: 0.9912 - o6_f1: 0.9925 - val_loss: 284.8492 - val_o1_loss: 0.3311 - val_o2_loss: 0.3083 - val_o3_loss: 0.3582 - val_o4_loss: 0.4148 - val_o5_loss: 0.4285 - val_o6_loss: 0.4648 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0142 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0489 - o4_loss: 0.0343 - o5_loss: 0.0295 - o6_loss: 0.0267 - o1_f1: 0.8957 - o2_f1: 0.9812 - o3_f1: 0.9851 - o4_f1: 0.9897 - o5_f1: 0.9948 - o6_f1: 0.9948 - val_loss: 285.2159 - val_o1_loss: 0.3312 - val_o2_loss: 0.3083 - val_o3_loss: 0.3580 - val_o4_loss: 0.4144 - val_o5_loss: 0.4283 - val_o6_loss: 0.4658 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0185 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0489 - o4_loss: 0.0343 - o5_loss: 0.0295 - o6_loss: 0.0267 - o1_f1: 0.9072 - o2_f1: 0.9803 - o3_f1: 0.9845 - o4_f1: 0.9882 - o5_f1: 0.9937 - o6_f1: 0.9918 - val_loss: 284.9566 - val_o1_loss: 0.3311 - val_o2_loss: 0.3083 - val_o3_loss: 0.3581 - val_o4_loss: 0.4146 - val_o5_loss: 0.4283 - val_o6_loss: 0.4651 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0658 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0489 - o4_loss: 0.0344 - o5_loss: 0.0295 - o6_loss: 0.0268 - o1_f1: 0.9097 - o2_f1: 0.9812 - o3_f1: 0.9849 - o4_f1: 0.9875 - o5_f1: 0.9914 - o6_f1: 0.9919 - val_loss: 284.8799 - val_o1_loss: 0.3311 - val_o2_loss: 0.3083 - val_o3_loss: 0.3582 - val_o4_loss: 0.4148 - val_o5_loss: 0.4285 - val_o6_loss: 0.4649 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 22.0112 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0488 - o4_loss: 0.0343 - o5_loss: 0.0294 - o6_loss: 0.0267 - o1_f1: 0.9002 - o2_f1: 0.9632 - o3_f1: 0.9747 - o4_f1: 0.9792 - o5_f1: 0.9921 - o6_f1: 0.9838 - val_loss: 284.9092 - val_o1_loss: 0.3310 - val_o2_loss: 0.3083 - val_o3_loss: 0.3583 - val_o4_loss: 0.4149 - val_o5_loss: 0.4286 - val_o6_loss: 0.4649 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.1089 - o1_loss: 0.2233 - o2_loss: 0.0797 - o3_loss: 0.0490 - o4_loss: 0.0345 - o5_loss: 0.0296 - o6_loss: 0.0268 - o1_f1: 0.8880 - o2_f1: 0.9749 - o3_f1: 0.9848 - o4_f1: 0.9876 - o5_f1: 0.9909 - o6_f1: 0.9925 - val_loss: 285.5176 - val_o1_loss: 0.3312 - val_o2_loss: 0.3083 - val_o3_loss: 0.3580 - val_o4_loss: 0.4143 - val_o5_loss: 0.4283 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0547 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0489 - o4_loss: 0.0344 - o5_loss: 0.0295 - o6_loss: 0.0268 - o1_f1: 0.8845 - o2_f1: 0.9694 - o3_f1: 0.9726 - o4_f1: 0.9781 - o5_f1: 0.9820 - o6_f1: 0.9855 - val_loss: 285.3745 - val_o1_loss: 0.3312 - val_o2_loss: 0.3083 - val_o3_loss: 0.3580 - val_o4_loss: 0.4144 - val_o5_loss: 0.4283 - val_o6_loss: 0.4662 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.1178 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0490 - o4_loss: 0.0344 - o5_loss: 0.0296 - o6_loss: 0.0269 - o1_f1: 0.9063 - o2_f1: 0.9783 - o3_f1: 0.9854 - o4_f1: 0.9885 - o5_f1: 0.9922 - o6_f1: 0.9922 - val_loss: 284.9451 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4151 - val_o5_loss: 0.4288 - val_o6_loss: 0.4649 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 22.0538 - o1_loss: 0.2232 - o2_loss: 0.0796 - o3_loss: 0.0489 - o4_loss: 0.0343 - o5_loss: 0.0295 - o6_loss: 0.0268 - o1_f1: 0.9023 - o2_f1: 0.9788 - o3_f1: 0.9861 - o4_f1: 0.9905 - o5_f1: 0.9938 - o6_f1: 0.9936 - val_loss: 285.0037 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4153 - val_o5_loss: 0.4290 - val_o6_loss: 0.4649 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.9615 - o1_loss: 0.2232 - o2_loss: 0.0795 - o3_loss: 0.0488 - o4_loss: 0.0342 - o5_loss: 0.0294 - o6_loss: 0.0266 - o1_f1: 0.8970 - o2_f1: 0.9784 - o3_f1: 0.9836 - o4_f1: 0.9882 - o5_f1: 0.9947 - o6_f1: 0.9947 - val_loss: 285.3583 - val_o1_loss: 0.3310 - val_o2_loss: 0.3083 - val_o3_loss: 0.3582 - val_o4_loss: 0.4148 - val_o5_loss: 0.4286 - val_o6_loss: 0.4660 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.9794 - o1_loss: 0.2232 - o2_loss: 0.0795 - o3_loss: 0.0488 - o4_loss: 0.0342 - o5_loss: 0.0294 - o6_loss: 0.0267 - o1_f1: 0.8980 - o2_f1: 0.9783 - o3_f1: 0.9847 - o4_f1: 0.9876 - o5_f1: 0.9923 - o6_f1: 0.9904 - val_loss: 285.4321 - val_o1_loss: 0.3311 - val_o2_loss: 0.3082 - val_o3_loss: 0.3582 - val_o4_loss: 0.4148 - val_o5_loss: 0.4286 - val_o6_loss: 0.4662 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.9455 - o1_loss: 0.2232 - o2_loss: 0.0795 - o3_loss: 0.0487 - o4_loss: 0.0342 - o5_loss: 0.0293 - o6_loss: 0.0266 - o1_f1: 0.8985 - o2_f1: 0.9760 - o3_f1: 0.9805 - o4_f1: 0.9860 - o5_f1: 0.9932 - o6_f1: 0.9932 - val_loss: 285.3545 - val_o1_loss: 0.3310 - val_o2_loss: 0.3082 - val_o3_loss: 0.3582 - val_o4_loss: 0.4148 - val_o5_loss: 0.4286 - val_o6_loss: 0.4660 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.9158 - o1_loss: 0.2232 - o2_loss: 0.0794 - o3_loss: 0.0486 - o4_loss: 0.0341 - o5_loss: 0.0293 - o6_loss: 0.0266 - o1_f1: 0.9058 - o2_f1: 0.9808 - o3_f1: 0.9842 - o4_f1: 0.9885 - o5_f1: 0.9943 - o6_f1: 0.9943 - val_loss: 285.2477 - val_o1_loss: 0.3310 - val_o2_loss: 0.3082 - val_o3_loss: 0.3582 - val_o4_loss: 0.4149 - val_o5_loss: 0.4287 - val_o6_loss: 0.4657 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.9654 - o1_loss: 0.2231 - o2_loss: 0.0794 - o3_loss: 0.0487 - o4_loss: 0.0342 - o5_loss: 0.0294 - o6_loss: 0.0266 - o1_f1: 0.8911 - o2_f1: 0.9791 - o3_f1: 0.9837 - o4_f1: 0.9881 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.3946 - val_o1_loss: 0.3310 - val_o2_loss: 0.3082 - val_o3_loss: 0.3582 - val_o4_loss: 0.4149 - val_o5_loss: 0.4287 - val_o6_loss: 0.4660 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8905 - o1_loss: 0.2231 - o2_loss: 0.0794 - o3_loss: 0.0486 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.8757 - o2_f1: 0.9779 - o3_f1: 0.9832 - o4_f1: 0.9876 - o5_f1: 0.9945 - o6_f1: 0.9923 - val_loss: 285.1154 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4153 - val_o5_loss: 0.4289 - val_o6_loss: 0.4652 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8963 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0486 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.8951 - o2_f1: 0.9800 - o3_f1: 0.9835 - o4_f1: 0.9877 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 285.4817 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3583 - val_o4_loss: 0.4151 - val_o5_loss: 0.4289 - val_o6_loss: 0.4662 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8585 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0485 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.8877 - o2_f1: 0.9740 - o3_f1: 0.9778 - o4_f1: 0.9812 - o5_f1: 0.9855 - o6_f1: 0.9855 - val_loss: 285.3455 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4152 - val_o5_loss: 0.4290 - val_o6_loss: 0.4658 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8721 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0485 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.8956 - o2_f1: 0.9804 - o3_f1: 0.9833 - o4_f1: 0.9862 - o5_f1: 0.9934 - o6_f1: 0.9906 - val_loss: 285.2941 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4153 - val_o5_loss: 0.4290 - val_o6_loss: 0.4656 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.8646 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0485 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.9029 - o2_f1: 0.9791 - o3_f1: 0.9865 - o4_f1: 0.9906 - o5_f1: 0.9953 - o6_f1: 0.9953 - val_loss: 285.2812 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4153 - val_o5_loss: 0.4289 - val_o6_loss: 0.4656 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.9354 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0486 - o4_loss: 0.0341 - o5_loss: 0.0293 - o6_loss: 0.0266 - o1_f1: 0.8898 - o2_f1: 0.9763 - o3_f1: 0.9813 - o4_f1: 0.9843 - o5_f1: 0.9931 - o6_f1: 0.9909 - val_loss: 285.1670 - val_o1_loss: 0.3308 - val_o2_loss: 0.3082 - val_o3_loss: 0.3586 - val_o4_loss: 0.4156 - val_o5_loss: 0.4292 - val_o6_loss: 0.4652 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8364 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0485 - o4_loss: 0.0339 - o5_loss: 0.0292 - o6_loss: 0.0264 - o1_f1: 0.9039 - o2_f1: 0.9769 - o3_f1: 0.9841 - o4_f1: 0.9885 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.6495 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4153 - val_o5_loss: 0.4291 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8320 - o1_loss: 0.2231 - o2_loss: 0.0792 - o3_loss: 0.0485 - o4_loss: 0.0339 - o5_loss: 0.0291 - o6_loss: 0.0264 - o1_f1: 0.8843 - o2_f1: 0.9758 - o3_f1: 0.9789 - o4_f1: 0.9826 - o5_f1: 0.9933 - o6_f1: 0.9933 - val_loss: 285.6002 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4153 - val_o5_loss: 0.4291 - val_o6_loss: 0.4663 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8755 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0485 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.8960 - o2_f1: 0.9790 - o3_f1: 0.9821 - o4_f1: 0.9848 - o5_f1: 0.9946 - o6_f1: 0.9946 - val_loss: 285.0998 - val_o1_loss: 0.3308 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4155 - val_o5_loss: 0.4290 - val_o6_loss: 0.4651 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8108 - o1_loss: 0.2230 - o2_loss: 0.0792 - o3_loss: 0.0484 - o4_loss: 0.0339 - o5_loss: 0.0291 - o6_loss: 0.0264 - o1_f1: 0.9014 - o2_f1: 0.9805 - o3_f1: 0.9849 - o4_f1: 0.9880 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.6560 - val_o1_loss: 0.3309 - val_o2_loss: 0.3082 - val_o3_loss: 0.3584 - val_o4_loss: 0.4154 - val_o5_loss: 0.4291 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8909 - o1_loss: 0.2231 - o2_loss: 0.0793 - o3_loss: 0.0485 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.9029 - o2_f1: 0.9824 - o3_f1: 0.9870 - o4_f1: 0.9906 - o5_f1: 0.9955 - o6_f1: 0.9940 - val_loss: 285.5699 - val_o1_loss: 0.3308 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4155 - val_o5_loss: 0.4292 - val_o6_loss: 0.4662 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8337 - o1_loss: 0.2230 - o2_loss: 0.0792 - o3_loss: 0.0484 - o4_loss: 0.0339 - o5_loss: 0.0291 - o6_loss: 0.0264 - o1_f1: 0.8875 - o2_f1: 0.9795 - o3_f1: 0.9825 - o4_f1: 0.9879 - o5_f1: 0.9955 - o6_f1: 0.9955 - val_loss: 285.4106 - val_o1_loss: 0.3308 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4154 - val_o5_loss: 0.4290 - val_o6_loss: 0.4659 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.7860 - o1_loss: 0.2230 - o2_loss: 0.0791 - o3_loss: 0.0483 - o4_loss: 0.0338 - o5_loss: 0.0291 - o6_loss: 0.0264 - o1_f1: 0.8932 - o2_f1: 0.9768 - o3_f1: 0.9823 - o4_f1: 0.9867 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 285.2909 - val_o1_loss: 0.3308 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4155 - val_o5_loss: 0.4291 - val_o6_loss: 0.4655 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8506 - o1_loss: 0.2231 - o2_loss: 0.0792 - o3_loss: 0.0485 - o4_loss: 0.0340 - o5_loss: 0.0292 - o6_loss: 0.0265 - o1_f1: 0.9026 - o2_f1: 0.9814 - o3_f1: 0.9849 - o4_f1: 0.9885 - o5_f1: 0.9949 - o6_f1: 0.9949 - val_loss: 285.7418 - val_o1_loss: 0.3309 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4154 - val_o5_loss: 0.4292 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.8333 - o1_loss: 0.2230 - o2_loss: 0.0792 - o3_loss: 0.0484 - o4_loss: 0.0339 - o5_loss: 0.0291 - o6_loss: 0.0264 - o1_f1: 0.9065 - o2_f1: 0.9797 - o3_f1: 0.9884 - o4_f1: 0.9917 - o5_f1: 0.9954 - o6_f1: 0.9954 - val_loss: 285.6927 - val_o1_loss: 0.3309 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4156 - val_o5_loss: 0.4293 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 3s - loss: 21.7730 - o1_loss: 0.2230 - o2_loss: 0.0791 - o3_loss: 0.0483 - o4_loss: 0.0338 - o5_loss: 0.0290 - o6_loss: 0.0263 - o1_f1: 0.8994 - o2_f1: 0.9783 - o3_f1: 0.9827 - o4_f1: 0.9877 - o5_f1: 0.9937 - o6_f1: 0.9937 - val_loss: 285.7436 - val_o1_loss: 0.3309 - val_o2_loss: 0.3081 - val_o3_loss: 0.3585 - val_o4_loss: 0.4155 - val_o5_loss: 0.4292 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.7207 - o1_loss: 0.2230 - o2_loss: 0.0790 - o3_loss: 0.0482 - o4_loss: 0.0337 - o5_loss: 0.0289 - o6_loss: 0.0263 - o1_f1: 0.9012 - o2_f1: 0.9796 - o3_f1: 0.9834 - o4_f1: 0.9884 - o5_f1: 0.9944 - o6_f1: 0.9944 - val_loss: 285.5605 - val_o1_loss: 0.3308 - val_o2_loss: 0.3081 - val_o3_loss: 0.3586 - val_o4_loss: 0.4158 - val_o5_loss: 0.4294 - val_o6_loss: 0.4660 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.7596 - o1_loss: 0.2230 - o2_loss: 0.0790 - o3_loss: 0.0482 - o4_loss: 0.0338 - o5_loss: 0.0290 - o6_loss: 0.0263 - o1_f1: 0.8998 - o2_f1: 0.9801 - o3_f1: 0.9848 - o4_f1: 0.9887 - o5_f1: 0.9956 - o6_f1: 0.9956 - val_loss: 285.4114 - val_o1_loss: 0.3307 - val_o2_loss: 0.3081 - val_o3_loss: 0.3588 - val_o4_loss: 0.4162 - val_o5_loss: 0.4297 - val_o6_loss: 0.4655 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 21.7015 - o1_loss: 0.2229 - o2_loss: 0.0790 - o3_loss: 0.0482 - o4_loss: 0.0337 - o5_loss: 0.0289 - o6_loss: 0.0262 - o1_f1: 0.8975 - o2_f1: 0.9755 - o3_f1: 0.9816 - o4_f1: 0.9854 - o5_f1: 0.9917 - o6_f1: 0.9917 - val_loss: 285.4897 - val_o1_loss: 0.3307 - val_o2_loss: 0.3081 - val_o3_loss: 0.3588 - val_o4_loss: 0.4161 - val_o5_loss: 0.4297 - val_o6_loss: 0.4657 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.7502 - o1_loss: 0.2229 - o2_loss: 0.0790 - o3_loss: 0.0482 - o4_loss: 0.0337 - o5_loss: 0.0290 - o6_loss: 0.0263 - o1_f1: 0.9003 - o2_f1: 0.9744 - o3_f1: 0.9847 - o4_f1: 0.9887 - o5_f1: 0.9936 - o6_f1: 0.9936 - val_loss: 285.4074 - val_o1_loss: 0.3307 - val_o2_loss: 0.3081 - val_o3_loss: 0.3587 - val_o4_loss: 0.4159 - val_o5_loss: 0.4294 - val_o6_loss: 0.4656 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6799 - o1_loss: 0.2229 - o2_loss: 0.0789 - o3_loss: 0.0481 - o4_loss: 0.0336 - o5_loss: 0.0289 - o6_loss: 0.0262 - o1_f1: 0.8890 - o2_f1: 0.9706 - o3_f1: 0.9769 - o4_f1: 0.9808 - o5_f1: 0.9872 - o6_f1: 0.9872 - val_loss: 285.7202 - val_o1_loss: 0.3307 - val_o2_loss: 0.3081 - val_o3_loss: 0.3587 - val_o4_loss: 0.4160 - val_o5_loss: 0.4297 - val_o6_loss: 0.4663 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6805 - o1_loss: 0.2229 - o2_loss: 0.0789 - o3_loss: 0.0481 - o4_loss: 0.0336 - o5_loss: 0.0289 - o6_loss: 0.0262 - o1_f1: 0.8922 - o2_f1: 0.9799 - o3_f1: 0.9830 - o4_f1: 0.9887 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 286.0446 - val_o1_loss: 0.3308 - val_o2_loss: 0.3081 - val_o3_loss: 0.3586 - val_o4_loss: 0.4157 - val_o5_loss: 0.4295 - val_o6_loss: 0.4672 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.7325 - o1_loss: 0.2229 - o2_loss: 0.0789 - o3_loss: 0.0482 - o4_loss: 0.0337 - o5_loss: 0.0290 - o6_loss: 0.0263 - o1_f1: 0.8861 - o2_f1: 0.9696 - o3_f1: 0.9740 - o4_f1: 0.9779 - o5_f1: 0.9859 - o6_f1: 0.9859 - val_loss: 285.7680 - val_o1_loss: 0.3307 - val_o2_loss: 0.3081 - val_o3_loss: 0.3587 - val_o4_loss: 0.4160 - val_o5_loss: 0.4296 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6636 - o1_loss: 0.2229 - o2_loss: 0.0789 - o3_loss: 0.0481 - o4_loss: 0.0336 - o5_loss: 0.0288 - o6_loss: 0.0262 - o1_f1: 0.9127 - o2_f1: 0.9801 - o3_f1: 0.9834 - o4_f1: 0.9868 - o5_f1: 0.9917 - o6_f1: 0.9917 - val_loss: 285.2859 - val_o1_loss: 0.3305 - val_o2_loss: 0.3080 - val_o3_loss: 0.3590 - val_o4_loss: 0.4164 - val_o5_loss: 0.4297 - val_o6_loss: 0.4651 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5174\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.7073 - o1_loss: 0.2230 - o2_loss: 0.0789 - o3_loss: 0.0481 - o4_loss: 0.0337 - o5_loss: 0.0289 - o6_loss: 0.0262 - o1_f1: 0.8966 - o2_f1: 0.9779 - o3_f1: 0.9835 - o4_f1: 0.9870 - o5_f1: 0.9923 - o6_f1: 0.9923 - val_loss: 286.2567 - val_o1_loss: 0.3307 - val_o2_loss: 0.3081 - val_o3_loss: 0.3586 - val_o4_loss: 0.4159 - val_o5_loss: 0.4298 - val_o6_loss: 0.4676 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6609 - o1_loss: 0.2229 - o2_loss: 0.0789 - o3_loss: 0.0480 - o4_loss: 0.0336 - o5_loss: 0.0288 - o6_loss: 0.0262 - o1_f1: 0.9028 - o2_f1: 0.9777 - o3_f1: 0.9823 - o4_f1: 0.9858 - o5_f1: 0.9944 - o6_f1: 0.9944 - val_loss: 285.8042 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3589 - val_o4_loss: 0.4163 - val_o5_loss: 0.4300 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6826 - o1_loss: 0.2229 - o2_loss: 0.0788 - o3_loss: 0.0480 - o4_loss: 0.0336 - o5_loss: 0.0289 - o6_loss: 0.0262 - o1_f1: 0.9049 - o2_f1: 0.9788 - o3_f1: 0.9843 - o4_f1: 0.9873 - o5_f1: 0.9926 - o6_f1: 0.9926 - val_loss: 286.0937 - val_o1_loss: 0.3307 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4162 - val_o5_loss: 0.4299 - val_o6_loss: 0.4671 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6018 - o1_loss: 0.2229 - o2_loss: 0.0788 - o3_loss: 0.0479 - o4_loss: 0.0335 - o5_loss: 0.0287 - o6_loss: 0.0261 - o1_f1: 0.9029 - o2_f1: 0.9817 - o3_f1: 0.9852 - o4_f1: 0.9883 - o5_f1: 0.9947 - o6_f1: 0.9947 - val_loss: 285.8751 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4162 - val_o5_loss: 0.4298 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6104 - o1_loss: 0.2229 - o2_loss: 0.0788 - o3_loss: 0.0479 - o4_loss: 0.0335 - o5_loss: 0.0287 - o6_loss: 0.0261 - o1_f1: 0.9022 - o2_f1: 0.9795 - o3_f1: 0.9833 - o4_f1: 0.9872 - o5_f1: 0.9927 - o6_f1: 0.9927 - val_loss: 285.7649 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4663 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6016 - o1_loss: 0.2229 - o2_loss: 0.0788 - o3_loss: 0.0479 - o4_loss: 0.0335 - o5_loss: 0.0287 - o6_loss: 0.0261 - o1_f1: 0.9065 - o2_f1: 0.9770 - o3_f1: 0.9847 - o4_f1: 0.9883 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 285.9491 - val_o1_loss: 0.3305 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4163 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6078 - o1_loss: 0.2229 - o2_loss: 0.0788 - o3_loss: 0.0479 - o4_loss: 0.0335 - o5_loss: 0.0288 - o6_loss: 0.0261 - o1_f1: 0.9089 - o2_f1: 0.9811 - o3_f1: 0.9857 - o4_f1: 0.9884 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 286.1000 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3587 - val_o4_loss: 0.4161 - val_o5_loss: 0.4298 - val_o6_loss: 0.4672 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
      " - 2s - loss: 21.6160 - o1_loss: 0.2229 - o2_loss: 0.0788 - o3_loss: 0.0479 - o4_loss: 0.0335 - o5_loss: 0.0288 - o6_loss: 0.0261 - o1_f1: 0.9075 - o2_f1: 0.9814 - o3_f1: 0.9852 - o4_f1: 0.9883 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 286.0695 - val_o1_loss: 0.3307 - val_o2_loss: 0.3080 - val_o3_loss: 0.3587 - val_o4_loss: 0.4161 - val_o5_loss: 0.4297 - val_o6_loss: 0.4671 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 3.90625e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.5423 - o1_loss: 0.2228 - o2_loss: 0.0787 - o3_loss: 0.0478 - o4_loss: 0.0334 - o5_loss: 0.0286 - o6_loss: 0.0260 - o1_f1: 0.8969 - o2_f1: 0.9778 - o3_f1: 0.9810 - o4_f1: 0.9865 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 286.0210 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4161 - val_o5_loss: 0.4297 - val_o6_loss: 0.4670 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5220 - o1_loss: 0.2228 - o2_loss: 0.0787 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0260 - o1_f1: 0.8792 - o2_f1: 0.9777 - o3_f1: 0.9808 - o4_f1: 0.9870 - o5_f1: 0.9944 - o6_f1: 0.9944 - val_loss: 285.9277 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4162 - val_o5_loss: 0.4298 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5239 - o1_loss: 0.2228 - o2_loss: 0.0787 - o3_loss: 0.0478 - o4_loss: 0.0334 - o5_loss: 0.0286 - o6_loss: 0.0260 - o1_f1: 0.9018 - o2_f1: 0.9811 - o3_f1: 0.9853 - o4_f1: 0.9881 - o5_f1: 0.9931 - o6_f1: 0.9931 - val_loss: 285.9206 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4162 - val_o5_loss: 0.4297 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5287 - o1_loss: 0.2228 - o2_loss: 0.0787 - o3_loss: 0.0478 - o4_loss: 0.0334 - o5_loss: 0.0286 - o6_loss: 0.0260 - o1_f1: 0.8883 - o2_f1: 0.9763 - o3_f1: 0.9797 - o4_f1: 0.9873 - o5_f1: 0.9944 - o6_f1: 0.9944 - val_loss: 285.9410 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4162 - val_o5_loss: 0.4298 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5306 - o1_loss: 0.2228 - o2_loss: 0.0787 - o3_loss: 0.0478 - o4_loss: 0.0334 - o5_loss: 0.0286 - o6_loss: 0.0260 - o1_f1: 0.9022 - o2_f1: 0.9815 - o3_f1: 0.9856 - o4_f1: 0.9890 - o5_f1: 0.9948 - o6_f1: 0.9948 - val_loss: 285.9155 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5181 - o1_loss: 0.2228 - o2_loss: 0.0787 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.9093 - o2_f1: 0.9802 - o3_f1: 0.9837 - o4_f1: 0.9883 - o5_f1: 0.9935 - o6_f1: 0.9935 - val_loss: 285.9191 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5145 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.8923 - o2_f1: 0.9688 - o3_f1: 0.9759 - o4_f1: 0.9800 - o5_f1: 0.9855 - o6_f1: 0.9855 - val_loss: 285.8845 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3588 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5198 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0260 - o1_f1: 0.8974 - o2_f1: 0.9794 - o3_f1: 0.9844 - o4_f1: 0.9873 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 285.8918 - val_o1_loss: 0.3306 - val_o2_loss: 0.3080 - val_o3_loss: 0.3589 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5018 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.8989 - o2_f1: 0.9836 - o3_f1: 0.9867 - o4_f1: 0.9904 - o5_f1: 0.9957 - o6_f1: 0.9957 - val_loss: 285.8383 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4298 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5119 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.9045 - o2_f1: 0.9759 - o3_f1: 0.9830 - o4_f1: 0.9876 - o5_f1: 0.9937 - o6_f1: 0.9937 - val_loss: 285.8534 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4980 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.8968 - o2_f1: 0.9759 - o3_f1: 0.9783 - o4_f1: 0.9819 - o5_f1: 0.9868 - o6_f1: 0.9868 - val_loss: 285.8661 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5194 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.8910 - o2_f1: 0.9709 - o3_f1: 0.9738 - o4_f1: 0.9771 - o5_f1: 0.9834 - o6_f1: 0.9834 - val_loss: 285.8631 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5014 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.9047 - o2_f1: 0.9752 - o3_f1: 0.9790 - o4_f1: 0.9838 - o5_f1: 0.9922 - o6_f1: 0.9922 - val_loss: 285.8394 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4298 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5098 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0478 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.8763 - o2_f1: 0.9727 - o3_f1: 0.9762 - o4_f1: 0.9804 - o5_f1: 0.9858 - o6_f1: 0.9858 - val_loss: 285.8337 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 3.90625e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.4833 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.8836 - o2_f1: 0.9787 - o3_f1: 0.9824 - o4_f1: 0.9890 - o5_f1: 0.9946 - o6_f1: 0.9946 - val_loss: 285.8642 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.5026 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.9082 - o2_f1: 0.9804 - o3_f1: 0.9831 - o4_f1: 0.9873 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 285.8675 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4298 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4872 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9018 - o2_f1: 0.9786 - o3_f1: 0.9829 - o4_f1: 0.9878 - o5_f1: 0.9936 - o6_f1: 0.9936 - val_loss: 285.9447 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4298 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4817 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9008 - o2_f1: 0.9784 - o3_f1: 0.9822 - o4_f1: 0.9885 - o5_f1: 0.9952 - o6_f1: 0.9952 - val_loss: 285.9299 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4952 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0286 - o6_loss: 0.0259 - o1_f1: 0.8942 - o2_f1: 0.9809 - o3_f1: 0.9838 - o4_f1: 0.9902 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 285.9410 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4856 - o1_loss: 0.2227 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.8956 - o2_f1: 0.9671 - o3_f1: 0.9774 - o4_f1: 0.9819 - o5_f1: 0.9887 - o6_f1: 0.9887 - val_loss: 285.8843 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4805 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9129 - o2_f1: 0.9815 - o3_f1: 0.9859 - o4_f1: 0.9889 - o5_f1: 0.9954 - o6_f1: 0.9954 - val_loss: 286.0184 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3588 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4669 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4716 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9124 - o2_f1: 0.9830 - o3_f1: 0.9869 - o4_f1: 0.9897 - o5_f1: 0.9947 - o6_f1: 0.9947 - val_loss: 285.9575 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4163 - val_o5_loss: 0.4298 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4651 - o1_loss: 0.2227 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.8974 - o2_f1: 0.9754 - o3_f1: 0.9818 - o4_f1: 0.9857 - o5_f1: 0.9918 - o6_f1: 0.9918 - val_loss: 285.9325 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4863 - o1_loss: 0.2228 - o2_loss: 0.0786 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9032 - o2_f1: 0.9823 - o3_f1: 0.9861 - o4_f1: 0.9886 - o5_f1: 0.9936 - o6_f1: 0.9936 - val_loss: 285.9770 - val_o1_loss: 0.3306 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4814 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0477 - o4_loss: 0.0333 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9043 - o2_f1: 0.9814 - o3_f1: 0.9855 - o4_f1: 0.9894 - o5_f1: 0.9961 - o6_f1: 0.9961 - val_loss: 285.9281 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4559 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0477 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8949 - o2_f1: 0.9798 - o3_f1: 0.9843 - o4_f1: 0.9887 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 285.9024 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4615 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0477 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.8949 - o2_f1: 0.9788 - o3_f1: 0.9835 - o4_f1: 0.9884 - o5_f1: 0.9952 - o6_f1: 0.9952 - val_loss: 285.9321 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4164 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4605 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0477 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9048 - o2_f1: 0.9792 - o3_f1: 0.9835 - o4_f1: 0.9865 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 285.8140 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4663 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 3.90625e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.4647 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0477 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.8877 - o2_f1: 0.9728 - o3_f1: 0.9773 - o4_f1: 0.9875 - o5_f1: 0.9938 - o6_f1: 0.9938 - val_loss: 285.8462 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4691 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0477 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0259 - o1_f1: 0.9017 - o2_f1: 0.9812 - o3_f1: 0.9843 - o4_f1: 0.9874 - o5_f1: 0.9940 - o6_f1: 0.9940 - val_loss: 285.9136 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4510 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8971 - o2_f1: 0.9704 - o3_f1: 0.9761 - o4_f1: 0.9808 - o5_f1: 0.9866 - o6_f1: 0.9866 - val_loss: 285.9405 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4491 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8878 - o2_f1: 0.9810 - o3_f1: 0.9844 - o4_f1: 0.9883 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.9459 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4365 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8918 - o2_f1: 0.9793 - o3_f1: 0.9829 - o4_f1: 0.9868 - o5_f1: 0.9948 - o6_f1: 0.9948 - val_loss: 285.8553 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4299 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4423 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8954 - o2_f1: 0.9700 - o3_f1: 0.9739 - o4_f1: 0.9775 - o5_f1: 0.9849 - o6_f1: 0.9849 - val_loss: 285.8627 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4299 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4387 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8967 - o2_f1: 0.9773 - o3_f1: 0.9817 - o4_f1: 0.9867 - o5_f1: 0.9941 - o6_f1: 0.9941 - val_loss: 285.9402 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4300 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4328 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8948 - o2_f1: 0.9806 - o3_f1: 0.9845 - o4_f1: 0.9883 - o5_f1: 0.9927 - o6_f1: 0.9927 - val_loss: 285.9217 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4303 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0285 - o6_loss: 0.0258 - o1_f1: 0.8959 - o2_f1: 0.9836 - o3_f1: 0.9872 - o4_f1: 0.9901 - o5_f1: 0.9952 - o6_f1: 0.9952 - val_loss: 285.8820 - val_o1_loss: 0.3304 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4281 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.9004 - o2_f1: 0.9825 - o3_f1: 0.9864 - o4_f1: 0.9895 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 285.8809 - val_o1_loss: 0.3304 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4242 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8996 - o2_f1: 0.9725 - o3_f1: 0.9775 - o4_f1: 0.9805 - o5_f1: 0.9855 - o6_f1: 0.9855 - val_loss: 285.8915 - val_o1_loss: 0.3304 - val_o2_loss: 0.3079 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4217 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.9037 - o2_f1: 0.9817 - o3_f1: 0.9850 - o4_f1: 0.9895 - o5_f1: 0.9933 - o6_f1: 0.9933 - val_loss: 285.8683 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4237 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8991 - o2_f1: 0.9815 - o3_f1: 0.9850 - o4_f1: 0.9881 - o5_f1: 0.9922 - o6_f1: 0.9922 - val_loss: 285.9647 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4245 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.9103 - o2_f1: 0.9818 - o3_f1: 0.9860 - o4_f1: 0.9901 - o5_f1: 0.9957 - o6_f1: 0.9957 - val_loss: 286.0064 - val_o1_loss: 0.3305 - val_o2_loss: 0.3079 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 3.90625e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.4313 - o1_loss: 0.2227 - o2_loss: 0.0785 - o3_loss: 0.0476 - o4_loss: 0.0332 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.9100 - o2_f1: 0.9791 - o3_f1: 0.9833 - o4_f1: 0.9870 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 285.9041 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4203 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0476 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8945 - o2_f1: 0.9710 - o3_f1: 0.9819 - o4_f1: 0.9864 - o5_f1: 0.9936 - o6_f1: 0.9936 - val_loss: 285.8738 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4047 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.9083 - o2_f1: 0.9784 - o3_f1: 0.9831 - o4_f1: 0.9862 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.9619 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4145 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.9025 - o2_f1: 0.9770 - o3_f1: 0.9807 - o4_f1: 0.9851 - o5_f1: 0.9923 - o6_f1: 0.9923 - val_loss: 285.9931 - val_o1_loss: 0.3305 - val_o2_loss: 0.3078 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.3998 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8975 - o2_f1: 0.9805 - o3_f1: 0.9838 - o4_f1: 0.9868 - o5_f1: 0.9931 - o6_f1: 0.9931 - val_loss: 285.9104 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4086 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8962 - o2_f1: 0.9798 - o3_f1: 0.9829 - o4_f1: 0.9871 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 285.8617 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4664 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4191 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0476 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8967 - o2_f1: 0.9726 - o3_f1: 0.9765 - o4_f1: 0.9798 - o5_f1: 0.9884 - o6_f1: 0.9884 - val_loss: 286.0487 - val_o1_loss: 0.3305 - val_o2_loss: 0.3078 - val_o3_loss: 0.3589 - val_o4_loss: 0.4165 - val_o5_loss: 0.4299 - val_o6_loss: 0.4669 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 3.90625e-06.\n",
      " - 2s - loss: 21.4018 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0258 - o1_f1: 0.8949 - o2_f1: 0.9812 - o3_f1: 0.9848 - o4_f1: 0.9886 - o5_f1: 0.9933 - o6_f1: 0.9933 - val_loss: 285.9034 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3815 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9043 - o2_f1: 0.9813 - o3_f1: 0.9850 - o4_f1: 0.9890 - o5_f1: 0.9944 - o6_f1: 0.9944 - val_loss: 285.9170 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3813 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8905 - o2_f1: 0.9790 - o3_f1: 0.9831 - o4_f1: 0.9867 - o5_f1: 0.9931 - o6_f1: 0.9931 - val_loss: 285.9172 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3857 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9055 - o2_f1: 0.9818 - o3_f1: 0.9852 - o4_f1: 0.9894 - o5_f1: 0.9943 - o6_f1: 0.9943 - val_loss: 285.9323 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3801 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8934 - o2_f1: 0.9831 - o3_f1: 0.9866 - o4_f1: 0.9905 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 285.9102 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 3s - loss: 21.3788 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8845 - o2_f1: 0.9764 - o3_f1: 0.9825 - o4_f1: 0.9876 - o5_f1: 0.9935 - o6_f1: 0.9935 - val_loss: 285.9164 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3801 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8936 - o2_f1: 0.9798 - o3_f1: 0.9835 - o4_f1: 0.9867 - o5_f1: 0.9917 - o6_f1: 0.9917 - val_loss: 285.8875 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 9.765625e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.3769 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8956 - o2_f1: 0.9801 - o3_f1: 0.9859 - o4_f1: 0.9890 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 285.9024 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3801 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8938 - o2_f1: 0.9787 - o3_f1: 0.9819 - o4_f1: 0.9857 - o5_f1: 0.9937 - o6_f1: 0.9937 - val_loss: 285.9182 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3793 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9028 - o2_f1: 0.9801 - o3_f1: 0.9836 - o4_f1: 0.9870 - o5_f1: 0.9924 - o6_f1: 0.9924 - val_loss: 285.9155 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3782 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9051 - o2_f1: 0.9836 - o3_f1: 0.9868 - o4_f1: 0.9897 - o5_f1: 0.9955 - o6_f1: 0.9955 - val_loss: 285.9008 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3787 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9014 - o2_f1: 0.9800 - o3_f1: 0.9852 - o4_f1: 0.9891 - o5_f1: 0.9947 - o6_f1: 0.9947 - val_loss: 285.9135 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3767 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9034 - o2_f1: 0.9828 - o3_f1: 0.9861 - o4_f1: 0.9888 - o5_f1: 0.9938 - o6_f1: 0.9938 - val_loss: 285.8998 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3738 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8963 - o2_f1: 0.9790 - o3_f1: 0.9839 - o4_f1: 0.9886 - o5_f1: 0.9949 - o6_f1: 0.9949 - val_loss: 285.9009 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3821 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9031 - o2_f1: 0.9850 - o3_f1: 0.9878 - o4_f1: 0.9909 - o5_f1: 0.9961 - o6_f1: 0.9961 - val_loss: 285.9303 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3747 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9059 - o2_f1: 0.9811 - o3_f1: 0.9857 - o4_f1: 0.9889 - o5_f1: 0.9933 - o6_f1: 0.9933 - val_loss: 285.9226 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3777 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8888 - o2_f1: 0.9737 - o3_f1: 0.9775 - o4_f1: 0.9810 - o5_f1: 0.9859 - o6_f1: 0.9859 - val_loss: 285.9127 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3767 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9057 - o2_f1: 0.9810 - o3_f1: 0.9857 - o4_f1: 0.9893 - o5_f1: 0.9954 - o6_f1: 0.9954 - val_loss: 285.9264 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3702 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9006 - o2_f1: 0.9782 - o3_f1: 0.9817 - o4_f1: 0.9853 - o5_f1: 0.9926 - o6_f1: 0.9926 - val_loss: 285.9124 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3694 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8915 - o2_f1: 0.9650 - o3_f1: 0.9747 - o4_f1: 0.9786 - o5_f1: 0.9853 - o6_f1: 0.9853 - val_loss: 285.9094 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3691 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9056 - o2_f1: 0.9777 - o3_f1: 0.9862 - o4_f1: 0.9892 - o5_f1: 0.9948 - o6_f1: 0.9948 - val_loss: 285.9244 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 9.765625e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.3722 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8963 - o2_f1: 0.9712 - o3_f1: 0.9751 - o4_f1: 0.9793 - o5_f1: 0.9856 - o6_f1: 0.9856 - val_loss: 285.9218 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3686 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8965 - o2_f1: 0.9799 - o3_f1: 0.9830 - o4_f1: 0.9861 - o5_f1: 0.9933 - o6_f1: 0.9933 - val_loss: 285.9266 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3674 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8993 - o2_f1: 0.9804 - o3_f1: 0.9830 - o4_f1: 0.9875 - o5_f1: 0.9926 - o6_f1: 0.9926 - val_loss: 285.9204 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3701 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9063 - o2_f1: 0.9716 - o3_f1: 0.9778 - o4_f1: 0.9861 - o5_f1: 0.9927 - o6_f1: 0.9927 - val_loss: 285.8985 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3661 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9092 - o2_f1: 0.9823 - o3_f1: 0.9851 - o4_f1: 0.9898 - o5_f1: 0.9956 - o6_f1: 0.9956 - val_loss: 285.9201 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3676 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8953 - o2_f1: 0.9794 - o3_f1: 0.9846 - o4_f1: 0.9884 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.9359 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3729 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.9046 - o2_f1: 0.9811 - o3_f1: 0.9850 - o4_f1: 0.9881 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.9087 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4168 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3641 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9017 - o2_f1: 0.9786 - o3_f1: 0.9817 - o4_f1: 0.9855 - o5_f1: 0.9949 - o6_f1: 0.9949 - val_loss: 285.9151 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3622 - o1_loss: 0.2226 - o2_loss: 0.0784 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8804 - o2_f1: 0.9788 - o3_f1: 0.9827 - o4_f1: 0.9881 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 285.9153 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3738 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0331 - o5_loss: 0.0284 - o6_loss: 0.0257 - o1_f1: 0.8985 - o2_f1: 0.9807 - o3_f1: 0.9839 - o4_f1: 0.9893 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 285.9043 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4665 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3624 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8974 - o2_f1: 0.9792 - o3_f1: 0.9827 - o4_f1: 0.9869 - o5_f1: 0.9922 - o6_f1: 0.9922 - val_loss: 285.9792 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3653 - o1_loss: 0.2227 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8948 - o2_f1: 0.9776 - o3_f1: 0.9815 - o4_f1: 0.9854 - o5_f1: 0.9943 - o6_f1: 0.9943 - val_loss: 285.9910 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3653 - o1_loss: 0.2226 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9033 - o2_f1: 0.9796 - o3_f1: 0.9846 - o4_f1: 0.9884 - o5_f1: 0.9940 - o6_f1: 0.9940 - val_loss: 285.9530 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3631 - o1_loss: 0.2226 - o2_loss: 0.0784 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8862 - o2_f1: 0.9714 - o3_f1: 0.9744 - o4_f1: 0.9804 - o5_f1: 0.9924 - o6_f1: 0.9924 - val_loss: 285.9935 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 9.765625e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.3654 - o1_loss: 0.2226 - o2_loss: 0.0784 - o3_loss: 0.0475 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8903 - o2_f1: 0.9818 - o3_f1: 0.9854 - o4_f1: 0.9885 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 285.9711 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3599 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9023 - o2_f1: 0.9762 - o3_f1: 0.9816 - o4_f1: 0.9863 - o5_f1: 0.9927 - o6_f1: 0.9927 - val_loss: 285.9914 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3580 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9090 - o2_f1: 0.9840 - o3_f1: 0.9869 - o4_f1: 0.9898 - o5_f1: 0.9951 - o6_f1: 0.9951 - val_loss: 285.9798 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3559 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8993 - o2_f1: 0.9797 - o3_f1: 0.9836 - o4_f1: 0.9885 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 286.0026 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3554 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9075 - o2_f1: 0.9810 - o3_f1: 0.9849 - o4_f1: 0.9878 - o5_f1: 0.9952 - o6_f1: 0.9952 - val_loss: 286.0022 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4667 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3629 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9035 - o2_f1: 0.9826 - o3_f1: 0.9865 - o4_f1: 0.9898 - o5_f1: 0.9956 - o6_f1: 0.9956 - val_loss: 285.9608 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4666 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3551 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9074 - o2_f1: 0.9769 - o3_f1: 0.9826 - o4_f1: 0.9873 - o5_f1: 0.9931 - o6_f1: 0.9931 - val_loss: 286.0344 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3540 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8998 - o2_f1: 0.9819 - o3_f1: 0.9861 - o4_f1: 0.9888 - o5_f1: 0.9941 - o6_f1: 0.9941 - val_loss: 286.0333 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3585 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8849 - o2_f1: 0.9828 - o3_f1: 0.9858 - o4_f1: 0.9908 - o5_f1: 0.9958 - o6_f1: 0.9958 - val_loss: 286.0354 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3623 - o1_loss: 0.2227 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8954 - o2_f1: 0.9654 - o3_f1: 0.9717 - o4_f1: 0.9750 - o5_f1: 0.9865 - o6_f1: 0.9865 - val_loss: 286.0484 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4669 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3520 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8876 - o2_f1: 0.9745 - o3_f1: 0.9815 - o4_f1: 0.9857 - o5_f1: 0.9920 - o6_f1: 0.9920 - val_loss: 286.0272 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3534 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9063 - o2_f1: 0.9789 - o3_f1: 0.9841 - o4_f1: 0.9881 - o5_f1: 0.9945 - o6_f1: 0.9945 - val_loss: 286.0293 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3532 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9057 - o2_f1: 0.9806 - o3_f1: 0.9850 - o4_f1: 0.9890 - o5_f1: 0.9942 - o6_f1: 0.9942 - val_loss: 286.0698 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4669 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3554 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8887 - o2_f1: 0.9721 - o3_f1: 0.9758 - o4_f1: 0.9895 - o5_f1: 0.9933 - o6_f1: 0.9933 - val_loss: 286.0799 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4166 - val_o5_loss: 0.4300 - val_o6_loss: 0.4670 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 9.765625e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 21.3598 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8917 - o2_f1: 0.9769 - o3_f1: 0.9811 - o4_f1: 0.9852 - o5_f1: 0.9923 - o6_f1: 0.9923 - val_loss: 286.0549 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4669 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 9.765625e-07.\n",
      " - 2s - loss: 21.3531 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.9012 - o2_f1: 0.9844 - o3_f1: 0.9872 - o4_f1: 0.9908 - o5_f1: 0.9950 - o6_f1: 0.9950 - val_loss: 286.0433 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4301 - val_o6_loss: 0.4668 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 2.44140625e-07.\n",
      " - 2s - loss: 21.3470 - o1_loss: 0.2226 - o2_loss: 0.0783 - o3_loss: 0.0474 - o4_loss: 0.0330 - o5_loss: 0.0283 - o6_loss: 0.0257 - o1_f1: 0.8971 - o2_f1: 0.9771 - o3_f1: 0.9821 - o4_f1: 0.9868 - o5_f1: 0.9939 - o6_f1: 0.9939 - val_loss: 286.0467 - val_o1_loss: 0.3304 - val_o2_loss: 0.3078 - val_o3_loss: 0.3590 - val_o4_loss: 0.4167 - val_o5_loss: 0.4300 - val_o6_loss: 0.4669 - val_o1_f1: 0.4960 - val_o2_f1: 0.5134 - val_o3_f1: 0.5352 - val_o4_f1: 0.5352 - val_o5_f1: 0.5352 - val_o6_f1: 0.5289\n",
      "['val_o1_loss', 'val_o2_loss', 'val_o3_loss', 'val_o4_loss', 'val_o5_loss', 'val_o6_loss']\n",
      "['o1_loss', 'o2_loss', 'o3_loss', 'o4_loss', 'o5_loss', 'o6_loss']\n",
      "['lr', 'o1_f1', 'o2_f1', 'o3_f1', 'o4_f1', 'o5_f1', 'o6_f1', 'val_o1_f1', 'val_o2_f1', 'val_o3_f1', 'val_o4_f1', 'val_o5_f1', 'val_o6_f1']\n",
      "(807, 1)\n",
      "[0.1  0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23\n",
      " 0.24 0.25 0.26 0.27 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37\n",
      " 0.38 0.39 0.4  0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51\n",
      " 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65\n",
      " 0.66 0.67 0.68 0.69 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79\n",
      " 0.8  0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89]\n",
      "    accuracy        f1  precision    recall    th\n",
      "0   0.957869  0.939502   0.891892  0.992481  0.10\n",
      "1   0.964064  0.947935   0.907216  0.992481  0.11\n",
      "2   0.971499  0.958258   0.926316  0.992481  0.12\n",
      "3   0.982652  0.974170   0.956522  0.992481  0.13\n",
      "4   0.990087  0.985075   0.977778  0.992481  0.14\n",
      "5   0.991326  0.986916   0.981413  0.992481  0.15\n",
      "6   0.992565  0.988764   0.985075  0.992481  0.16\n",
      "7   0.993804  0.990619   0.988764  0.992481  0.17\n",
      "8   0.993804  0.990619   0.988764  0.992481  0.18\n",
      "9   0.993804  0.990619   0.988764  0.992481  0.19\n",
      "10  0.995043  0.992481   0.992481  0.992481  0.20\n",
      "11  0.996283  0.994350   0.996226  0.992481  0.21\n",
      "12  0.996283  0.994350   0.996226  0.992481  0.22\n",
      "13  0.996283  0.994350   0.996226  0.992481  0.23\n",
      "14  0.996283  0.994350   0.996226  0.992481  0.24\n",
      "15  0.996283  0.994350   0.996226  0.992481  0.25\n",
      "16  0.995043  0.992453   0.996212  0.988722  0.26\n",
      "17  0.995043  0.992453   0.996212  0.988722  0.27\n",
      "18  0.995043  0.992453   0.996212  0.988722  0.28\n",
      "19  0.995043  0.992453   0.996212  0.988722  0.29\n",
      "20  0.995043  0.992453   0.996212  0.988722  0.30\n",
      "21  0.995043  0.992453   0.996212  0.988722  0.31\n",
      "22  0.995043  0.992453   0.996212  0.988722  0.32\n",
      "23  0.995043  0.992453   0.996212  0.988722  0.33\n",
      "24  0.995043  0.992453   0.996212  0.988722  0.34\n",
      "25  0.995043  0.992453   0.996212  0.988722  0.35\n",
      "26  0.995043  0.992453   0.996212  0.988722  0.36\n",
      "27  0.995043  0.992453   0.996212  0.988722  0.37\n",
      "28  0.995043  0.992453   0.996212  0.988722  0.38\n",
      "29  0.995043  0.992453   0.996212  0.988722  0.39\n",
      "..       ...       ...        ...       ...   ...\n",
      "50  0.991326  0.986667   1.000000  0.973684  0.60\n",
      "51  0.991326  0.986667   1.000000  0.973684  0.61\n",
      "52  0.988848  0.982792   1.000000  0.966165  0.62\n",
      "53  0.988848  0.982792   1.000000  0.966165  0.63\n",
      "54  0.988848  0.982792   1.000000  0.966165  0.64\n",
      "55  0.987608  0.980843   1.000000  0.962406  0.65\n",
      "56  0.987608  0.980843   1.000000  0.962406  0.66\n",
      "57  0.987608  0.980843   1.000000  0.962406  0.67\n",
      "58  0.986369  0.978887   1.000000  0.958647  0.68\n",
      "59  0.986369  0.978887   1.000000  0.958647  0.69\n",
      "60  0.986369  0.978887   1.000000  0.958647  0.70\n",
      "61  0.986369  0.978887   1.000000  0.958647  0.71\n",
      "62  0.986369  0.978887   1.000000  0.958647  0.72\n",
      "63  0.983891  0.974952   1.000000  0.951128  0.73\n",
      "64  0.982652  0.972973   1.000000  0.947368  0.74\n",
      "65  0.980173  0.968992   1.000000  0.939850  0.75\n",
      "66  0.980173  0.968992   1.000000  0.939850  0.76\n",
      "67  0.980173  0.968992   1.000000  0.939850  0.77\n",
      "68  0.977695  0.964981   1.000000  0.932331  0.78\n",
      "69  0.976456  0.962963   1.000000  0.928571  0.79\n",
      "70  0.976456  0.962963   1.000000  0.928571  0.80\n",
      "71  0.972739  0.956863   1.000000  0.917293  0.81\n",
      "72  0.967782  0.948617   1.000000  0.902256  0.82\n",
      "73  0.960347  0.936000   1.000000  0.879699  0.83\n",
      "74  0.955390  0.927419   1.000000  0.864662  0.84\n",
      "75  0.949195  0.916497   1.000000  0.845865  0.85\n",
      "76  0.941760  0.903093   1.000000  0.823308  0.86\n",
      "77  0.933086  0.887029   1.000000  0.796992  0.87\n",
      "78  0.924411  0.870488   1.000000  0.770677  0.88\n",
      "79  0.916976  0.855914   1.000000  0.748120  0.89\n",
      "\n",
      "[80 rows x 5 columns]\n",
      "prediction threshold 0.21\n",
      "layer # 0, layer name inputs,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "inputs\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe35cbdccd0> None\n",
      "input dimensions (None, 27687)\n",
      "inputs\n",
      "model.inputs [<tf.Tensor 'inputs_1:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_1/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_1/Tanh\n",
      "h1_1/Tanh\n",
      "h2_1/Tanh\n",
      "h3_1/Tanh\n",
      "h4_1/Tanh\n",
      "h5_1/Tanh\n",
      "o6_1/Sigmoid\n",
      "ins [<tf.Tensor 'h0_1/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_1/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_1/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_1/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_1/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_1/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_1/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_1:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 27687)\n",
      "gradients.shape (807, 27687)\n",
      "feature_weights.shape (27687,)\n",
      "feature_weights min max -3.2749982 49.658566\n",
      "layer # 1, layer name h0,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "h0\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe35cbdc9d0> None\n",
      "input dimensions (None, 27687)\n",
      "h0\n",
      "model.inputs [<tf.Tensor 'inputs_2:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_2/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h0_2/Tanh:0\", shape=(?, 9229), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_2/Tanh\n",
      "h1_2/Tanh\n",
      "h2_2/Tanh\n",
      "h3_2/Tanh\n",
      "h4_2/Tanh\n",
      "h5_2/Tanh\n",
      "o6_2/Sigmoid\n",
      "ins [<tf.Tensor 'h0_2/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_2/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_2/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_2/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_2/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_2/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_2/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_2:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inputs_2:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_2:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 9229)\n",
      "gradients.shape (807, 9229)\n",
      "feature_weights.shape (9229,)\n",
      "feature_weights min max -3.2947774 66.77785\n",
      "layer # 2, layer name h1,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "h1\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe35cde6750> None\n",
      "input dimensions (None, 27687)\n",
      "h1\n",
      "model.inputs [<tf.Tensor 'inputs_3:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_3/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h1_3/Tanh:0\", shape=(?, 1387), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_3/Tanh\n",
      "h1_3/Tanh\n",
      "h2_3/Tanh\n",
      "h3_3/Tanh\n",
      "h4_3/Tanh\n",
      "h5_3/Tanh\n",
      "o6_3/Sigmoid\n",
      "ins [<tf.Tensor 'h0_3/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_3/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_3/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_3/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_3/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_3/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_3/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_3:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_3:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_3:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 1387)\n",
      "gradients.shape (807, 1387)\n",
      "feature_weights.shape (1387,)\n",
      "feature_weights min max -2.323144 26.53767\n",
      "layer # 3, layer name h2,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "h2\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe3505cb850> None\n",
      "input dimensions (None, 27687)\n",
      "h2\n",
      "model.inputs [<tf.Tensor 'inputs_4:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_4/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h2_4/Tanh:0\", shape=(?, 1066), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_4/Tanh\n",
      "h1_4/Tanh\n",
      "h2_4/Tanh\n",
      "h3_4/Tanh\n",
      "h4_4/Tanh\n",
      "h5_4/Tanh\n",
      "o6_4/Sigmoid\n",
      "ins [<tf.Tensor 'h0_4/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_4/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_4/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_4/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_4/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_4/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_4/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_4:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_4:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_4:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 1066)\n",
      "gradients.shape (807, 1066)\n",
      "feature_weights.shape (1066,)\n",
      "feature_weights min max -2.323144 26.537672\n",
      "layer # 4, layer name h3,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "h3\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe35e0ef8d0> None\n",
      "input dimensions (None, 27687)\n",
      "h3\n",
      "model.inputs [<tf.Tensor 'inputs_5:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_5/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h3_5/Tanh:0\", shape=(?, 447), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_5/Tanh\n",
      "h1_5/Tanh\n",
      "h2_5/Tanh\n",
      "h3_5/Tanh\n",
      "h4_5/Tanh\n",
      "h5_5/Tanh\n",
      "o6_5/Sigmoid\n",
      "ins [<tf.Tensor 'h0_5/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_5/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_5/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_5/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_5/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_5/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_5/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_5:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_5:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_5:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 447)\n",
      "gradients.shape (807, 447)\n",
      "feature_weights.shape (447,)\n",
      "feature_weights min max -2.323144 51.29851\n",
      "layer # 5, layer name h4,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "h4\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe35f4488d0> None\n",
      "input dimensions (None, 27687)\n",
      "h4\n",
      "model.inputs [<tf.Tensor 'inputs_6:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_6/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h4_6/Tanh:0\", shape=(?, 147), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_6/Tanh\n",
      "h1_6/Tanh\n",
      "h2_6/Tanh\n",
      "h3_6/Tanh\n",
      "h4_6/Tanh\n",
      "h5_6/Tanh\n",
      "o6_6/Sigmoid\n",
      "ins [<tf.Tensor 'h0_6/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_6/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_6/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_6/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_6/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_6/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_6/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_6:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_6:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_6:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 147)\n",
      "gradients.shape (807, 147)\n",
      "feature_weights.shape (147,)\n",
      "feature_weights min max -2.3231442 53.54981\n",
      "layer # 6, layer name h5,  output name -1\n",
      "graph <tensorflow.python.framework.ops.Graph object at 0x7fe42b3f27d0>\n",
      "h5\n",
      "input dimension 27687 self.units 9229\n",
      "n_inputs_per_node 3\n",
      "self.kernel_initializer None <keras.initializers.VarianceScaling object at 0x7fe35f5e6d10> None\n",
      "input dimensions (None, 27687)\n",
      "h5\n",
      "model.inputs [<tf.Tensor 'inputs_7:0' shape=(?, 27687) dtype=float32>]\n",
      "model y Tensor(\"o6_7/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "model x Tensor(\"h5_7/Tanh:0\", shape=(?, 26), dtype=float32)\n",
      "hello from deep explain\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "xss (807, 27687), xs (807, 27687)\n",
      "h0_7/Tanh\n",
      "h1_7/Tanh\n",
      "h2_7/Tanh\n",
      "h3_7/Tanh\n",
      "h4_7/Tanh\n",
      "h5_7/Tanh\n",
      "o6_7/Sigmoid\n",
      "ins [<tf.Tensor 'h0_7/BiasAdd:0' shape=(?, 9229) dtype=float32>, <tf.Tensor 'h1_7/BiasAdd:0' shape=(?, 1387) dtype=float32>, <tf.Tensor 'h2_7/BiasAdd:0' shape=(?, 1066) dtype=float32>, <tf.Tensor 'h3_7/BiasAdd:0' shape=(?, 447) dtype=float32>, <tf.Tensor 'h4_7/BiasAdd:0' shape=(?, 147) dtype=float32>, <tf.Tensor 'h5_7/BiasAdd:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'o_linear6_7/BiasAdd:0' shape=(?, 1) dtype=float32>]\n",
      "Tensor(\"inputs_7:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_7:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (1, 27687) float64\n",
      "Tensor(\"inputs_7:0\", shape=(?, 27687), dtype=float32) <type 'numpy.ndarray'> (807, 27687) float64\n",
      "attributions (807, 26)\n",
      "gradients.shape (807, 26)\n",
      "feature_weights.shape (26,)\n",
      "feature_weights min max -2.3073554 56.7458\n",
      "predicting\n",
      "model id: P-net_ALL\n",
      "predicitng ...\n",
      "(204, 1)\n",
      "(204, 1)\n",
      "(204, 2)\n",
      "y_pred_test (204, 1) (204,)\n",
      "(204, 1) (204, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       137\n",
      "           1       0.64      0.79      0.71        67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   micro avg       0.78      0.78      0.78       204\n",
      "   macro avg       0.76      0.79      0.77       204\n",
      "weighted avg       0.80      0.78      0.79       204\n",
      "\n",
      "model name P-net_ALL -- Test score {'aupr': 0.8774140406819753, 'f1': 0.7066666666666667, 'auc': 0.9187275302320514, 'recall': 0.7910447761194029, 'precision': 0.6385542168674698, 'accuracy': 0.7843137254901961}\n",
      "saving results\n",
      "saving yml : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/P-net_ALL_params.yml\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/P-net_ALL_testing.csv\n",
      "('info', Index([u'01-087MM_BONE', u'01-095N1_LN', u'08-093J1_LN', u'10362',\n",
      "       u'AAPC-IP_LG-069-Tumor-SM-3NC72', u'AAPC-STID0000002909-Tumor-SM-2XTZ4',\n",
      "       u'AAPC-STID0000003057-Tumor-SM-2XTZT',\n",
      "       u'AAPC-STID0000007180-Tumor-SM-2XU14',\n",
      "       u'AAPC-STID0000012110-Tumor-SM-2XU1J',\n",
      "       u'AAPC-STID0000017088-Tumor-SM-2XU1V',\n",
      "       ...\n",
      "       u'TCGA-V1-A9OY', u'TCGA-V1-A9Z9', u'TCGA-VN-A88O', u'TCGA-VN-A943',\n",
      "       u'TCGA-XK-AAJP', u'TCGA-YL-A8HL', u'TCGA-ZG-A9LM', u'TCGA-ZG-A9LN',\n",
      "       u'TCGA-ZG-A9MC', u'TP_2034'],\n",
      "      dtype='object', length=204))\n",
      "saving coef \n",
      "Confusion matrix, without normalization\n",
      "[[107  30]\n",
      " [ 14  53]]\n",
      "Normalized confusion matrix\n",
      "[[0.7810219  0.2189781 ]\n",
      " [0.20895522 0.79104478]]\n",
      "saving coef\n",
      "saving coef\n",
      "saving model P-net_ALL coef to dir (/Users/jongha523/pnet_prostate_paper/_logs/p1000/pnet/onsplit_average_reg_10_tanh_large_testing/fs)\n",
      "FS dir (/Users/jongha523/pnet_prostate_paper/_logs/p1000/pnet/onsplit_average_reg_10_tanh_large_testing/fs/P-net_ALL.h5)\n",
      "predicitng ...\n",
      "(807, 1)\n",
      "(807, 1)\n",
      "(807, 2)\n",
      "y_pred_test (807, 1) (807,)\n",
      "(807, 1) (807, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       541\n",
      "           1       1.00      0.99      0.99       266\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       807\n",
      "   macro avg       1.00      1.00      1.00       807\n",
      "weighted avg       1.00      1.00      1.00       807\n",
      "\n",
      "model P-net_ALL -- Train score {'aupr': 0.9975716281700495, 'f1': 0.9943502824858758, 'auc': 0.9982766528150321, 'recall': 0.9924812030075187, 'precision': 0.9962264150943396, 'accuracy': 0.9962825278810409}\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/P-net_ALL_training.csv\n",
      "('info', Index([u'01-120A1_LIVER', u'02-083E1_LN', u'03-082H1_LIVER',\n",
      "       u'03-130L_RETROPERITONEAL', u'03-139E3_RETROPERITONEAL',\n",
      "       u'03-163S4_LIVER', u'03-192B_LUNG', u'05-116F_LUNG', u'05-148E3_LIVER',\n",
      "       u'05-165O_ADRENAL',\n",
      "       ...\n",
      "       u'TCGA-ZG-A9ND', u'TCGA-ZG-A9NI', u'TP_2010', u'TP_2032', u'TP_2054',\n",
      "       u'TP_2060', u'TP_2061', u'TP_2069', u'TP_2078', u'TP_2079'],\n",
      "      dtype='object', length=807))\n",
      "fitting\n",
      "{'type': 'sgd', 'params': {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01, 'class_weight': {0: 0.75, 1: 1.5}}, 'id': 'Logistic Regression'}\n",
      "/opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/pnet_env/lib/python2.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "predicting\n",
      "model id: Logistic Regression_ALL\n",
      "predicitng ...\n",
      "y_pred_test (204,) (204,)\n",
      "(204, 1) (204,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       137\n",
      "           1       0.79      0.67      0.73        67\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       204\n",
      "   macro avg       0.82      0.79      0.80       204\n",
      "weighted avg       0.83      0.83      0.83       204\n",
      "\n",
      "model name Logistic Regression_ALL -- Test score {'aupr': 0.8089833666704149, 'f1': 0.7258064516129032, 'auc': 0.881904346878745, 'recall': 0.6716417910447762, 'precision': 0.7894736842105263, 'accuracy': 0.8333333333333334}\n",
      "saving results\n",
      "saving yml : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/Logistic Regression_ALL_params.yml\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/Logistic Regression_ALL_testing.csv\n",
      "('info', Index([u'01-087MM_BONE', u'01-095N1_LN', u'08-093J1_LN', u'10362',\n",
      "       u'AAPC-IP_LG-069-Tumor-SM-3NC72', u'AAPC-STID0000002909-Tumor-SM-2XTZ4',\n",
      "       u'AAPC-STID0000003057-Tumor-SM-2XTZT',\n",
      "       u'AAPC-STID0000007180-Tumor-SM-2XU14',\n",
      "       u'AAPC-STID0000012110-Tumor-SM-2XU1J',\n",
      "       u'AAPC-STID0000017088-Tumor-SM-2XU1V',\n",
      "       ...\n",
      "       u'TCGA-V1-A9OY', u'TCGA-V1-A9Z9', u'TCGA-VN-A88O', u'TCGA-VN-A943',\n",
      "       u'TCGA-XK-AAJP', u'TCGA-YL-A8HL', u'TCGA-ZG-A9LM', u'TCGA-ZG-A9LN',\n",
      "       u'TCGA-ZG-A9MC', u'TP_2034'],\n",
      "      dtype='object', length=204))\n",
      "saving coef \n",
      "Confusion matrix, without normalization\n",
      "[[125  12]\n",
      " [ 22  45]]\n",
      "Normalized confusion matrix\n",
      "[[0.91240876 0.08759124]\n",
      " [0.32835821 0.67164179]]\n",
      "saving coef\n",
      "predicitng ...\n",
      "y_pred_test (807,) (807,)\n",
      "(807, 1) (807,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       541\n",
      "           1       0.99      0.98      0.99       266\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       807\n",
      "   macro avg       0.99      0.99      0.99       807\n",
      "weighted avg       0.99      0.99      0.99       807\n",
      "\n",
      "model Logistic Regression_ALL -- Train score {'aupr': 0.998589320472007, 'f1': 0.9886792452830188, 'auc': 0.9991800202910233, 'recall': 0.9849624060150376, 'precision': 0.9924242424242424, 'accuracy': 0.9925650557620818}\n",
      "saving results : /Users/jongha523/pnet_prostate_paper/_logs/p1000/./pnet/onsplit_average_reg_10_tanh_large_testing/Logistic Regression_ALL_training.csv\n",
      "('info', Index([u'01-120A1_LIVER', u'02-083E1_LN', u'03-082H1_LIVER',\n",
      "       u'03-130L_RETROPERITONEAL', u'03-139E3_RETROPERITONEAL',\n",
      "       u'03-163S4_LIVER', u'03-192B_LUNG', u'05-116F_LUNG', u'05-148E3_LIVER',\n",
      "       u'05-165O_ADRENAL',\n",
      "       ...\n",
      "       u'TCGA-ZG-A9ND', u'TCGA-ZG-A9NI', u'TP_2010', u'TP_2032', u'TP_2054',\n",
      "       u'TP_2060', u'TP_2061', u'TP_2069', u'TP_2078', u'TP_2079'],\n",
      "      dtype='object', length=807))\n",
      "accuracy\n",
      "auc\n",
      "aupr\n",
      "f1\n",
      "precision\n",
      "recall\n",
      "                         accuracy       auc  ...  precision    recall\n",
      "P-net_ALL                0.784314  0.918728  ...   0.638554  0.791045\n",
      "Logistic Regression_ALL  0.833333  0.881904  ...   0.789474  0.671642\n",
      "\n",
      "[2 rows x 6 columns]\n",
      "Elapsed Time: 12m 37s\n",
      "(pnet_env) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#Run the run_me.py file once more to retrain the model with newly defined parameters (batch size=20)\n",
    "#evaluation metrics shown at the very bottom\n",
    "pythonw run_me.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
